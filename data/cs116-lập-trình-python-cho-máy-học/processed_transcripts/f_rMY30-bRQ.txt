0:00:00 - 0:00:06, thì đối với cái phương và ngoài ra thì
0:00:03 - 0:00:10, chúng ta sẽ còn có phương pháp
0:00:06 - 0:00:12, wrapper theo cái kiểu là random feature tức là
0:00:10 - 0:00:15, với cái đặc trưng X chúng ta có cái
0:00:12 - 0:00:16, đặc trưng là các cái cột ở đây và chúng
0:00:15 - 0:00:19, ta
0:00:16 - 0:00:22, sẽ đưa một cái đặc trưng nữa một cái đặc
0:00:19 - 0:00:24, trưng đặc biệt đó là random feature các
0:00:22 - 0:00:26, cái giá trị trên cái cột này chúng ta sẽ
0:00:24 - 0:00:31, được khởi tạo ngẫu nhiên. Sang bước thứ
0:00:26 - 0:00:34, hai chúng ta sẽ đem cái dữ liệu đã có
0:00:31 - 0:00:36, đặc trưng ngẫu nhiên này vào cái mô hình
0:00:34 - 0:00:38, huấn luyện và mô hình huấn luyện này thì
0:00:36 - 0:00:41, thông thường sẽ là sử dụng các cái mô
0:00:38 - 0:00:43, hình mà có cái độ đo để đánh giá cái tầm
0:00:41 - 0:00:46, quan trọng của đặc trưng ha. Và sau khi
0:00:43 - 0:00:49, chúng ta thực hiện supervised learning với
0:00:46 - 0:00:53, cái mô hình này xong chúng ta sẽ đánh
0:00:49 - 0:00:55, giá xem là cái mức độ quan trọng của đặc
0:00:53 - 0:00:58, trưng, mức độ quan trọng của đặc trưng nó
0:00:55 - 0:01:01, được tính hoặc được trích ra từ cái mô
0:00:58 - 0:01:04, hình này ha. Và đối với cái đặc trưng mà
0:01:01 - 0:01:06, random ở đây và chúng ta có cái độ quan
0:01:04 - 0:01:09, trọng là như thế này thì tất cả những
0:01:06 - 0:01:11, cái đặc trưng nào mà có cái độ quan
0:01:09 - 0:01:15, trọng nhỏ hơn cái độ quan trọng của đặc
0:01:11 - 0:01:18, trưng random thì chúng ta sẽ loại bỏ đi.
0:01:15 - 0:01:21, Và chúng ta lặp đi lặp lại cái quá trình
0:01:18 - 0:01:25, này. Chúng ta lại tiếp tục thêm một cái
0:01:21 - 0:01:28, cột đặc trưng random trên những
0:01:25 - 0:01:30, cái dữ liệu trên những cái đặc trưng mà
0:01:28 - 0:01:32, chúng ta đã lọc ở cái bước đầu tiên
0:01:30 - 0:01:35, đó thì chúng ta lặp đi lặp lại cho đến
0:01:32 - 0:01:38, khi nào mà chúng ta đạt được một
0:01:35 - 0:01:41, cái ngưỡng dừng thì đó chính là những cái
0:01:38 - 0:01:43, đặc trưng còn lại quan trọng phục vụ cho
0:01:41 - 0:01:43, cái model của
0:01:45 - 0:01:51, mình. Ở đây thì chúng ta lưu ý là cái
0:01:49 - 0:01:55, phương pháp này là phương pháp số hai ha.
0:01:51 - 0:01:55, Rồi cuối cùng thì chúng ta nhận xét đó
0:01:56 - 0:02:01, là ưu điểm của phương pháp wrapper đó
0:01:59 - 0:02:03, là có cái sự nó đã bắt đầu có cái sự
0:02:01 - 0:02:05, tương tác giữa các cái đặc trưng với
0:02:03 - 0:02:10, nhau thông qua cái việc là đưa vào một
0:02:05 - 0:02:13, cái mô hình để huấn luyện. Và tập con của
0:02:10 - 0:02:17, các cái đặc trưng thì nó sẽ được chọn
0:02:13 - 0:02:19, lựa để tối ưu theo mô hình, nó sẽ tối ưu
0:02:17 - 0:02:21, theo mô hình. Tuy nhiên cái khuyết điểm
0:02:19 - 0:02:23, của cái phương pháp này đó là chi phí
0:02:21 - 0:02:24, tính toán lớn tại vì chúng ta phải thực
0:02:23 - 0:02:26, hiện đi thực hiện lại, thực hiện đi thực
0:02:24 - 0:02:30, hiện lại cái việc huấn luyện cái mô hình
0:02:26 - 0:02:32, nhiều lần. Và phương pháp này thì nó sẽ
0:02:30 - 0:02:34, dễ bị hiện tượng
0:02:32 - 0:02:38, overfitting dẫn đến là cái kết quả của
0:02:34 - 0:02:41, mình nó sẽ tốt cho dữ liệu train nhưng
0:02:38 - 0:02:43, mà khi chúng ta test trên một cái dữ
0:02:41 - 0:02:45, liệu chưa thấy bao giờ thì độ chính xác
0:02:43 - 0:02:48, nó lại thấp. Và phương pháp này thì nó
0:02:45 - 0:02:49, phức tạp hơn, cách thức nó thực hiện nó
0:02:48 - 0:02:53, phức tạp hơn so với lại phương pháp
0:02:49 - 0:02:54, filter và phương pháp số một. Chúng ta sẽ
0:02:53 - 0:02:58, qua cái phương pháp số ba đó là phương
0:02:54 - 0:03:01, pháp embedded Model tức là bản thân trong cái
0:02:58 - 0:03:04, mô hình của mình nó đã có cái khả
0:03:01 - 0:03:06, năng chọn lọc đặc trưng. Đó thì phương
0:03:04 - 0:03:09, pháp đầu tiên đó chính là phương pháp
0:03:06 - 0:03:13, lasso. Thì trong cái phương pháp lasso
0:03:09 - 0:03:16, này nó sử dụng cái regularization là L1.
0:03:13 - 0:03:19, Thì cái regularization L1 này nó sẽ ép
0:03:16 - 0:03:23, cái mô hình của mình nó sẽ cố gắng chọn
0:03:19 - 0:03:26, ra những cái đặc trưng nào mà ít quan
0:03:23 - 0:03:28, trọng nó sẽ cho cái hệ số tiến về 0. Cái
0:03:26 - 0:03:30, hệ số của ví dụ chúng ta có cái đặc
0:03:28 - 0:03:32, trưng x_i này không quan trọng thì cái hệ
0:03:30 - 0:03:36, số beta tương ứng với cái đặc trưng x_i
0:03:32 - 0:03:39, này nó sẽ tiến về 0 do cái thành phần
0:03:36 - 0:03:43, regularization thành phần chính quy hóa
0:03:39 - 0:03:47, L1 này. Còn tương tự như vậy cho các cái
0:03:43 - 0:03:51, phương pháp ridge regression và elastic net
0:03:47 - 0:03:52, nó cũng sẽ góp phần cho chúng ta chọn
0:03:51 - 0:03:54, lựa cái đặc trưng nào quan trọng hơn.
0:03:52 - 0:03:57, Những đặc trưng nào không quan trọng thì
0:03:54 - 0:04:00, cái hệ số của nó nó thường sẽ được ép về
0:03:57 - 0:04:03, cái giá trị thấp hơn.
0:04:00 - 0:04:04, Và chúng ta cũng có một số cái mô hình
0:04:03 - 0:04:07, khác
0:04:04 - 0:04:10, những cái mô hình mà dạng cây tree-based
0:04:07 - 0:04:12, Model. Những cái mô hình dạng cây thì
0:04:10 - 0:04:14, trong cái quá trình mà xây dựng cây nó
0:04:12 - 0:04:17, cũng đã có cái ngầm thực hiện cái thao
0:04:14 - 0:04:19, tác đó là chọn lọc đặc trưng, chọn những
0:04:17 - 0:04:23, cái đặc
0:04:19 - 0:04:25, trưng mà có chứa nhiều thông tin, có chứa
0:04:23 - 0:04:28, nhiều thông tin hoặc là chọn ra những
0:04:25 - 0:04:30, cái đặc trưng mà có cái tính phân loại
0:04:28 - 0:04:33, cao,
0:04:30 - 0:04:33, tính phân loại
0:04:34 - 0:04:39, cao. Còn các cái đặc trưng mà không có
0:04:37 - 0:04:42, cái tính phân loại cao hoặc là các cái
0:04:39 - 0:04:44, đặc trưng dư thừa thì cái phương
0:04:42 - 0:04:46, pháp mà dựa trên cây nó sẽ loại bỏ đi, nó
0:04:44 - 0:04:50, sẽ không có đưa vào bên trong cái cấu
0:04:46 - 0:04:52, trúc cây để mà phân lớp. Thì đó là cái
0:04:50 - 0:04:55, phương pháp số ba là embedded Model tức là
0:04:52 - 0:04:57, chúng ta ngầm bên trong Model nó đã thực
0:04:55 - 0:05:00, hiện cái việc chọn lựa đặc trưng cho
0:04:57 - 0:05:03, mình rồi. Và ưu điểm của phương pháp này
0:05:00 - 0:05:06, đó là nó sẽ có cái hiệu quả tính toán
0:05:03 - 0:05:09, cao hơn so với wrapper do nó không phải
0:05:06 - 0:05:11, thực hiện đi thực hiện lại cái việc huấn
0:05:09 - 0:05:14, luyện mô hình nhiều lần và cái tính tổng
0:05:11 - 0:05:16, quát hóa của nó cũng cao hơn và có được
0:05:14 - 0:05:19, cái sự tương tác giữa các cái đặc trưng
0:05:16 - 0:05:21, cũng như là các tham số của mô hình. Và
0:05:19 - 0:05:23, khuyết điểm của nó đó là cái khả năng
0:05:21 - 0:05:27, giải thích của đặc trưng nó sẽ thấp hơn
0:05:23 - 0:05:30, so với lại filter. Tại vì ở bên trong mô
0:05:27 - 0:05:32, hình nó vận hành nó chạy
0:05:30 - 0:05:34, ngầm và nó thực hiện cái việc chọn lựa
0:05:32 - 0:05:37, đặc trưng một cách ngầm định. Do đó thì
0:05:34 - 0:05:40, khi nó ra được cái kết quả rồi thì chúng
0:05:37 - 0:05:41, ta rất khó để có thể giải thích cho
0:05:40 - 0:05:43, những cái người mà không có chuyên môn
0:05:41 - 0:05:45, về machine learning biết là tại sao mô
0:05:43 - 0:05:48, hình nó chọn cái đặc trưng này mà không
0:05:45 - 0:05:51, chọn cái đặc trưng kia. Và nó vẫn có một
0:05:48 - 0:05:55, cái khả năng đó là overfit với dữ liệu.
0:05:51 - 0:05:57, Ví dụ như với một cái mô hình tree-based
0:05:55 - 0:06:00, thì có khả năng là cái cây mà nó được
0:05:57 - 0:06:02, tạo ra nó sẽ đúng cho cái dữ liệu huấn
0:06:00 - 0:06:05, luyện của mình. Nhưng khi chúng ta chỉ
0:06:02 - 0:06:07, thay đổi nhỏ trên những cái dữ liệu huấn
0:06:05 - 0:06:09, luyện hoặc là dữ liệu test thì có khả
0:06:07 - 0:06:10, năng là độ chính xác của nó nó sẽ không có
0:06:09 - 0:06:14, còn cao
0:06:10 - 0:06:18, nữa. Thì đó chính là cái ưu khuyết điểm
0:06:14 - 0:06:21, của phương pháp số ba. Và phương pháp số 4
0:06:18 - 0:06:24, đó chính là chúng ta sẽ giảm chiều dựa
0:06:21 - 0:06:27, trên một số thuật toán học không giám sát
0:06:24 - 0:06:29, ví dụ như là thuật toán PCA. Chi tiết
0:06:27 - 0:06:31, trong cái phần các cái mô hình un
0:06:29 - 0:06:34, supervised learning thì chúng ta sẽ được
0:06:31 - 0:06:35, hiểu rõ hơn về thuật toán PCA này. Nhưng mà
0:06:34 - 0:06:39, đại khái đó
0:06:35 - 0:06:43, là với cái đặc trưng, với cái tập dữ liệu
0:06:39 - 0:06:47, đặc trưng đầu vào là x1, x2 cho đến xn
0:06:43 - 0:06:50, thì qua cái thuật toán PCA nó sẽ đưa về
0:06:47 - 0:06:56, cái đặc trưng là x phẩy. Lưu ý x phẩy này nó khác
0:06:50 - 0:07:00, với x này ha, x phẩy 1, x phẩy 2 và x phẩy
0:06:56 - 0:07:02, k, trong đó k nó phải bé hơn cái con số n
0:07:00 - 0:07:05, này thì khi đó là nó giảm số chiều. Tương
0:07:02 - 0:07:08, tự như vậy cho cái thuật toán là
0:07:05 - 0:07:10, independent component analysis và thuật
0:07:08 - 0:07:13, toán phân tích các thành phần độc lập.
0:07:10 - 0:07:15, Thì ưu điểm của phương pháp giảm chiều
0:07:13 - 0:07:17, dữ liệu đó chính là cái hiệu quả tính
0:07:15 - 0:07:19, toán của nó cao do các cái nhóm thuật
0:07:17 - 0:07:21, toán này được thực hiện trên các cái
0:07:19 - 0:07:24, phép biến đổi tuyến tính nên tốc độ tính
0:07:21 - 0:07:28, toán rất là nhanh. Và nó có thể trực quan
0:07:24 - 0:07:30, hóa được dưới dạng là các cái, nó có
0:07:28 - 0:07:33, thể trực quan hóa được do chúng ta có
0:07:30 - 0:07:35, thể giảm cái số chiều của mình xuống là
0:07:33 - 0:07:37, K có thể là bằng 2 và bằng 3 tức là hai
0:07:35 - 0:07:39, chiều cho đến 3 chiều thì khi đó chúng
0:07:37 - 0:07:43, ta có thể vẽ được trong cái không gian
0:07:39 - 0:07:46, và chúng ta có thể quan sát được. Và cái
0:07:43 - 0:07:49, việc loại bỏ các cái đặc trưng nhiễu thì
0:07:46 - 0:07:52, nó sẽ là đặc trưng có cái phương sai
0:07:49 - 0:07:53, thấp. Đó thì cái việc loại bỏ cái đặc
0:07:52 - 0:07:57, trưng này thì nó cũng có cái tính chất
0:07:53 - 0:08:00, gọi là có thể giải thích được. Điểm yếu
0:07:57 - 0:08:03, của cái phương pháp giảm chiều dữ liệu
0:08:00 - 0:08:05, đó là khả năng giải thích các cái đặc
0:08:03 - 0:08:08, trưng, tức là khả năng giải thích đặc
0:08:05 - 0:08:11, trưng của mình nó là thấp do các cái
0:08:08 - 0:08:14, thao tác tính toán trên PCA và ICA này
0:08:11 - 0:08:18, đó là những cái thao tác cũng tương đối
0:08:14 - 0:08:20, là ngầm tính toán. Và cái mô hình của
0:08:18 - 0:08:22, mình nó sẽ ngầm chọn ra những cái đặc
0:08:20 - 0:08:24, trưng. Và khi chúng ta chuyển sang cái
0:08:22 - 0:08:27, dạng đặc trưng là x phẩy 1, x phẩy 2 cho đến X
0:08:24 - 0:08:29, phẩy k thì các cái giải giá trị của x phẩy này
0:08:27 - 0:08:32, nó không còn giống với lại cái giá trị
0:08:29 - 0:08:35, x1, x2 ban đầu nữa dẫn đến là khó giải
0:08:32 - 0:08:37, thích. Và các cái phương pháp này thì nó
0:08:35 - 0:08:40, chỉ có thể tính toán được trên các cái
0:08:37 - 0:08:41, dữ liệu dạng số, dạng số học. Do đó thì
0:08:40 - 0:08:44, nó không phù hợp với các cái dữ liệu
0:08:41 - 0:08:47, dạng phân loại hoặc là dạng danh mục.
0:08:44 - 0:08:49, Và cái việc chuyển cái đặc trưng sang
0:08:47 - 0:08:53, cái không gian khác thì nó sẽ không cung
0:08:49 - 0:08:54, cấp được cái tập con cụ thể là các cái
0:08:53 - 0:08:57, đặc trưng quan
0:08:54 - 0:09:01, trọng. Đó thì đây chính là những cái điểm
0:08:57 - 0:09:05, yếu của cái phương pháp số
0:09:01 - 0:09:08, 4. Và chúng ta sẽ có một số cái công cụ
0:09:05 - 0:09:11, để giúp cho chúng ta chọn lựa đặc trưng.
0:09:08 - 0:09:13, Đó là thông qua các cái thư viện. Thì nổi
0:09:11 - 0:09:15, tiếng nhất và có thể dễ sử dụng đó chính
0:09:13 - 0:09:18, là thư viện scikit-learn. Thì chúng ta sẽ có
0:09:15 - 0:09:22, các cái API nằm trong cái thư viện của scikit-learn.
0:09:18 - 0:09:26, Rồi chúng ta sẽ có cái thư viện là
0:09:22 - 0:09:28, Leave-One-Feature-Out (LOFO). Rồi chúng ta
0:09:26 - 0:09:30, sẽ có thư viện là SHAP. Thì đây cũng
0:09:28 - 0:09:33, là một trong những cái thư viện mà có
0:09:30 - 0:09:38, cái số lượt citation rất là nhiều. Rồi
0:09:33 - 0:09:40, thư viện là Boruta SHAP vân vân.
0:09:38 - 0:09:42, Thì đây chính là những cái thư viện mà
0:09:40 - 0:09:44, thường được sử dụng cho cái việc là chọn
0:09:42 - 0:09:47, lựa đặc
0:09:44 - 0:09:51, trưng. Và như vậy thì trong cái bài ngày
0:09:47 - 0:09:54, hôm nay thì chúng ta đã cùng lượt qua
0:09:51 - 0:09:56, các cái thao tác tiền xử lý dữ liệu. Nó
0:09:54 - 0:10:00, bao gồm là các cái thao tác liên quan
0:10:00 - 0:10:02, đến cái xử lý dữ liệu bị thiếu,
0:10:02 - 0:10:05, dữ liệu bị nhiễu.
0:10:05 - 0:10:09, Và sau khi chúng ta đã tiền xử lý dữ liệu để mà làm sạch dữ liệu rồi thì
0:10:07 - 0:10:13, chúng ta sẽ có ba cái thao tác trên đặc
0:10:09 - 0:10:13, trưng. Đầu tiên đó là chúng ta tạo đặc
0:10:17 - 0:10:24, trưng rồi sau đó chúng ta biến đổi đặc
0:10:22 - 0:10:24, trưng.
0:10:25 - 0:10:31, Cái việc biến đổi này nó sẽ giúp
0:10:28 - 0:10:34, chúng ta đưa cái đặc trưng từ dạng gốc
0:10:31 - 0:10:36, về cái đặc trưng mà mô hình máy học có
0:10:34 - 0:10:39, thể tính toán một cách dễ dàng. Và cuối
0:10:36 - 0:10:41, cùng đó là chúng ta chọn lựa đặc trưng.
0:10:39 - 0:10:43, Tại vì sau khi chúng ta đã tạo đặc trưng,
0:10:41 - 0:10:45, biến đổi đặc trưng xong thì có rất nhiều
0:10:43 - 0:10:47, những cái đặc trưng nó không thực sự cần
0:10:45 - 0:10:51, thiết cho mô hình của mình. Thì những cái
0:10:47 - 0:10:52, đặc trưng đó sẽ được loại bỏ đi. Còn
0:10:51 - 0:10:55, những đặc trưng nào quan trọng thì sẽ
0:10:52 - 0:10:57, được giữ lại. Thì đó là toàn bộ những cái
0:10:55 - 0:11:00, nội dung mà chúng ta học trong cái bài
0:10:57 - 0:11:00, học ngày hôm nay.