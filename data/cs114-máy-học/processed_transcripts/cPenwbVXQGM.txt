0:00:01 - 0:00:16, [âm nhạc]
0:00:13 - 0:00:21, Bây giờ chúng ta sẽ thử chạy
0:00:16 - 0:00:23, trên một cái GPU à gắn với máy tính thật
0:00:21 - 0:00:24, của các bạn, không phải thông qua máy ảo
0:00:23 - 0:00:27, Google Colab. Thì liệu các bạn có thể
0:00:24 - 0:00:30, chạy được những cái chương trình machine
0:00:27 - 0:00:34, learning này hay không? Thì trên nếu hồi
0:00:30 - 0:00:36, nãy các bạn tinh ý thì sẽ thấy trên
0:00:34 - 0:00:39, máy tính
0:00:36 - 0:00:46, của thầy hiện tại cũng có một cái GPU
0:00:39 - 0:00:48, ha. Đó là con AMD Radeon 6700XT.
0:00:46 - 0:00:53, Đó, GPU này thì nó cũng đời cũ rồi, thậm
0:00:48 - 0:00:53, chí nó còn cũ hơn cả con CPU nữa.
0:00:54 - 0:01:01, Nếu chúng ta tra nhanh thử thông tin cái
0:00:57 - 0:01:01, GPU này thì à
0:01:02 - 0:01:08, hiện giờ chắc là chỉ còn những cái trang,
0:01:06 - 0:01:14, những cái shop nào mà họ bán đồ cũ thì
0:01:08 - 0:01:15, may ra họ còn mẫu GPU này thôi ha. Đó.
0:01:14 - 0:01:18, Đây a
0:01:15 - 0:01:23, à shop này cũng còn khá nhiều. Còn một
0:01:18 - 0:01:27, số shop khác thì đây mẫu 6700XT này hiện
0:01:23 - 0:01:29, bán với giá khoảng 7 triệu. Chắc là hàng
0:01:27 - 0:01:31, tồn kho của họ. Còn nếu hàng nếu các bạn
0:01:29 - 0:01:36, mua đồ second-hand thì chắc nó sẽ rẻ
0:01:31 - 0:01:39, hơn nữa ha. Thì GPU này
0:01:36 - 0:01:41, nó có cấu hình cũng a không phải là cao
0:01:39 - 0:01:43, lắm ha.
0:01:41 - 0:01:47, Nếu các bạn đây có thể thấy hình dáng
0:01:43 - 0:01:52, của GPU về thông số thì nó chỉ có 12 GB
0:01:47 - 0:01:54, V RAM thôi, ít hơn cả GPU Tesla T4 mà
0:01:52 - 0:01:58, Google Colab sẽ cung cấp miễn phí của
0:01:54 - 0:02:01, các bạn. Nhưng mẫu GPU này là mẫu GPU
0:01:58 - 0:02:05, cho người dùng cá nhân và thường. Nó
0:02:01 - 0:02:07, hướng đến việc ừ tăng tốc các cái thao tác xử
0:02:05 - 0:02:09, lý liên quan đến đồ họa nhiều hơn là các
0:02:07 - 0:02:11, cái thao tác xử lý tính toán trên máy
0:02:09 - 0:02:13, chủ.
0:02:11 - 0:02:16, Nên nó sẽ yêu cầu nguồn điện cao hơn và
0:02:13 - 0:02:19, tốc độ chạy của nó thì nhiều khi cũng có
0:02:16 - 0:02:22, thể là nhanh hơn Tesla T4 nhưng mà VRAM
0:02:19 - 0:02:24, của nó sẽ hạn chế hơn. Và cái mẫu GPU
0:02:22 - 0:02:27, này thì các bạn không thể gắn nhiều quá
0:02:24 - 0:02:29, nhiều GPU vào cùng một máy như mẫu GPU
0:02:27 - 0:02:33, dành riêng cho server được ha. Trên
0:02:29 - 0:02:35, server một máy chủ có thể gắn đến hàng
0:02:33 - 0:02:37, vài chục ha. Mấy cái nhiều nhất có thể
0:02:35 - 0:02:39, gắn đến khoảng hai mươi mấy cái GPU. Còn
0:02:37 - 0:02:42, nếu trong máy tính cá nhân của các bạn
0:02:39 - 0:02:44, thì thường mỗi máy tính chỉ gắn được một
0:02:42 - 0:02:50, GPU này mà thôi. Đó thì ở đây chúng ta
0:02:44 - 0:02:50, có một GPU duy nhất. GPU này
0:02:51 - 0:02:55, hiện tại cũng đang được sử dụng khá
0:02:52 - 0:02:59, nhiều ha. Đó, đây là GPU duy nhất có
0:02:55 - 0:03:01, trong máy tính nên nó sẽ phải gánh cả
0:03:01 - 0:03:05, các cái ứng dụng đồ họa mà máy đang
0:03:04 - 0:03:07, chạy. Đặc biệt là ứng dụng quay video,
0:03:05 - 0:03:10, bài giảng chẳng hạn thì các bạn thấy
0:03:07 - 0:03:14, VRAM chưa gì là nó đã dùng gần phân nửa
0:03:10 - 0:03:16, rồi đó. Và
0:03:14 - 0:03:19, utilization đang cỡ khoảng 40%.
0:03:16 - 0:03:21, Đây là chỉ là những phần mềm chạy trên
0:03:19 - 0:03:23, máy và để quay video bài giảng này mà
0:03:21 - 0:03:25, thôi ha. Chưa đụng gì đến machine
0:03:23 - 0:03:28, learning. Thì nếu chúng ta cần, chúng ta
0:03:25 - 0:03:31, vẫn có thể chạy
0:03:28 - 0:03:34, cái code machine learning của chúng ta
0:03:31 - 0:03:36, trên con GPU này. Mặc dù nó sẽ không
0:03:34 - 0:03:37, phải là tối ưu như là chạy trên một
0:03:36 - 0:03:41, server đó. Nhưng nếu các bạn biết cách
0:03:37 - 0:03:44, cài đặt các bạn vẫn có thể chạy được.
0:03:41 - 0:03:47, Thì đầu tiên mỗi GPU tùy hãng sản xuất
0:03:44 - 0:03:48, ha, tùy công nghệ mà để chạy các bạn sẽ
0:03:47 - 0:03:50, phải có cách cài đặt TensorFlow khác
0:03:48 - 0:03:52, nhau.
0:03:50 - 0:03:57, Thông thường cách cài đặt dễ nhất nếu
0:03:52 - 0:04:00, các bạn dùng cách cài đặt mặc định này
0:03:57 - 0:04:03, nó chỉ work nếu như các bạn dùng GPU đời
0:04:00 - 0:04:06, mới mà của hãng Nvidia. Còn với hãng AMD
0:04:03 - 0:04:11, thì các bạn sẽ nếu như dùng Docker các
0:04:06 - 0:04:11, bạn sẽ phải sử dụng docker
0:04:18 - 0:04:25, hỗ trợ một cái công nghệ gọi là ROCm
0:04:20 - 0:04:26, [âm nhạc]
0:04:25 - 0:04:31, rồi. ROCm đây là cái
0:04:26 - 0:04:33, Docker
0:04:31 - 0:04:37, Hub image à tức là cái máy ảo chứa cài sẵn
0:04:33 - 0:04:40, TensorFlow và cái thư viện tên là
0:04:37 - 0:04:43, ROCm do AMD họ cung cấp và quản lý.
0:04:40 - 0:04:48, Rồi đây là cái công cụ để giúp TensorFlow
0:04:43 - 0:04:49, chạy được trên những cái GPU do
0:04:48 - 0:04:52, hãng AMD họ phát hành.
0:04:49 - 0:04:55, Thì các bạn sẽ thấy cái lệnh để chạy
0:04:52 - 0:04:59, lệnh Docker run ở đây sẽ có cú pháp phức
0:04:55 - 0:05:03, tạp hơn à tương đối là nhiều so với cái
0:04:59 - 0:05:06, lệnh Docker dùng để chạy trên GPU Nvidia
0:05:03 - 0:05:13, ha. Đó và ở đây thì chúng ta chạy thử
0:05:06 - 0:05:13, thôi. Đó.
0:05:17 - 0:05:24, Rồi và máy này thì đã có chạy trước đó.
0:05:20 - 0:05:26, Rồi lệnh chạy sẽ bắt đầu như thế này ha.
0:05:24 - 0:05:30, Docker run. Rồi chúng ta cũng share cái
0:05:26 - 0:05:34, working directory hiện hành với cái máy
0:05:30 - 0:05:38, ảo. Và đây là các cái thông số à mặc
0:05:34 - 0:05:41, định theo gợi ý của Docker
0:05:38 - 0:05:43, Hub do AMD họ đề xuất. Rồi và chúng ta
0:05:41 - 0:05:48, share cái folder này ha. Chúng ta sẽ
0:05:43 - 0:05:49, chạy một cái terminal bash để chúng ta
0:05:48 - 0:05:51, có thể tương tác với lại cái máy ảo.
0:05:49 - 0:05:53, Sau khi chạy xong thì chắc các bạn còn
0:05:51 - 0:05:55, nhớ công việc đầu tiên chúng ta sẽ phải
0:05:53 - 0:06:03, install hai cái thư viện mà mặc định
0:05:55 - 0:06:06, TensorFlow họ không cung cấp sẵn đó là
0:06:03 - 0:06:08, Matplotlib và tensorflow-datasets.
0:06:06 - 0:06:12, Rồi và máy này cài sẵn rồi thì nên nó
0:06:08 - 0:06:12, chạy cũng khá là nhanh thôi ha.
0:06:13 - 0:06:19, Requirement đều satisfied sẵn.
0:06:16 - 0:06:23, Sau khi cài đặt xong thì
0:06:19 - 0:06:23, à ở đây chúng ta sẽ tạm thời chia màn
0:06:24 - 0:06:32, hình này làm hai phần.
0:06:27 - 0:06:32, một bên để các bạn à quan sát
0:06:37 - 0:06:45, tài nguyên được sử dụng của máy.
0:06:40 - 0:06:48, Đó, bên dưới là tài nguyên được sử dụng
0:06:45 - 0:06:51, của máy hiện hành ha. Và
0:06:48 - 0:06:56, đây là tài nguyên ở phía bên tay phải
0:06:51 - 0:07:01, trái của chúng ta là các cái tài nguyên
0:06:56 - 0:07:05, của GPU ha. Và bên tay phải phía trên là
0:07:01 - 0:07:09, các cái tài nguyên của ừ CPU. Bây giờ
0:07:05 - 0:07:11, chúng ta sẽ chạy lại cái
0:07:09 - 0:07:13, ừ máy ảo này ha. Ờ
0:07:11 - 0:07:18, đầu tiên chúng ta vẫn chạy lại hai lệnh
0:07:13 - 0:07:21, cài đặt à thư viện ha. Mặc dù thư viện
0:07:18 - 0:07:22, này có cài sẵn rồi nhưng mà do máy ảo.
0:07:21 - 0:07:24, Khi các bạn à tắt máy ảo Docker và các
0:07:22 - 0:07:27, bạn chạy lại đôi khi các bạn sẽ được một
0:07:24 - 0:07:31, cái máy ảo hoàn toàn mới tùy vào các
0:07:27 - 0:07:33, tham số. Đó cả kỹ năng sử dụng Docker
0:07:31 - 0:07:35, cũng là một kiến thức các bạn à nên
0:07:33 - 0:07:40, trang bị. Nó cũng khá hữu ích trong rất
0:07:35 - 0:07:42, nhiều tình huống. Đó, thư viện đã cài
0:07:40 - 0:07:45, sẵn. Thì bây giờ chúng ta chạy
0:07:42 - 0:07:45, file Python mà chúng ta đã tải về hồi
0:07:56 - 0:08:00, nãy.
0:07:58 - 0:08:03, Rồi và đầu tiên các bạn có thể nhận thấy
0:08:00 - 0:08:07, ngay đó là chúng ta đang thực hiện quá
0:08:03 - 0:08:08, trình training nhưng tốc độ nó đang khá
0:08:07 - 0:08:12, chậm. nó lên tới hàng trăm mili giây cho mỗi batch
0:08:08 - 0:08:15, và
0:08:12 - 0:08:17, GPU ở bên này các bạn có thể thấy GPU
0:08:15 - 0:08:20, utilization ở đây
0:08:17 - 0:08:23, chỉ có vài chục phần trăm thôi và còn
0:08:20 - 0:08:27, CPU utilization thì đang đến 80% như vậy
0:08:23 - 0:08:30, có nghĩa là chúng ta vẫn chưa dùng được
0:08:27 - 0:08:34, GPU ha. Đó
0:08:30 - 0:08:34, nếu các bạn quan sát kỹ cái thông báo
0:08:38 - 0:08:44, thông báo lúc mà
0:08:42 - 0:08:47, nếu các bạn quan sát kỹ thông báo lúc
0:08:44 - 0:08:50, trước khi bắt đầu vào quá trình training,
0:08:47 - 0:08:52, các bạn sẽ thấy ở đây một thông báo
0:08:50 - 0:08:55, warning là
0:08:52 - 0:09:00, ignoring visible
0:08:55 - 0:09:03, GPU device ha. có nghĩa là máy tính của
0:09:00 - 0:09:05, chúng ta có cài có cắm GPU sẵn nhưng à
0:09:03 - 0:09:07, TensorFlow mặc định họ chỉ chạy ROCm
0:09:05 - 0:09:11, ROCm TensorFlow ha, mà là một phiên bản TensorFlow khác do
0:09:07 - 0:09:14, AMD họ cung cấp để các bạn sử dụng chung
0:09:11 - 0:09:18, với card của AMD GPU thì họ chỉ hỗ trợ
0:09:14 - 0:09:23, các cái version này thôi đây.
0:09:18 - 0:09:26, Còn version của card 6700XT là version
0:09:23 - 0:09:29, có mã hiệu mặc dù khác nhau chỉ một tí
0:09:26 - 0:09:32, thôi ha. GFX 1031, nhưng phiên bản được hỗ trợ lại là
0:09:29 - 0:09:34, 1030 nên card của chúng ta bị ignore
0:09:32 - 0:09:39, không dùng đến.
0:09:34 - 0:09:41, Muốn sử dụng đến cái
0:09:39 - 0:09:44, card này chúng ta sẽ phải chạy với một
0:09:41 - 0:09:46, cái tham số hay một cái environment
0:09:44 - 0:09:49, variable.
0:09:46 - 0:09:51, Environment variable là các cái biến của
0:09:49 - 0:09:53, hệ điều hành ha. Đây là biến của hệ điều
0:09:51 - 0:09:55, hành không phải là biến trong Python
0:09:53 - 0:09:58, nha. Và các bạn sẽ gán giá trị cho các
0:09:55 - 0:10:01, cái biến này trước khi các bạn chạy lệnh
0:10:01 - 0:10:06, Python. Đó. Ở đây chúng ta sẽ gán
0:10:04 - 0:10:09, override GFX_VERSION à có nghĩa là chúng
0:10:06 - 0:10:11, ta
0:10:09 - 0:10:13, yêu cầu ROCm TensorFlow
0:10:11 - 0:10:15, nhận cái GPU của chúng ta là phiên bản
0:10:13 - 0:10:17, 10.3.0
0:10:15 - 0:10:20, chứ không phải là 10.3.1 như hồi
0:10:17 - 0:10:20, nãy nó nhận ra.
0:10:21 - 0:10:27, Đó.
0:10:24 - 0:10:32, Rồi nếu như chúng ta chạy với tham số
0:10:27 - 0:10:35, này với cái environment variable này thì
0:10:32 - 0:10:37, bây giờ lệnh chạy của chúng ta
0:10:35 - 0:10:40, rồi đã có một chút thay đổi ha. Đó các
0:10:37 - 0:10:42, bạn có thể thấy ở đây thông báo là
0:10:40 - 0:10:45, created device thay vì ignoring device.
0:10:42 - 0:10:48, Và nếu như các bạn chạy thử trên máy
0:10:45 - 0:10:50, mình bây giờ các bạn sẽ thấy máy sẽ bị
0:10:48 - 0:10:53, lag khá đáng kể tại vì GPU đang được
0:10:50 - 0:10:55, huy động.
0:10:53 - 0:10:59, Đó các bạn nhìn bên tay phải ha. À có
0:10:55 - 0:11:03, thể video bây giờ nó sẽ hơi giật tại vì
0:10:59 - 0:11:06, GPU đang được huy động gần như là 100%
0:11:03 - 0:11:08, đó. Và nó xung đột với cái phần mềm thu
0:11:06 - 0:11:11, quay phim ghi hình bài giảng. Nhưng mà bù
0:11:08 - 0:11:15, lại các bạn có thể nhìn thấy thời gian
0:11:11 - 0:11:20, chạy
0:11:15 - 0:11:23, của một batch nó đang a cải thiện khá là
0:11:20 - 0:11:23, nhiều ha. Đó. Rồi chúng ta sẽ tạm à dừng
0:11:23 - 0:11:31, cái
0:11:26 - 0:11:34, việc training model ở đây ha. Đó tại vì
0:11:31 - 0:11:36, à GPU được utilize quá nhiều thì phần
0:11:34 - 0:11:38, giao diện đồ họa mà các bạn làm việc với
0:11:36 - 0:11:41, máy nó cũng sẽ bị ảnh hưởng ha. Do máy
0:11:38 - 0:11:43, chúng ta chỉ có một GPU duy nhất thôi.
0:11:41 - 0:11:47, Nó phải handle quá nhiều công việc. Đó.
0:11:43 - 0:11:49, Đó cũng là nhược điểm giữa GPU của máy
0:11:47 - 0:11:51, tính cá nhân so với các GPU trên server.
0:11:49 - 0:11:53, Trừ khi các bạn có nhiều máy tính thì
0:11:51 - 0:11:55, các bạn dùng riêng hoặc các bạn có máy
0:11:53 - 0:11:58, tính nhiều GPU thì các bạn mới có thể
0:11:55 - 0:12:01, tránh khỏi cái vấn đề này. Thì ở đây các
0:11:58 - 0:12:03, bạn có thể thấy thời gian training cho
0:12:01 - 0:12:05, một batch nó dao động khá là nhiều. Đó
0:12:03 - 0:12:10, do GPU được huy động cho nhiều công việc
0:12:05 - 0:12:14, khác nhau nhưng mà nhìn chung nó nhanh
0:12:10 - 0:12:14, hơn là chúng ta sử dụng so với CPU.
0:12:16 - 0:12:21, Rồi và cuối cùng hình như để
0:12:18 - 0:12:23, cho cái quá trình training này mượt hơn
0:12:21 - 0:12:28, thì các bạn sẽ phải set thêm một cái
0:12:23 - 0:13:03, environment nữa. Environment này là của
0:12:28 - 0:13:05, TensorFlow ha. Đó có nghĩa là TF_FORCE_GPU_ALLOW_GROWTH.
0:13:03 - 0:13:07, Rồi do TensorFlow mặc định khi
0:13:04 - 0:13:10, TensorFlow hoạt động nó sẽ chiếm dụng
0:13:07 - 0:13:12, toàn bộ tài nguyên GPU của máy.
0:13:10 - 0:13:16, Vì thường trên các cái máy server GPU
0:13:12 - 0:13:19, sinh ra chỉ để
0:13:16 - 0:13:22, phục vụ cho các cái hoạt động tính toán
0:13:19 - 0:13:24, nên TensorFlow nó sẽ huy động toàn bộ cái
0:13:22 - 0:13:26, GPU của máy. Còn trên máy tính cá nhân
0:13:24 - 0:13:29, thì các bạn dùng GPU cho nhiều công việc
0:13:26 - 0:13:34, thì các bạn set cái environment này bằng
0:13:29 - 0:13:37, true.
0:13:34 - 0:13:40, GPU allow growth có nghĩa là
0:13:37 - 0:13:42, mặc định TensorFlow sẽ không chiếm dụng
0:13:40 - 0:13:44, toàn bộ GPU mà khi nào nó cần dùng thì
0:13:42 - 0:13:48, nó mới xin cấp phát tài nguyên. Việc này
0:13:44 - 0:13:53, có thể khiến cho cái quá trình training
0:13:48 - 0:13:55, nó chậm đi ha. nhưng mà bù lại nó không
0:13:53 - 0:13:59, ảnh hưởng nhiều so với các cái
0:13:55 - 0:14:03, process khác trên máy.
0:13:59 - 0:14:09, Hi vọng là quá trình chạy với máy tính
0:14:03 - 0:14:13, cá nhân các bạn set cái environment
0:14:09 - 0:14:16, variable này thì quá trình chạy nó sẽ
0:14:13 - 0:14:20, mượt mà hơn. Đó.
0:14:16 - 0:14:23, Rồi và bây giờ các bạn có thể thấy GPU
0:14:20 - 0:14:27, của chúng ta nó cũng đang được huy động
0:14:23 - 0:14:30, khá là nhiều nhưng nó không bị chiếm
0:14:27 - 0:14:34, dụng toàn bộ như lần trước.
0:14:30 - 0:14:37, Và CPU thì đang nghỉ ngơi rất là chill
0:14:34 - 0:14:40, ha. CPU utilization chỉ
0:00:01 - 0:00:16, [âm nhạc]
0:00:13 - 0:00:21, Bây giờ chúng ta sẽ thử chạy
0:00:16 - 0:00:23, trên một cái GPU à gắn với máy tính thật
0:00:21 - 0:00:24, của các bạn, không phải thông qua máy ảo
0:00:23 - 0:00:27, Google Colab. Thì liệu các bạn có thể
0:00:24 - 0:00:30, chạy được những cái chương trình machine
0:00:27 - 0:00:34, learning này hay không? Thì trên nếu hồi
0:00:30 - 0:00:36, nãy các bạn tinh ý thì sẽ thấy trên
0:00:34 - 0:00:39, máy tính
0:00:36 - 0:00:46, của thầy hiện tại cũng có một cái GPU
0:00:39 - 0:00:48, ha. Đó là con AMD Radeon 6700XT.
0:00:46 - 0:00:53, Đó, GPU này thì nó cũng đời cũ rồi, thậm
0:00:48 - 0:00:53, chí nó còn cũ hơn cả con CPU nữa.
0:00:54 - 0:01:01, Nếu chúng ta tra nhanh thử thông tin cái
0:00:57 - 0:01:01, GPU này thì à
0:01:02 - 0:01:08, hiện giờ chắc là chỉ còn những cái trang,
0:01:06 - 0:01:14, những cái shop nào mà họ bán đồ cũ thì
0:01:08 - 0:01:15, may ra họ còn mẫu GPU này thôi ha. Đó.
0:01:14 - 0:01:18, Đây a
0:01:15 - 0:01:23, à shop này cũng còn khá nhiều. Còn một
0:01:18 - 0:01:27, số shop khác thì đây mẫu 6700XT này hiện
0:01:23 - 0:01:29, bán với giá khoảng 7 triệu. Chắc là hàng
0:01:27 - 0:01:31, tồn kho của họ. Còn nếu hàng nếu các bạn
0:01:29 - 0:01:36, mua đồ second-hand thì chắc nó sẽ rẻ
0:01:31 - 0:01:39, hơn nữa ha. Thì GPU này
0:01:36 - 0:01:41, nó có cấu hình cũng a không phải là cao
0:01:39 - 0:01:43, lắm ha.
0:01:41 - 0:01:47, Nếu các bạn đây có thể thấy hình dáng
0:01:43 - 0:01:52, của GPU về thông số thì nó chỉ có 12 GB
0:01:47 - 0:01:54, V RAM thôi, ít hơn cả GPU Tesla T4 mà
0:01:52 - 0:01:58, Google Colab sẽ cung cấp miễn phí của
0:01:54 - 0:02:01, các bạn. Nhưng mẫu GPU này là mẫu GPU
0:01:58 - 0:02:05, cho người dùng cá nhân và thường. Nó
0:02:01 - 0:02:07, hướng đến việc ừ tăng tốc các cái thao tác xử
0:02:05 - 0:02:09, lý liên quan đến đồ họa nhiều hơn là các
0:02:07 - 0:02:11, cái thao tác xử lý tính toán trên máy
0:02:09 - 0:02:13, chủ.
0:02:11 - 0:02:16, Nên nó sẽ yêu cầu nguồn điện cao hơn và
0:02:13 - 0:02:19, tốc độ chạy của nó thì nhiều khi cũng có
0:02:16 - 0:02:22, thể là nhanh hơn Tesla T4 nhưng mà VRAM
0:02:19 - 0:02:24, của nó sẽ hạn chế hơn. Và cái mẫu GPU
0:02:22 - 0:02:27, này thì các bạn không thể gắn nhiều quá
0:02:24 - 0:02:29, nhiều GPU vào cùng một máy như mẫu GPU
0:02:27 - 0:02:33, dành riêng cho server được ha. Trên
0:02:29 - 0:02:35, server một máy chủ có thể gắn đến hàng
0:02:33 - 0:02:37, vài chục ha. Mấy cái nhiều nhất có thể
0:02:35 - 0:02:39, gắn đến khoảng hai mươi mấy cái GPU. Còn
0:02:37 - 0:02:42, nếu trong máy tính cá nhân của các bạn
0:02:39 - 0:02:44, thì thường mỗi máy tính chỉ gắn được một
0:02:42 - 0:02:50, GPU này mà thôi. Đó thì ở đây chúng ta
0:02:44 - 0:02:50, có một GPU duy nhất. GPU này
0:02:51 - 0:02:55, hiện tại cũng đang được sử dụng khá
0:02:52 - 0:02:59, nhiều ha. Đó, đây là GPU duy nhất có
0:02:55 - 0:03:01, trong máy tính nên nó sẽ phải gánh cả
0:03:01 - 0:03:05, các cái ứng dụng đồ họa mà máy đang
0:03:04 - 0:03:07, chạy. Đặc biệt là ứng dụng quay video,
0:03:05 - 0:03:10, bài giảng chẳng hạn thì các bạn thấy
0:03:07 - 0:03:14, VRAM chưa gì là nó đã dùng gần phân nửa
0:03:10 - 0:03:16, rồi đó. Và
0:03:14 - 0:03:19, utilization đang cỡ khoảng 40%.
0:03:16 - 0:03:21, Đây là chỉ là những phần mềm chạy trên
0:03:19 - 0:03:23, máy và để quay video bài giảng này mà
0:03:21 - 0:03:25, thôi ha. Chưa đụng gì đến machine
0:03:23 - 0:03:28, learning. Thì nếu chúng ta cần, chúng ta
0:03:25 - 0:03:31, vẫn có thể chạy
0:03:28 - 0:03:34, cái code machine learning của chúng ta
0:03:31 - 0:03:36, trên con GPU này. Mặc dù nó sẽ không
0:03:34 - 0:03:37, phải là tối ưu như là chạy trên một
0:03:36 - 0:03:41, server đó. Nhưng nếu các bạn biết cách
0:03:37 - 0:03:44, cài đặt các bạn vẫn có thể chạy được.
0:03:41 - 0:03:47, Thì đầu tiên mỗi GPU tùy hãng sản xuất
0:03:44 - 0:03:48, ha, tùy công nghệ mà để chạy các bạn sẽ
0:03:47 - 0:03:50, phải có cách cài đặt TensorFlow khác
0:03:48 - 0:03:52, nhau.
0:03:50 - 0:03:57, Thông thường cách cài đặt dễ nhất nếu
0:03:52 - 0:04:00, các bạn dùng cách cài đặt mặc định này
0:03:57 - 0:04:03, nó chỉ work nếu như các bạn dùng GPU đời
0:04:00 - 0:04:06, mới mà của hãng Nvidia. Còn với hãng AMD
0:04:03 - 0:04:11, thì các bạn sẽ nếu như dùng Docker các
0:04:06 - 0:04:11, bạn sẽ phải sử dụng docker
0:04:18 - 0:04:25, hỗ trợ một cái công nghệ gọi là ROCm
0:04:20 - 0:04:26, [âm nhạc]
0:04:25 - 0:04:31, rồi. ROCm đây là cái
0:04:26 - 0:04:33, Docker
0:04:31 - 0:04:37, Hub image à tức là cái máy ảo chứa cài sẵn
0:04:33 - 0:04:40, TensorFlow và cái thư viện tên là
0:04:37 - 0:04:43, ROCm do AMD họ cung cấp và quản lý.
0:04:40 - 0:04:48, Rồi đây là cái công cụ để giúp TensorFlow
0:04:43 - 0:04:49, chạy được trên những cái GPU do
0:04:48 - 0:04:52, hãng AMD họ phát hành.
0:04:49 - 0:04:55, Thì các bạn sẽ thấy cái lệnh để chạy
0:04:52 - 0:04:59, lệnh Docker run ở đây sẽ có cú pháp phức
0:04:55 - 0:05:03, tạp hơn à tương đối là nhiều so với cái
0:04:59 - 0:05:06, lệnh Docker dùng để chạy trên GPU Nvidia
0:05:03 - 0:05:13, ha. Đó và ở đây thì chúng ta chạy thử
0:05:06 - 0:05:13, thôi. Đó.
0:05:17 - 0:05:24, Rồi và máy này thì đã có chạy trước đó.
0:05:20 - 0:05:26, Rồi lệnh chạy sẽ bắt đầu như thế này ha.
0:05:24 - 0:05:30, Docker run. Rồi chúng ta cũng share cái
0:05:26 - 0:05:34, working directory hiện hành với cái máy
0:05:30 - 0:05:38, ảo. Và đây là các cái thông số à mặc
0:05:34 - 0:05:41, định theo gợi ý của Docker
0:05:38 - 0:05:43, Hub do AMD họ đề xuất. Rồi và chúng ta
0:05:41 - 0:05:48, share cái folder này ha. Chúng ta sẽ
0:05:43 - 0:05:49, chạy một cái terminal bash để chúng ta
0:05:48 - 0:05:51, có thể tương tác với lại cái máy ảo.
0:05:49 - 0:05:53, Sau khi chạy xong thì chắc các bạn còn
0:05:51 - 0:05:55, nhớ công việc đầu tiên chúng ta sẽ phải
0:05:53 - 0:06:03, install hai cái thư viện mà mặc định
0:05:55 - 0:06:06, TensorFlow họ không cung cấp sẵn đó là
0:06:03 - 0:06:08, Matplotlib và tensorflow-datasets.
0:06:06 - 0:06:12, Rồi và máy này cài sẵn rồi thì nên nó
0:06:08 - 0:06:12, chạy cũng khá là nhanh thôi ha.
0:06:13 - 0:06:19, Requirement đều satisfied sẵn.
0:06:16 - 0:06:23, Sau khi cài đặt xong thì
0:06:19 - 0:06:23, à ở đây chúng ta sẽ tạm thời chia màn
0:06:24 - 0:06:32, hình này làm hai phần.
0:06:27 - 0:06:32, một bên để các bạn à quan sát
0:06:37 - 0:06:45, tài nguyên được sử dụng của máy.
0:06:40 - 0:06:48, Đó, bên dưới là tài nguyên được sử dụng
0:06:45 - 0:06:51, của máy hiện hành ha. Và
0:06:48 - 0:06:56, đây là tài nguyên ở phía bên tay phải
0:06:51 - 0:07:01, trái của chúng ta là các cái tài nguyên
0:06:56 - 0:07:05, của GPU ha. Và bên tay phải phía trên là
0:07:01 - 0:07:09, các cái tài nguyên của ừ CPU. Bây giờ
0:07:05 - 0:07:11, chúng ta sẽ chạy lại cái
0:07:09 - 0:07:13, ừ máy ảo này ha. Ờ
0:07:11 - 0:07:18, đầu tiên chúng ta vẫn chạy lại hai lệnh
0:07:13 - 0:07:21, cài đặt à thư viện ha. Mặc dù thư viện
0:07:18 - 0:07:22, này có cài sẵn rồi nhưng mà do máy ảo.
0:07:21 - 0:07:24, Khi các bạn à tắt máy ảo Docker và các
0:07:22 - 0:07:27, bạn chạy lại đôi khi các bạn sẽ được một
0:07:24 - 0:07:31, cái máy ảo hoàn toàn mới tùy vào các
0:07:27 - 0:07:33, tham số. Đó cả kỹ năng sử dụng Docker
0:07:31 - 0:07:35, cũng là một kiến thức các bạn à nên
0:07:33 - 0:07:40, trang bị. Nó cũng khá hữu ích trong rất
0:07:35 - 0:07:42, nhiều tình huống. Đó, thư viện đã cài
0:07:40 - 0:07:45, sẵn. Thì bây giờ chúng ta chạy
0:07:42 - 0:07:45, file Python mà chúng ta đã tải về hồi
0:07:56 - 0:08:00, nãy.
0:07:58 - 0:08:03, Rồi và đầu tiên các bạn có thể nhận thấy
0:08:00 - 0:08:07, ngay đó là chúng ta đang thực hiện quá
0:08:03 - 0:08:08, trình training nhưng tốc độ nó đang khá
0:08:07 - 0:08:12, chậm. nó lên tới hàng trăm mili giây cho mỗi batch
0:08:08 - 0:08:15, và
0:08:12 - 0:08:17, GPU ở bên này các bạn có thể thấy GPU
0:08:15 - 0:08:20, utilization ở đây
0:08:17 - 0:08:23, chỉ có vài chục phần trăm thôi và còn
0:08:20 - 0:08:27, CPU utilization thì đang đến 80% như vậy
0:08:23 - 0:08:30, có nghĩa là chúng ta vẫn chưa dùng được
0:08:27 - 0:08:34, GPU ha. Đó
0:08:30 - 0:08:34, nếu các bạn quan sát kỹ cái thông báo
0:08:38 - 0:08:44, thông báo lúc mà
0:08:42 - 0:08:47, nếu các bạn quan sát kỹ thông báo lúc
0:08:44 - 0:08:50, trước khi bắt đầu vào quá trình training,
0:08:47 - 0:08:52, các bạn sẽ thấy ở đây một thông báo
0:08:50 - 0:08:55, warning là
0:08:52 - 0:09:00, ignoring visible
0:08:55 - 0:09:03, GPU device ha. có nghĩa là máy tính của
0:09:00 - 0:09:05, chúng ta có cài có cắm GPU sẵn nhưng à
0:09:03 - 0:09:07, TensorFlow mặc định họ chỉ chạy ROCm
0:09:05 - 0:09:11, ROCm TensorFlow ha, mà là một phiên bản TensorFlow khác do
0:09:07 - 0:09:14, AMD họ cung cấp để các bạn sử dụng chung
0:09:11 - 0:09:18, với card của AMD GPU thì họ chỉ hỗ trợ
0:09:14 - 0:09:23, các cái version này thôi đây.
0:09:18 - 0:09:26, Còn version của card 6700XT là version
0:09:23 - 0:09:29, có mã hiệu mặc dù khác nhau chỉ một tí
0:09:26 - 0:09:32, thôi ha. GFX 1031, nhưng phiên bản được hỗ trợ lại là
0:09:29 - 0:09:34, 1030 nên card của chúng ta bị ignore
0:09:32 - 0:09:39, không dùng đến.
0:09:34 - 0:09:41, Muốn sử dụng đến cái
0:09:39 - 0:09:44, card này chúng ta sẽ phải chạy với một
0:09:41 - 0:09:46, cái tham số hay một cái environment
0:09:44 - 0:09:49, variable.
0:09:46 - 0:09:51, Environment variable là các cái biến của
0:09:49 - 0:09:53, hệ điều hành ha. Đây là biến của hệ điều
0:09:51 - 0:09:55, hành không phải là biến trong Python
0:09:53 - 0:09:58, nha. Và các bạn sẽ gán giá trị cho các
0:09:55 - 0:10:01, cái biến này trước khi các bạn chạy lệnh
0:10:01 - 0:10:06, Python. Đó. Ở đây chúng ta sẽ gán
0:10:04 - 0:10:09, override GFX_VERSION à có nghĩa là chúng
0:10:06 - 0:10:11, ta
0:10:09 - 0:10:13, yêu cầu ROCm TensorFlow
0:10:11 - 0:10:15, nhận cái GPU của chúng ta là phiên bản
0:10:13 - 0:10:17, 10.3.0
0:10:15 - 0:10:20, chứ không phải là 10.3.1 như hồi
0:10:17 - 0:10:20, nãy nó nhận ra.
0:10:21 - 0:10:27, Đó.
0:10:24 - 0:10:32, Rồi nếu như chúng ta chạy với tham số
0:10:27 - 0:10:35, này với cái environment variable này thì
0:10:32 - 0:10:37, bây giờ lệnh chạy của chúng ta
0:10:35 - 0:10:40, rồi đã có một chút thay đổi ha. Đó các
0:10:37 - 0:10:42, bạn có thể thấy ở đây thông báo là
0:10:40 - 0:10:45, created device thay vì ignoring device.
0:10:42 - 0:10:48, Và nếu như các bạn chạy thử trên máy
0:10:45 - 0:10:50, mình bây giờ các bạn sẽ thấy máy sẽ bị
0:10:48 - 0:10:53, lag khá đáng kể tại vì GPU đang được
0:10:50 - 0:10:55, huy động.
0:10:53 - 0:10:59, Đó các bạn nhìn bên tay phải ha. À có
0:10:55 - 0:11:03, thể video bây giờ nó sẽ hơi giật tại vì
0:10:59 - 0:11:06, GPU đang được huy động gần như là 100%
0:11:03 - 0:11:08, đó. Và nó xung đột với cái phần mềm thu
0:11:06 - 0:11:11, quay phim ghi hình bài giảng. Nhưng mà bù
0:11:08 - 0:11:15, lại các bạn có thể nhìn thấy thời gian
0:11:11 - 0:11:20, chạy
0:11:15 - 0:11:23, của một batch nó đang a cải thiện khá là
0:11:20 - 0:11:23, nhiều ha. Đó. Rồi chúng ta sẽ tạm à dừng
0:11:23 - 0:11:31, cái
0:11:26 - 0:11:34, việc training model ở đây ha. Đó tại vì
0:11:31 - 0:11:36, à GPU được utilize quá nhiều thì phần
0:11:34 - 0:11:38, giao diện đồ họa mà các bạn làm việc với
0:11:36 - 0:11:41, máy nó cũng sẽ bị ảnh hưởng ha. Do máy
0:11:38 - 0:11:43, chúng ta chỉ có một GPU duy nhất thôi.
0:11:41 - 0:11:47, Nó phải handle quá nhiều công việc. Đó.
0:11:43 - 0:11:49, Đó cũng là nhược điểm giữa GPU của máy
0:11:47 - 0:11:51, tính cá nhân so với các GPU trên server.
0:11:49 - 0:11:53, Trừ khi các bạn có nhiều máy tính thì
0:11:51 - 0:11:55, các bạn dùng riêng hoặc các bạn có máy
0:11:53 - 0:11:58, tính nhiều GPU thì các bạn mới có thể
0:11:55 - 0:12:01, tránh khỏi cái vấn đề này. Thì ở đây các
0:11:58 - 0:12:03, bạn có thể thấy thời gian training cho
0:12:01 - 0:12:05, một batch nó dao động khá là nhiều. Đó
0:12:03 - 0:12:10, do GPU được huy động cho nhiều công việc
0:12:05 - 0:12:14, khác nhau nhưng mà nhìn chung nó nhanh
0:12:10 - 0:12:14, hơn là chúng ta sử dụng so với CPU.
0:12:16 - 0:12:21, Rồi và cuối cùng hình như để
0:12:18 - 0:12:23, cho cái quá trình training này mượt hơn
0:12:21 - 0:12:28, thì các bạn sẽ phải set thêm một cái
0:12:23 - 0:13:03, environment nữa. Environment này là của
0:12:28 - 0:13:05, TensorFlow ha. Đó có nghĩa là TF_FORCE_GPU_ALLOW_GROWTH.
0:13:03 - 0:13:07, Rồi do TensorFlow mặc định khi
0:13:04 - 0:13:10, TensorFlow hoạt động nó sẽ chiếm dụng
0:13:07 - 0:13:12, toàn bộ tài nguyên GPU của máy.
0:13:10 - 0:13:16, Vì thường trên các cái máy server GPU
0:13:12 - 0:13:19, sinh ra chỉ để
0:13:16 - 0:13:22, phục vụ cho các cái hoạt động tính toán
0:13:19 - 0:13:24, nên TensorFlow nó sẽ huy động toàn bộ cái
0:13:22 - 0:13:26, GPU của máy. Còn trên máy tính cá nhân
0:13:24 - 0:13:29, thì các bạn dùng GPU cho nhiều công việc
0:13:26 - 0:13:34, thì các bạn set cái environment này bằng
0:13:29 - 0:13:37, true.
0:13:34 - 0:13:40, GPU allow growth có nghĩa là
0:13:37 - 0:13:42, mặc định TensorFlow sẽ không chiếm dụng
0:13:40 - 0:14:45, toàn bộ GPU mà khi nào nó cần dùng thì
0:13:42 - 0:14:48, nó mới xin cấp phát tài nguyên. Việc này
0:13:44 - 0:14:53, có thể khiến cho cái quá trình training
0:13:48 - 0:14:55, nó chậm đi ha. nhưng mà bù lại nó không
0:14:53 - 0:14:59, ảnh hưởng nhiều so với các cái
0:14:55 - 0:15:03, process khác trên máy.
0:14:59 - 0:15:09, Hi vọng là quá trình chạy với máy tính
0:15:03 - 0:15:13, cá nhân các bạn set cái environment
0:15:09 - 0:15:16, variable này thì quá trình chạy nó sẽ
0:15:13 - 0:15:20, mượt mà hơn. Đó.
0:15:16 - 0:15:23, Rồi và bây giờ các bạn có thể thấy GPU
0:15:20 - 0:15:27, của chúng ta nó cũng đang được huy động
0:15:23 - 0:15:30, khá là nhiều nhưng nó không bị chiếm
0:15:27 - 0:15:34, dụng toàn bộ như lần trước.
0:15:30 - 0:15:37, Và CPU thì đang nghỉ ngơi rất là chill
0:15:34 - 0:15:40, ha. CPU utilization chỉ
0:15:37 - 0:15:42, loanh quanh đâu đó cỡ 15% thôi. Chủ yếu
0:15:40 - 0:15:44, là để lấy dữ liệu và đưa cho
0:15:42 - 0:15:48, GPU làm việc. Trong khi đó con Ryzen 5950X nó
0:15:44 - 0:14:53, đang khá là chill. À còn con 6700XT của
0:14:48 - 0:14:55, chúng ta thì đấy các bạn thấy chỗ GFX à
0:14:53 - 0:14:59, utilization này nó lên tới khoảng 90%.
0:14:55 - 0:15:03, Nó đang làm việc à rất là vất vả
0:14:59 - 0:15:09, nhưng mà bù lại đó. Nếu các bạn quan sát
0:15:03 - 0:15:13, thời gian chạy cho mỗi batch cũng như
0:15:09 - 0:15:16, thời gian chạy cho toàn bộ một vòng lập
0:15:13 - 0:15:20, một epoch trong quá trình training nó đã
0:15:16 - 0:15:23, giảm đi đáng kể.
0:15:20 - 0:15:27, Đó với ở đây chúng ta thấy có một số epoch
0:15:23 - 0:15:29, chạy nhanh nhất thì nó chỉ khoảng 14
0:15:27 - 0:15:31, giây thôi.
0:15:29 - 0:15:34, Epoch đầu tiên thì luôn luôn là lâu do máy
0:15:31 - 0:15:35, phải chuẩn bị dữ liệu. Còn các epoch sau
0:15:34 - 0:15:39, thì các bạn thấy thường chạy rất là ổn
0:15:35 - 0:15:41, định, chỉ khoảng 14 giây cho một epoch
0:15:39 - 0:15:46, trong khi nếu các bạn còn nhớ với GPU ha
0:15:41 - 0:15:48, cũng là GPU Tesla T4 mà Nvidia cung cấp
0:15:46 - 0:15:50, cho các bạn thì thời gian cho một epoch
0:15:48 - 0:15:52, thường khoảng 50 giây. Đó như vậy cái
0:15:50 - 0:15:55, GPU dân dụng của chúng ta, cái GPU cho
0:15:52 - 0:15:58, người dùng cá nhân con 6700XT
0:15:55 - 0:16:01, đó à cỡ 7 triệu mấy này nó chạy nhanh
0:15:58 - 0:16:05, gần gấp ba lần
0:16:01 - 0:16:07, GPU của Google Colab cung cấp ha. Nếu
0:16:05 - 0:16:08, các bạn biết cách setup, cài đặt và sử
0:16:07 - 0:16:11, dụng thì các bạn có thể sử dụng GPU trên
0:16:08 - 0:16:14, máy tính cá nhân của mình.
0:16:11 - 0:16:16, Nhưng mà không phải máy tính cá nhân của
0:16:14 - 0:16:19, ai cũng có GPU này và không phải GPU nào
0:16:16 - 0:16:21, cũng có thể hỗ trợ quá trình training
0:16:19 - 0:16:24, nhé các bạn. Đó, các bạn sẽ phải
0:16:21 - 0:16:26, học hỏi và làm quen với khá nhiều kiến
0:16:24 - 0:16:32, thức mới nếu như các bạn muốn sử dụng
0:16:26 - 0:16:32, máy của mình cho các cái hoạt động liên
0:16:36 - 0:16:48, quan đến machine learning. Bù lại các
0:16:36 - 0:16:48, bạn có thể có cái máy nó chạy nhanh hơn
0:16:36 - 0:16:48, là cái phiên bản default miễn phí trên
0:16:36 - 0:16:48, Google Colab ha. Thì trong môn này các
0:16:36 - 0:16:48, bạn có thể sử dụng phương pháp nào cũng
0:16:36 - 0:16:48, được ha. Các bạn có thể sử dụng Google
0:16:36 - 0:16:48, Colab cho nó đơn giản để chúng ta làm
0:16:36 - 0:16:48, quen với bài học. Và nếu muốn thì các
0:16:36 - 0:16:48, bạn hoàn toàn vẫn có thể chạy cái chương
0:16:36 - 0:16:48, trình Python này trên máy của mình.
0:16:36 - 0:16:48, Trong các bài tiếp theo, chúng ta sẽ đi
0:16:36 - 0:16:48, sâu hơn về ngôn ngữ lập trình Python. để
0:16:36 - 0:16:48, giúp các bạn có thể tự tin làm chủ ngôn
0:16:36 - 0:16:48, ngữ này cho những bài học sắp tới.
0:16:36 - 0:16:48, [âm nhạc]