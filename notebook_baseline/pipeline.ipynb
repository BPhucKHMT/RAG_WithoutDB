{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e90eda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\ADMIN\\anaconda3\\envs\\Phuc1\\Lib\\site-packages\\~-mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\ADMIN\\anaconda3\\envs\\Phuc1\\Lib\\site-packages\\~-mpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "easyocr 1.7.2 requires ninja, which is not installed.\n",
      "easyocr 1.7.2 requires pyclipper, which is not installed.\n",
      "easyocr 1.7.2 requires python-bidi, which is not installed.\n",
      "easyocr 1.7.2 requires scikit-image, which is not installed.\n",
      "easyocr 1.7.2 requires Shapely, which is not installed.\n",
      "plotly 6.4.0 requires narwhals>=1.15.1, which is not installed.\n",
      "kubernetes 34.1.0 requires urllib3<2.4.0,>=1.24.2, but you have urllib3 2.5.0 which is incompatible.\n",
      "langchain-community 0.3.24 requires langsmith<0.4,>=0.1.125, but you have langsmith 0.4.37 which is incompatible.\n",
      "langchain-google-genai 2.1.12 requires google-ai-generativelanguage<1,>=0.7, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\n",
      "langchainhub 0.1.21 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (0.48.2)\n",
      "Requirement already satisfied: torch<3,>=2.3 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from bitsandbytes) (2.9.1+cu126)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from bitsandbytes) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from bitsandbytes) (25.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from torch<3,>=2.3->bitsandbytes) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from torch<3,>=2.3->bitsandbytes) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from torch<3,>=2.3->bitsandbytes) (2025.10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (2.1.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\ADMIN\\anaconda3\\envs\\Phuc1\\Lib\\site-packages\\~.rch'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "easyocr 1.7.2 requires ninja, which is not installed.\n",
      "easyocr 1.7.2 requires pyclipper, which is not installed.\n",
      "easyocr 1.7.2 requires python-bidi, which is not installed.\n",
      "easyocr 1.7.2 requires scikit-image, which is not installed.\n",
      "easyocr 1.7.2 requires Shapely, which is not installed.\n",
      "plotly 6.4.0 requires narwhals>=1.15.1, which is not installed.\n",
      "kubernetes 34.1.0 requires urllib3<2.4.0,>=1.24.2, but you have urllib3 2.5.0 which is incompatible.\n",
      "langchain-community 0.3.24 requires langsmith<0.4,>=0.1.125, but you have langsmith 0.4.37 which is incompatible.\n",
      "langchain-google-genai 2.1.12 requires google-ai-generativelanguage<1,>=0.7, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\n",
      "langchainhub 0.1.21 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
      "tokenizers 0.21.4 requires huggingface-hub<1.0,>=0.16.4, but you have huggingface-hub 1.1.4 which is incompatible.\n",
      "transformers 4.52.4 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.1.4 which is incompatible.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "easyocr 1.7.2 requires ninja, which is not installed.\n",
      "easyocr 1.7.2 requires pyclipper, which is not installed.\n",
      "easyocr 1.7.2 requires python-bidi, which is not installed.\n",
      "easyocr 1.7.2 requires scikit-image, which is not installed.\n",
      "easyocr 1.7.2 requires Shapely, which is not installed.\n",
      "plotly 6.4.0 requires narwhals>=1.15.1, which is not installed.\n",
      "kubernetes 34.1.0 requires urllib3<2.4.0,>=1.24.2, but you have urllib3 2.5.0 which is incompatible.\n",
      "langchain-google-genai 2.1.12 requires google-ai-generativelanguage<1,>=0.7, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\n",
      "langchainhub 0.1.21 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
      "tokenizers 0.21.4 requires huggingface-hub<1.0,>=0.16.4, but you have huggingface-hub 1.1.4 which is incompatible.\n",
      "transformers 4.52.4 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.1.4 which is incompatible.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "plotly 6.4.0 requires narwhals>=1.15.1, which is not installed.\n",
      "kubernetes 34.1.0 requires urllib3<2.4.0,>=1.24.2, but you have urllib3 2.5.0 which is incompatible.\n",
      "langchain-google-genai 2.1.12 requires google-ai-generativelanguage<1,>=0.7, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\n",
      "tokenizers 0.21.4 requires huggingface-hub<1.0,>=0.16.4, but you have huggingface-hub 1.1.4 which is incompatible.\n",
      "transformers 4.52.4 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.1.4 which is incompatible.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "easyocr 1.7.2 requires ninja, which is not installed.\n",
      "easyocr 1.7.2 requires pyclipper, which is not installed.\n",
      "easyocr 1.7.2 requires python-bidi, which is not installed.\n",
      "easyocr 1.7.2 requires scikit-image, which is not installed.\n",
      "easyocr 1.7.2 requires Shapely, which is not installed.\n",
      "plotly 6.4.0 requires narwhals>=1.15.1, which is not installed.\n",
      "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.1 which is incompatible.\n",
      "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.33.1 which is incompatible.\n",
      "langchain 0.3.25 requires langchain-core<1.0.0,>=0.3.58, but you have langchain-core 1.0.5 which is incompatible.\n",
      "langchain 0.3.25 requires langsmith<0.4,>=0.1.17, but you have langsmith 0.4.43 which is incompatible.\n",
      "langchain-community 0.3.24 requires langchain-core<1.0.0,>=0.3.59, but you have langchain-core 1.0.5 which is incompatible.\n",
      "langchain-community 0.3.24 requires langsmith<0.4,>=0.1.125, but you have langsmith 0.4.43 which is incompatible.\n",
      "langchain-experimental 0.3.4 requires langchain-core<0.4.0,>=0.3.28, but you have langchain-core 1.0.5 which is incompatible.\n",
      "langchain-google-genai 2.1.12 requires google-ai-generativelanguage<1,>=0.7, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\n",
      "langchain-groq 0.3.8 requires langchain-core<1.0.0,>=0.3.75, but you have langchain-core 1.0.5 which is incompatible.\n",
      "langchain-huggingface 0.2.0 requires langchain-core<1.0.0,>=0.3.59, but you have langchain-core 1.0.5 which is incompatible.\n",
      "langchain-openai 0.3.35 requires langchain-core<1.0.0,>=0.3.78, but you have langchain-core 1.0.5 which is incompatible.\n",
      "langchainhub 0.1.21 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
      "transformers 4.52.4 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.1.4 which is incompatible.\n",
      "transformers 4.52.4 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.22.1 which is incompatible.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "easyocr 1.7.2 requires ninja, which is not installed.\n",
      "easyocr 1.7.2 requires pyclipper, which is not installed.\n",
      "easyocr 1.7.2 requires python-bidi, which is not installed.\n",
      "easyocr 1.7.2 requires scikit-image, which is not installed.\n",
      "easyocr 1.7.2 requires Shapely, which is not installed.\n",
      "plotly 6.4.0 requires narwhals>=1.15.1, which is not installed.\n",
      "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.33.1 which is incompatible.\n",
      "kubernetes 34.1.0 requires urllib3<2.4.0,>=1.24.2, but you have urllib3 2.5.0 which is incompatible.\n",
      "langchain-google-genai 2.1.12 requires google-ai-generativelanguage<1,>=0.7, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\n",
      "langchainhub 0.1.21 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
      "transformers 4.52.4 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.1.4 which is incompatible.\n",
      "transformers 4.52.4 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.22.1 which is incompatible.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "easyocr 1.7.2 requires ninja, which is not installed.\n",
      "easyocr 1.7.2 requires pyclipper, which is not installed.\n",
      "easyocr 1.7.2 requires python-bidi, which is not installed.\n",
      "easyocr 1.7.2 requires scikit-image, which is not installed.\n",
      "easyocr 1.7.2 requires Shapely, which is not installed.\n",
      "plotly 6.4.0 requires narwhals>=1.15.1, which is not installed.\n",
      "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.33.1 which is incompatible.\n",
      "kubernetes 34.1.0 requires urllib3<2.4.0,>=1.24.2, but you have urllib3 2.5.0 which is incompatible.\n",
      "langchain-google-genai 2.1.12 requires google-ai-generativelanguage<1,>=0.7, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\n",
      "langchainhub 0.1.21 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
      "transformers 4.52.4 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.1.4 which is incompatible.\n",
      "transformers 4.52.4 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.22.1 which is incompatible.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "easyocr 1.7.2 requires ninja, which is not installed.\n",
      "easyocr 1.7.2 requires pyclipper, which is not installed.\n",
      "easyocr 1.7.2 requires python-bidi, which is not installed.\n",
      "easyocr 1.7.2 requires scikit-image, which is not installed.\n",
      "easyocr 1.7.2 requires Shapely, which is not installed.\n",
      "plotly 6.4.0 requires narwhals>=1.15.1, which is not installed.\n",
      "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.33.1 which is incompatible.\n",
      "kubernetes 34.1.0 requires urllib3<2.4.0,>=1.24.2, but you have urllib3 2.5.0 which is incompatible.\n",
      "langchain-community 0.3.24 requires langsmith<0.4,>=0.1.125, but you have langsmith 0.4.43 which is incompatible.\n",
      "langchain-google-genai 2.1.12 requires google-ai-generativelanguage<1,>=0.7, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\n",
      "langchainhub 0.1.21 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.33.1 which is incompatible.\n",
      "langchain-google-genai 2.1.12 requires google-ai-generativelanguage<1,>=0.7, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_openai in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (0.3.35)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.78 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from langchain_openai) (0.3.79)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.104.2 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from langchain_openai) (2.7.1)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from langchain_openai) (0.12.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (0.4.43)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (1.33)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (6.0.3)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (4.15.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (2.12.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.78->langchain_openai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (0.11.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.78->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.78->langchain_openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.78->langchain_openai) (0.4.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2025.11.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.104.2->langchain_openai) (0.4.6)\n",
      "Requirement already satisfied: langchain-google-genai in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (2.1.12)\n",
      "Requirement already satisfied: langchain-core>=0.3.75 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from langchain-google-genai) (0.3.79)\n",
      "Collecting google-ai-generativelanguage<1,>=0.7 (from langchain-google-genai)\n",
      "  Using cached google_ai_generativelanguage-0.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pydantic<3,>=2 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from langchain-google-genai) (2.12.4)\n",
      "Requirement already satisfied: filetype<2,>=1.2 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.28.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.43.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.76.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (6.33.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.72.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.32.5)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: typing-extensions~=4.12 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from grpcio<2.0.0,>=1.33.2->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (4.15.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai)\n",
      "  Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2025.11.12)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (0.6.1)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from langchain-core>=0.3.75->langchain-google-genai) (0.4.43)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from langchain-core>=0.3.75->langchain-google-genai) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from langchain-core>=0.3.75->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from langchain-core>=0.3.75->langchain-google-genai) (6.0.3)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from langchain-core>=0.3.75->langchain-google-genai) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.3.75->langchain-google-genai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (0.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (1.3.1)\n",
      "Using cached google_ai_generativelanguage-0.9.0-py3-none-any.whl (1.4 MB)\n",
      "Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Installing collected packages: protobuf, google-ai-generativelanguage\n",
      "\n",
      "  Attempting uninstall: protobuf\n",
      "\n",
      "    Found existing installation: protobuf 6.33.1\n",
      "\n",
      "    Uninstalling protobuf-6.33.1:\n",
      "\n",
      "      Successfully uninstalled protobuf-6.33.1\n",
      "\n",
      "   ---------------------------------------- 0/2 [protobuf]\n",
      "  Attempting uninstall: google-ai-generativelanguage\n",
      "   ---------------------------------------- 0/2 [protobuf]\n",
      "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
      "   ---------------------------------------- 0/2 [protobuf]\n",
      "   -------------------- ------------------- 1/2 [google-ai-generativelanguage]\n",
      "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
      "   -------------------- ------------------- 1/2 [google-ai-generativelanguage]\n",
      "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
      "   -------------------- ------------------- 1/2 [google-ai-generativelanguage]\n",
      "   -------------------- ------------------- 1/2 [google-ai-generativelanguage]\n",
      "   -------------------- ------------------- 1/2 [google-ai-generativelanguage]\n",
      "   -------------------- ------------------- 1/2 [google-ai-generativelanguage]\n",
      "   -------------------- ------------------- 1/2 [google-ai-generativelanguage]\n",
      "   -------------------- ------------------- 1/2 [google-ai-generativelanguage]\n",
      "   -------------------- ------------------- 1/2 [google-ai-generativelanguage]\n",
      "   -------------------- ------------------- 1/2 [google-ai-generativelanguage]\n",
      "   -------------------- ------------------- 1/2 [google-ai-generativelanguage]\n",
      "   -------------------- ------------------- 1/2 [google-ai-generativelanguage]\n",
      "   ---------------------------------------- 2/2 [google-ai-generativelanguage]\n",
      "\n",
      "Successfully installed google-ai-generativelanguage-0.9.0 protobuf-5.29.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.9.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rank_bm25 in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\anaconda3\\envs\\phuc1\\lib\\site-packages (from rank_bm25) (2.2.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q --force transformers==4.52.4\n",
    "!pip install -U bitsandbytes\n",
    "!pip install -q --force accelerate==1.7.0\n",
    "!pip install -q --force langchain==0.3.25\n",
    "!pip install -q --force langchainhub==0.1.21\n",
    "!pip install -q --force langchain-chroma==0.2.4\n",
    "!pip install -q --force langchain_experimental==0.3.4\n",
    "!pip install -q --force langchain-community==0.3.24\n",
    "!pip install -q --force langchain_huggingface==0.2.0\n",
    "!pip install -q --force python-dotenv==1.1.0\n",
    "!pip install -q --force pypdf\n",
    "!pip install langchain_openai\n",
    "!pip install langchain-google-genai\n",
    "!pip install rank_bm25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa729a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu126\n",
      "Requirement already satisfied: torch in c:\\users\\admin\\anaconda3\\lib\\site-packages (2.9.0)\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu126/torchvision-0.24.1%2Bcu126-cp312-cp312-win_amd64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu126/torch-2.9.1%2Bcu126-cp312-cp312-win_amd64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Downloading https://download.pytorch.org/whl/cu126/torchvision-0.24.1%2Bcu126-cp312-cp312-win_amd64.whl (8.8 MB)\n",
      "   ---------------------------------------- 0.0/8.8 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.0/8.8 MB 10.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.8/8.8 MB 22.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.8/8.8 MB 21.8 MB/s eta 0:00:00\n",
      "Downloading https://download.pytorch.org/whl/cu126/torch-2.9.1%2Bcu126-cp312-cp312-win_amd64.whl (2584.5 MB)\n",
      "   ---------------------------------------- 0.0/2.6 GB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.6 GB 29.3 MB/s eta 0:01:29\n",
      "   ---------------------------------------- 0.0/2.6 GB 28.3 MB/s eta 0:01:31\n",
      "   ---------------------------------------- 0.0/2.6 GB 24.1 MB/s eta 0:01:47\n",
      "   ---------------------------------------- 0.0/2.6 GB 23.5 MB/s eta 0:01:49\n",
      "   ---------------------------------------- 0.0/2.6 GB 23.5 MB/s eta 0:01:50\n",
      "   ---------------------------------------- 0.0/2.6 GB 24.5 MB/s eta 0:01:45\n",
      "    --------------------------------------- 0.0/2.6 GB 24.3 MB/s eta 0:01:46\n",
      "    --------------------------------------- 0.0/2.6 GB 22.7 MB/s eta 0:01:52\n",
      "    --------------------------------------- 0.0/2.6 GB 23.6 MB/s eta 0:01:48\n",
      "    --------------------------------------- 0.0/2.6 GB 23.1 MB/s eta 0:01:50\n",
      "    --------------------------------------- 0.1/2.6 GB 23.3 MB/s eta 0:01:49\n",
      "    --------------------------------------- 0.1/2.6 GB 21.8 MB/s eta 0:01:56\n",
      "    --------------------------------------- 0.1/2.6 GB 21.2 MB/s eta 0:02:00\n",
      "    --------------------------------------- 0.1/2.6 GB 21.3 MB/s eta 0:01:59\n",
      "   - -------------------------------------- 0.1/2.6 GB 21.1 MB/s eta 0:02:00\n",
      "   - -------------------------------------- 0.1/2.6 GB 21.0 MB/s eta 0:02:00\n",
      "   - -------------------------------------- 0.1/2.6 GB 21.4 MB/s eta 0:01:58\n",
      "   - -------------------------------------- 0.1/2.6 GB 21.2 MB/s eta 0:01:59\n",
      "   - -------------------------------------- 0.1/2.6 GB 20.9 MB/s eta 0:02:00\n",
      "   - -------------------------------------- 0.1/2.6 GB 20.8 MB/s eta 0:02:00\n",
      "   - -------------------------------------- 0.1/2.6 GB 21.2 MB/s eta 0:01:58\n",
      "   - -------------------------------------- 0.1/2.6 GB 21.5 MB/s eta 0:01:56\n",
      "   - -------------------------------------- 0.1/2.6 GB 21.1 MB/s eta 0:01:58\n",
      "   - -------------------------------------- 0.1/2.6 GB 20.8 MB/s eta 0:02:00\n",
      "   - -------------------------------------- 0.1/2.6 GB 20.6 MB/s eta 0:02:01\n",
      "   - -------------------------------------- 0.1/2.6 GB 20.4 MB/s eta 0:02:02\n",
      "   - -------------------------------------- 0.1/2.6 GB 20.4 MB/s eta 0:02:02\n",
      "   - -------------------------------------- 0.1/2.6 GB 20.2 MB/s eta 0:02:02\n",
      "   - -------------------------------------- 0.1/2.6 GB 20.5 MB/s eta 0:02:01\n",
      "   - -------------------------------------- 0.1/2.6 GB 20.5 MB/s eta 0:02:00\n",
      "   -- ------------------------------------- 0.1/2.6 GB 20.4 MB/s eta 0:02:00\n",
      "   -- ------------------------------------- 0.1/2.6 GB 20.4 MB/s eta 0:02:00\n",
      "   -- ------------------------------------- 0.1/2.6 GB 20.6 MB/s eta 0:01:59\n",
      "   -- ------------------------------------- 0.1/2.6 GB 20.6 MB/s eta 0:01:59\n",
      "   -- ------------------------------------- 0.1/2.6 GB 20.6 MB/s eta 0:01:58\n",
      "   -- ------------------------------------- 0.2/2.6 GB 20.7 MB/s eta 0:01:58\n",
      "   -- ------------------------------------- 0.2/2.6 GB 20.9 MB/s eta 0:01:56\n",
      "   -- ------------------------------------- 0.2/2.6 GB 21.2 MB/s eta 0:01:55\n",
      "   -- ------------------------------------- 0.2/2.6 GB 21.1 MB/s eta 0:01:55\n",
      "   -- ------------------------------------- 0.2/2.6 GB 21.3 MB/s eta 0:01:54\n",
      "   -- ------------------------------------- 0.2/2.6 GB 21.3 MB/s eta 0:01:53\n",
      "   -- ------------------------------------- 0.2/2.6 GB 21.1 MB/s eta 0:01:54\n",
      "   -- ------------------------------------- 0.2/2.6 GB 21.0 MB/s eta 0:01:55\n",
      "   -- ------------------------------------- 0.2/2.6 GB 20.9 MB/s eta 0:01:55\n",
      "   --- ------------------------------------ 0.2/2.6 GB 20.9 MB/s eta 0:01:55\n",
      "   --- ------------------------------------ 0.2/2.6 GB 20.8 MB/s eta 0:01:55\n",
      "   --- ------------------------------------ 0.2/2.6 GB 20.7 MB/s eta 0:01:56\n",
      "   --- ------------------------------------ 0.2/2.6 GB 20.5 MB/s eta 0:01:57\n",
      "   --- ------------------------------------ 0.2/2.6 GB 20.1 MB/s eta 0:01:59\n",
      "   --- ------------------------------------ 0.2/2.6 GB 19.9 MB/s eta 0:02:00\n",
      "   --- ------------------------------------ 0.2/2.6 GB 19.7 MB/s eta 0:02:01\n",
      "   --- ------------------------------------ 0.2/2.6 GB 19.7 MB/s eta 0:02:01\n",
      "   --- ------------------------------------ 0.2/2.6 GB 19.6 MB/s eta 0:02:01\n",
      "   --- ------------------------------------ 0.2/2.6 GB 19.6 MB/s eta 0:02:01\n",
      "   --- ------------------------------------ 0.2/2.6 GB 19.4 MB/s eta 0:02:02\n",
      "   --- ------------------------------------ 0.2/2.6 GB 19.3 MB/s eta 0:02:03\n",
      "   --- ------------------------------------ 0.2/2.6 GB 19.2 MB/s eta 0:02:03\n",
      "   --- ------------------------------------ 0.2/2.6 GB 19.2 MB/s eta 0:02:03\n",
      "   --- ------------------------------------ 0.2/2.6 GB 19.2 MB/s eta 0:02:03\n",
      "   --- ------------------------------------ 0.2/2.6 GB 19.2 MB/s eta 0:02:02\n",
      "   --- ------------------------------------ 0.2/2.6 GB 19.2 MB/s eta 0:02:02\n",
      "   --- ------------------------------------ 0.2/2.6 GB 19.3 MB/s eta 0:02:02\n",
      "   --- ------------------------------------ 0.3/2.6 GB 19.3 MB/s eta 0:02:01\n",
      "   --- ------------------------------------ 0.3/2.6 GB 19.4 MB/s eta 0:02:01\n",
      "   ---- ----------------------------------- 0.3/2.6 GB 19.4 MB/s eta 0:02:00\n",
      "   ---- ----------------------------------- 0.3/2.6 GB 19.3 MB/s eta 0:02:01\n",
      "   ---- ----------------------------------- 0.3/2.6 GB 19.3 MB/s eta 0:02:01\n",
      "   ---- ----------------------------------- 0.3/2.6 GB 19.2 MB/s eta 0:02:01\n",
      "   ---- ----------------------------------- 0.3/2.6 GB 19.2 MB/s eta 0:02:00\n",
      "   ---- ----------------------------------- 0.3/2.6 GB 19.1 MB/s eta 0:02:01\n",
      "   ---- ----------------------------------- 0.3/2.6 GB 18.9 MB/s eta 0:02:02\n",
      "   ---- ----------------------------------- 0.3/2.6 GB 18.9 MB/s eta 0:02:02\n",
      "   ---- ----------------------------------- 0.3/2.6 GB 18.7 MB/s eta 0:02:03\n",
      "   ---- ----------------------------------- 0.3/2.6 GB 18.8 MB/s eta 0:02:02\n",
      "   ---- ----------------------------------- 0.3/2.6 GB 18.7 MB/s eta 0:02:03\n",
      "   ---- ----------------------------------- 0.3/2.6 GB 18.6 MB/s eta 0:02:03\n",
      "   ---- ----------------------------------- 0.3/2.6 GB 18.7 MB/s eta 0:02:02\n",
      "   ---- ----------------------------------- 0.3/2.6 GB 18.6 MB/s eta 0:02:02\n",
      "   ---- ----------------------------------- 0.3/2.6 GB 19.0 MB/s eta 0:02:00\n",
      "   ----- ---------------------------------- 0.3/2.6 GB 19.0 MB/s eta 0:01:59\n",
      "   ----- ---------------------------------- 0.3/2.6 GB 19.1 MB/s eta 0:01:58\n",
      "   ----- ---------------------------------- 0.3/2.6 GB 19.1 MB/s eta 0:01:58\n",
      "   ----- ---------------------------------- 0.3/2.6 GB 19.0 MB/s eta 0:01:59\n",
      "   ----- ---------------------------------- 0.3/2.6 GB 19.0 MB/s eta 0:01:59\n",
      "   ----- ---------------------------------- 0.3/2.6 GB 19.0 MB/s eta 0:01:58\n",
      "   ----- ---------------------------------- 0.3/2.6 GB 18.9 MB/s eta 0:01:59\n",
      "   ----- ---------------------------------- 0.4/2.6 GB 18.9 MB/s eta 0:01:59\n",
      "   ----- ---------------------------------- 0.4/2.6 GB 18.7 MB/s eta 0:01:59\n",
      "   ----- ---------------------------------- 0.4/2.6 GB 18.8 MB/s eta 0:01:59\n",
      "   ----- ---------------------------------- 0.4/2.6 GB 18.7 MB/s eta 0:01:59\n",
      "   ----- ---------------------------------- 0.4/2.6 GB 18.8 MB/s eta 0:01:59\n",
      "   ----- ---------------------------------- 0.4/2.6 GB 18.7 MB/s eta 0:01:59\n",
      "   ----- ---------------------------------- 0.4/2.6 GB 18.7 MB/s eta 0:01:58\n",
      "   ----- ---------------------------------- 0.4/2.6 GB 18.6 MB/s eta 0:01:59\n",
      "   ----- ---------------------------------- 0.4/2.6 GB 18.4 MB/s eta 0:02:00\n",
      "   ----- ---------------------------------- 0.4/2.6 GB 18.4 MB/s eta 0:02:00\n",
      "   ----- ---------------------------------- 0.4/2.6 GB 18.3 MB/s eta 0:02:01\n",
      "   ----- ---------------------------------- 0.4/2.6 GB 18.0 MB/s eta 0:02:03\n",
      "   ----- ---------------------------------- 0.4/2.6 GB 17.8 MB/s eta 0:02:04\n",
      "   ------ --------------------------------- 0.4/2.6 GB 17.6 MB/s eta 0:02:05\n",
      "   ------ --------------------------------- 0.4/2.6 GB 17.6 MB/s eta 0:02:05\n",
      "   ------ --------------------------------- 0.4/2.6 GB 17.7 MB/s eta 0:02:04\n",
      "   ------ --------------------------------- 0.4/2.6 GB 17.6 MB/s eta 0:02:05\n",
      "   ------ --------------------------------- 0.4/2.6 GB 17.6 MB/s eta 0:02:04\n",
      "   ------ --------------------------------- 0.4/2.6 GB 17.5 MB/s eta 0:02:05\n",
      "   ------ --------------------------------- 0.4/2.6 GB 17.3 MB/s eta 0:02:06\n",
      "   ------ --------------------------------- 0.4/2.6 GB 17.2 MB/s eta 0:02:07\n",
      "   ------ --------------------------------- 0.4/2.6 GB 17.1 MB/s eta 0:02:08\n",
      "   ------ --------------------------------- 0.4/2.6 GB 16.9 MB/s eta 0:02:09\n",
      "   ------ --------------------------------- 0.4/2.6 GB 16.8 MB/s eta 0:02:09\n",
      "   ------ --------------------------------- 0.4/2.6 GB 16.7 MB/s eta 0:02:10\n",
      "   ------ --------------------------------- 0.4/2.6 GB 16.6 MB/s eta 0:02:10\n",
      "   ------ --------------------------------- 0.4/2.6 GB 16.6 MB/s eta 0:02:10\n",
      "   ------ --------------------------------- 0.4/2.6 GB 16.5 MB/s eta 0:02:11\n",
      "   ------ --------------------------------- 0.4/2.6 GB 16.4 MB/s eta 0:02:11\n",
      "   ------ --------------------------------- 0.4/2.6 GB 16.5 MB/s eta 0:02:10\n",
      "   ------ --------------------------------- 0.4/2.6 GB 16.5 MB/s eta 0:02:10\n",
      "   ------ --------------------------------- 0.5/2.6 GB 16.5 MB/s eta 0:02:10\n",
      "   ------- -------------------------------- 0.5/2.6 GB 16.4 MB/s eta 0:02:10\n",
      "   ------- -------------------------------- 0.5/2.6 GB 16.5 MB/s eta 0:02:09\n",
      "   ------- -------------------------------- 0.5/2.6 GB 16.5 MB/s eta 0:02:09\n",
      "   ------- -------------------------------- 0.5/2.6 GB 16.4 MB/s eta 0:02:10\n",
      "   ------- -------------------------------- 0.5/2.6 GB 16.6 MB/s eta 0:02:08\n",
      "   ------- -------------------------------- 0.5/2.6 GB 16.5 MB/s eta 0:02:09\n",
      "   ------- -------------------------------- 0.5/2.6 GB 16.4 MB/s eta 0:02:10\n",
      "   ------- -------------------------------- 0.5/2.6 GB 16.4 MB/s eta 0:02:10\n",
      "   ------- -------------------------------- 0.5/2.6 GB 16.3 MB/s eta 0:02:10\n",
      "   ------- -------------------------------- 0.5/2.6 GB 16.1 MB/s eta 0:02:12\n",
      "   ------- -------------------------------- 0.5/2.6 GB 15.9 MB/s eta 0:02:13\n",
      "   ------- -------------------------------- 0.5/2.6 GB 15.8 MB/s eta 0:02:14\n",
      "   ------- -------------------------------- 0.5/2.6 GB 15.8 MB/s eta 0:02:14\n",
      "   ------- -------------------------------- 0.5/2.6 GB 15.5 MB/s eta 0:02:16\n",
      "   ------- -------------------------------- 0.5/2.6 GB 15.5 MB/s eta 0:02:16\n",
      "   ------- -------------------------------- 0.5/2.6 GB 15.6 MB/s eta 0:02:15\n",
      "   ------- -------------------------------- 0.5/2.6 GB 15.6 MB/s eta 0:02:15\n",
      "   ------- -------------------------------- 0.5/2.6 GB 15.5 MB/s eta 0:02:15\n",
      "   ------- -------------------------------- 0.5/2.6 GB 15.5 MB/s eta 0:02:15\n",
      "   ------- -------------------------------- 0.5/2.6 GB 15.5 MB/s eta 0:02:15\n",
      "   ------- -------------------------------- 0.5/2.6 GB 15.5 MB/s eta 0:02:15\n",
      "   ------- -------------------------------- 0.5/2.6 GB 15.4 MB/s eta 0:02:16\n",
      "   ------- -------------------------------- 0.5/2.6 GB 15.3 MB/s eta 0:02:16\n",
      "   ------- -------------------------------- 0.5/2.6 GB 15.3 MB/s eta 0:02:16\n",
      "   ------- -------------------------------- 0.5/2.6 GB 15.1 MB/s eta 0:02:17\n",
      "   ------- -------------------------------- 0.5/2.6 GB 15.1 MB/s eta 0:02:18\n",
      "   ------- -------------------------------- 0.5/2.6 GB 15.0 MB/s eta 0:02:19\n",
      "   -------- ------------------------------- 0.5/2.6 GB 14.9 MB/s eta 0:02:19\n",
      "   -------- ------------------------------- 0.5/2.6 GB 14.9 MB/s eta 0:02:19\n",
      "   -------- ------------------------------- 0.5/2.6 GB 14.9 MB/s eta 0:02:19\n",
      "   -------- ------------------------------- 0.5/2.6 GB 14.8 MB/s eta 0:02:19\n",
      "   -------- ------------------------------- 0.5/2.6 GB 14.7 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 0.5/2.6 GB 14.7 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 0.5/2.6 GB 14.6 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 0.5/2.6 GB 14.6 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 0.5/2.6 GB 14.6 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 0.5/2.6 GB 14.5 MB/s eta 0:02:21\n",
      "   -------- ------------------------------- 0.5/2.6 GB 14.6 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 0.6/2.6 GB 14.6 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 0.6/2.6 GB 14.5 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 0.6/2.6 GB 14.6 MB/s eta 0:02:19\n",
      "   -------- ------------------------------- 0.6/2.6 GB 14.5 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 0.6/2.6 GB 14.5 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 0.6/2.6 GB 14.5 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 0.6/2.6 GB 14.5 MB/s eta 0:02:19\n",
      "   -------- ------------------------------- 0.6/2.6 GB 14.4 MB/s eta 0:02:20\n",
      "   --------- ------------------------------ 0.6/2.6 GB 14.4 MB/s eta 0:02:20\n",
      "   --------- ------------------------------ 0.6/2.6 GB 14.4 MB/s eta 0:02:20\n",
      "   --------- ------------------------------ 0.6/2.6 GB 14.3 MB/s eta 0:02:20\n",
      "   --------- ------------------------------ 0.6/2.6 GB 14.3 MB/s eta 0:02:20\n",
      "   --------- ------------------------------ 0.6/2.6 GB 14.3 MB/s eta 0:02:19\n",
      "   --------- ------------------------------ 0.6/2.6 GB 14.4 MB/s eta 0:02:18\n",
      "   --------- ------------------------------ 0.6/2.6 GB 14.4 MB/s eta 0:02:18\n",
      "   --------- ------------------------------ 0.6/2.6 GB 14.4 MB/s eta 0:02:17\n",
      "   --------- ------------------------------ 0.6/2.6 GB 14.5 MB/s eta 0:02:16\n",
      "   --------- ------------------------------ 0.6/2.6 GB 14.6 MB/s eta 0:02:15\n",
      "   --------- ------------------------------ 0.6/2.6 GB 14.8 MB/s eta 0:02:13\n",
      "   --------- ------------------------------ 0.6/2.6 GB 14.7 MB/s eta 0:02:13\n",
      "   --------- ------------------------------ 0.6/2.6 GB 14.7 MB/s eta 0:02:13\n",
      "   --------- ------------------------------ 0.6/2.6 GB 14.6 MB/s eta 0:02:14\n",
      "   --------- ------------------------------ 0.6/2.6 GB 14.7 MB/s eta 0:02:12\n",
      "   --------- ------------------------------ 0.6/2.6 GB 14.7 MB/s eta 0:02:13\n",
      "   ---------- ----------------------------- 0.6/2.6 GB 15.1 MB/s eta 0:02:09\n",
      "   ---------- ----------------------------- 0.7/2.6 GB 15.2 MB/s eta 0:02:07\n",
      "   ---------- ----------------------------- 0.7/2.6 GB 15.2 MB/s eta 0:02:08\n",
      "   ---------- ----------------------------- 0.7/2.6 GB 15.0 MB/s eta 0:02:08\n",
      "   ---------- ----------------------------- 0.7/2.6 GB 15.0 MB/s eta 0:02:08\n",
      "   ---------- ----------------------------- 0.7/2.6 GB 15.0 MB/s eta 0:02:08\n",
      "   ---------- ----------------------------- 0.7/2.6 GB 14.9 MB/s eta 0:02:09\n",
      "   ---------- ----------------------------- 0.7/2.6 GB 14.8 MB/s eta 0:02:10\n",
      "   ---------- ----------------------------- 0.7/2.6 GB 14.9 MB/s eta 0:02:09\n",
      "   ---------- ----------------------------- 0.7/2.6 GB 14.9 MB/s eta 0:02:09\n",
      "   ---------- ----------------------------- 0.7/2.6 GB 14.8 MB/s eta 0:02:09\n",
      "   ---------- ----------------------------- 0.7/2.6 GB 14.9 MB/s eta 0:02:08\n",
      "   ---------- ----------------------------- 0.7/2.6 GB 15.0 MB/s eta 0:02:08\n",
      "   ---------- ----------------------------- 0.7/2.6 GB 15.0 MB/s eta 0:02:07\n",
      "   ---------- ----------------------------- 0.7/2.6 GB 15.1 MB/s eta 0:02:06\n",
      "   ---------- ----------------------------- 0.7/2.6 GB 15.2 MB/s eta 0:02:05\n",
      "   ---------- ----------------------------- 0.7/2.6 GB 15.3 MB/s eta 0:02:04\n",
      "   ---------- ----------------------------- 0.7/2.6 GB 15.3 MB/s eta 0:02:03\n",
      "   ----------- ---------------------------- 0.7/2.6 GB 15.5 MB/s eta 0:02:01\n",
      "   ----------- ---------------------------- 0.7/2.6 GB 15.5 MB/s eta 0:02:00\n",
      "   ----------- ---------------------------- 0.7/2.6 GB 15.9 MB/s eta 0:01:58\n",
      "   ----------- ---------------------------- 0.7/2.6 GB 16.3 MB/s eta 0:01:54\n",
      "   ----------- ---------------------------- 0.7/2.6 GB 16.9 MB/s eta 0:01:50\n",
      "   ----------- ---------------------------- 0.7/2.6 GB 17.4 MB/s eta 0:01:47\n",
      "   ----------- ---------------------------- 0.7/2.6 GB 17.6 MB/s eta 0:01:45\n",
      "   ----------- ---------------------------- 0.7/2.6 GB 17.6 MB/s eta 0:01:45\n",
      "   ----------- ---------------------------- 0.8/2.6 GB 17.5 MB/s eta 0:01:45\n",
      "   ----------- ---------------------------- 0.8/2.6 GB 17.6 MB/s eta 0:01:44\n",
      "   ----------- ---------------------------- 0.8/2.6 GB 17.8 MB/s eta 0:01:43\n",
      "   ----------- ---------------------------- 0.8/2.6 GB 18.2 MB/s eta 0:01:40\n",
      "   ------------ --------------------------- 0.8/2.6 GB 18.6 MB/s eta 0:01:38\n",
      "   ------------ --------------------------- 0.8/2.6 GB 18.6 MB/s eta 0:01:37\n",
      "   ------------ --------------------------- 0.8/2.6 GB 18.6 MB/s eta 0:01:37\n",
      "   ------------ --------------------------- 0.8/2.6 GB 18.5 MB/s eta 0:01:38\n",
      "   ------------ --------------------------- 0.8/2.6 GB 18.4 MB/s eta 0:01:38\n",
      "   ------------ --------------------------- 0.8/2.6 GB 18.2 MB/s eta 0:01:39\n",
      "   ------------ --------------------------- 0.8/2.6 GB 18.0 MB/s eta 0:01:40\n",
      "   ------------ --------------------------- 0.8/2.6 GB 17.9 MB/s eta 0:01:41\n",
      "   ------------ --------------------------- 0.8/2.6 GB 17.8 MB/s eta 0:01:41\n",
      "   ------------ --------------------------- 0.8/2.6 GB 17.6 MB/s eta 0:01:42\n",
      "   ------------ --------------------------- 0.8/2.6 GB 17.7 MB/s eta 0:01:42\n",
      "   ------------ --------------------------- 0.8/2.6 GB 17.8 MB/s eta 0:01:41\n",
      "   ------------ --------------------------- 0.8/2.6 GB 17.7 MB/s eta 0:01:41\n",
      "   ------------ --------------------------- 0.8/2.6 GB 17.7 MB/s eta 0:01:41\n",
      "   ------------ --------------------------- 0.8/2.6 GB 17.8 MB/s eta 0:01:41\n",
      "   ------------ --------------------------- 0.8/2.6 GB 17.7 MB/s eta 0:01:40\n",
      "   ------------ --------------------------- 0.8/2.6 GB 17.7 MB/s eta 0:01:41\n",
      "   ------------ --------------------------- 0.8/2.6 GB 17.6 MB/s eta 0:01:41\n",
      "   ------------ --------------------------- 0.8/2.6 GB 17.5 MB/s eta 0:01:41\n",
      "   ------------ --------------------------- 0.8/2.6 GB 17.5 MB/s eta 0:01:41\n",
      "   ------------ --------------------------- 0.8/2.6 GB 17.4 MB/s eta 0:01:41\n",
      "   ------------ --------------------------- 0.8/2.6 GB 17.4 MB/s eta 0:01:41\n",
      "   ------------ --------------------------- 0.8/2.6 GB 17.3 MB/s eta 0:01:42\n",
      "   ------------ --------------------------- 0.8/2.6 GB 17.2 MB/s eta 0:01:42\n",
      "   ------------ --------------------------- 0.8/2.6 GB 17.2 MB/s eta 0:01:42\n",
      "   ------------ --------------------------- 0.8/2.6 GB 17.0 MB/s eta 0:01:43\n",
      "   ------------- -------------------------- 0.8/2.6 GB 16.9 MB/s eta 0:01:43\n",
      "   ------------- -------------------------- 0.8/2.6 GB 16.9 MB/s eta 0:01:43\n",
      "   ------------- -------------------------- 0.8/2.6 GB 16.8 MB/s eta 0:01:44\n",
      "   ------------- -------------------------- 0.8/2.6 GB 16.7 MB/s eta 0:01:44\n",
      "   ------------- -------------------------- 0.9/2.6 GB 16.7 MB/s eta 0:01:44\n",
      "   ------------- -------------------------- 0.9/2.6 GB 16.6 MB/s eta 0:01:44\n",
      "   ------------- -------------------------- 0.9/2.6 GB 16.6 MB/s eta 0:01:45\n",
      "   ------------- -------------------------- 0.9/2.6 GB 16.4 MB/s eta 0:01:45\n",
      "   ------------- -------------------------- 0.9/2.6 GB 16.4 MB/s eta 0:01:46\n",
      "   ------------- -------------------------- 0.9/2.6 GB 16.3 MB/s eta 0:01:46\n",
      "   ------------- -------------------------- 0.9/2.6 GB 16.2 MB/s eta 0:01:47\n",
      "   ------------- -------------------------- 0.9/2.6 GB 16.2 MB/s eta 0:01:46\n",
      "   ------------- -------------------------- 0.9/2.6 GB 16.1 MB/s eta 0:01:47\n",
      "   ------------- -------------------------- 0.9/2.6 GB 16.0 MB/s eta 0:01:47\n",
      "   ------------- -------------------------- 0.9/2.6 GB 15.9 MB/s eta 0:01:48\n",
      "   ------------- -------------------------- 0.9/2.6 GB 15.8 MB/s eta 0:01:48\n",
      "   ------------- -------------------------- 0.9/2.6 GB 15.7 MB/s eta 0:01:49\n",
      "   ------------- -------------------------- 0.9/2.6 GB 15.6 MB/s eta 0:01:49\n",
      "   ------------- -------------------------- 0.9/2.6 GB 15.5 MB/s eta 0:01:50\n",
      "   ------------- -------------------------- 0.9/2.6 GB 15.6 MB/s eta 0:01:49\n",
      "   ------------- -------------------------- 0.9/2.6 GB 15.8 MB/s eta 0:01:47\n",
      "   -------------- ------------------------- 0.9/2.6 GB 15.9 MB/s eta 0:01:46\n",
      "   -------------- ------------------------- 0.9/2.6 GB 15.9 MB/s eta 0:01:45\n",
      "   -------------- ------------------------- 0.9/2.6 GB 15.9 MB/s eta 0:01:46\n",
      "   -------------- ------------------------- 0.9/2.6 GB 16.0 MB/s eta 0:01:45\n",
      "   -------------- ------------------------- 0.9/2.6 GB 16.2 MB/s eta 0:01:43\n",
      "   -------------- ------------------------- 0.9/2.6 GB 16.4 MB/s eta 0:01:42\n",
      "   -------------- ------------------------- 0.9/2.6 GB 16.5 MB/s eta 0:01:41\n",
      "   -------------- ------------------------- 0.9/2.6 GB 16.8 MB/s eta 0:01:38\n",
      "   -------------- ------------------------- 0.9/2.6 GB 17.0 MB/s eta 0:01:37\n",
      "   -------------- ------------------------- 0.9/2.6 GB 16.9 MB/s eta 0:01:38\n",
      "   -------------- ------------------------- 1.0/2.6 GB 16.9 MB/s eta 0:01:37\n",
      "   -------------- ------------------------- 1.0/2.6 GB 16.8 MB/s eta 0:01:37\n",
      "   -------------- ------------------------- 1.0/2.6 GB 16.8 MB/s eta 0:01:37\n",
      "   -------------- ------------------------- 1.0/2.6 GB 16.8 MB/s eta 0:01:37\n",
      "   -------------- ------------------------- 1.0/2.6 GB 16.8 MB/s eta 0:01:37\n",
      "   --------------- ------------------------ 1.0/2.6 GB 16.7 MB/s eta 0:01:37\n",
      "   --------------- ------------------------ 1.0/2.6 GB 16.5 MB/s eta 0:01:38\n",
      "   --------------- ------------------------ 1.0/2.6 GB 16.4 MB/s eta 0:01:38\n",
      "   --------------- ------------------------ 1.0/2.6 GB 16.4 MB/s eta 0:01:38\n",
      "   --------------- ------------------------ 1.0/2.6 GB 16.2 MB/s eta 0:01:39\n",
      "   --------------- ------------------------ 1.0/2.6 GB 16.1 MB/s eta 0:01:40\n",
      "   --------------- ------------------------ 1.0/2.6 GB 16.0 MB/s eta 0:01:40\n",
      "   --------------- ------------------------ 1.0/2.6 GB 15.9 MB/s eta 0:01:40\n",
      "   --------------- ------------------------ 1.0/2.6 GB 15.8 MB/s eta 0:01:41\n",
      "   --------------- ------------------------ 1.0/2.6 GB 15.8 MB/s eta 0:01:41\n",
      "   --------------- ------------------------ 1.0/2.6 GB 15.6 MB/s eta 0:01:42\n",
      "   --------------- ------------------------ 1.0/2.6 GB 15.6 MB/s eta 0:01:42\n",
      "   --------------- ------------------------ 1.0/2.6 GB 15.8 MB/s eta 0:01:40\n",
      "   --------------- ------------------------ 1.0/2.6 GB 15.8 MB/s eta 0:01:40\n",
      "   --------------- ------------------------ 1.0/2.6 GB 15.7 MB/s eta 0:01:40\n",
      "   --------------- ------------------------ 1.0/2.6 GB 15.6 MB/s eta 0:01:41\n",
      "   --------------- ------------------------ 1.0/2.6 GB 15.5 MB/s eta 0:01:41\n",
      "   --------------- ------------------------ 1.0/2.6 GB 15.4 MB/s eta 0:01:42\n",
      "   --------------- ------------------------ 1.0/2.6 GB 15.3 MB/s eta 0:01:42\n",
      "   --------------- ------------------------ 1.0/2.6 GB 15.2 MB/s eta 0:01:43\n",
      "   ---------------- ----------------------- 1.0/2.6 GB 15.2 MB/s eta 0:01:43\n",
      "   ---------------- ----------------------- 1.0/2.6 GB 15.1 MB/s eta 0:01:43\n",
      "   ---------------- ----------------------- 1.0/2.6 GB 15.2 MB/s eta 0:01:42\n",
      "   ---------------- ----------------------- 1.0/2.6 GB 15.4 MB/s eta 0:01:40\n",
      "   ---------------- ----------------------- 1.1/2.6 GB 15.6 MB/s eta 0:01:39\n",
      "   ---------------- ----------------------- 1.1/2.6 GB 15.9 MB/s eta 0:01:37\n",
      "   ---------------- ----------------------- 1.1/2.6 GB 16.1 MB/s eta 0:01:35\n",
      "   ---------------- ----------------------- 1.1/2.6 GB 16.2 MB/s eta 0:01:34\n",
      "   ---------------- ----------------------- 1.1/2.6 GB 16.4 MB/s eta 0:01:33\n",
      "   ---------------- ----------------------- 1.1/2.6 GB 16.3 MB/s eta 0:01:33\n",
      "   ---------------- ----------------------- 1.1/2.6 GB 16.4 MB/s eta 0:01:33\n",
      "   ---------------- ----------------------- 1.1/2.6 GB 16.5 MB/s eta 0:01:31\n",
      "   ---------------- ----------------------- 1.1/2.6 GB 16.6 MB/s eta 0:01:31\n",
      "   ---------------- ----------------------- 1.1/2.6 GB 16.6 MB/s eta 0:01:31\n",
      "   ---------------- ----------------------- 1.1/2.6 GB 16.5 MB/s eta 0:01:31\n",
      "   ---------------- ----------------------- 1.1/2.6 GB 16.6 MB/s eta 0:01:30\n",
      "   ----------------- ---------------------- 1.1/2.6 GB 16.9 MB/s eta 0:01:28\n",
      "   ----------------- ---------------------- 1.1/2.6 GB 17.1 MB/s eta 0:01:27\n",
      "   ----------------- ---------------------- 1.1/2.6 GB 17.2 MB/s eta 0:01:26\n",
      "   ----------------- ---------------------- 1.1/2.6 GB 17.3 MB/s eta 0:01:26\n",
      "   ----------------- ---------------------- 1.1/2.6 GB 17.6 MB/s eta 0:01:24\n",
      "   ----------------- ---------------------- 1.1/2.6 GB 17.7 MB/s eta 0:01:23\n",
      "   ----------------- ---------------------- 1.1/2.6 GB 18.0 MB/s eta 0:01:22\n",
      "   ----------------- ---------------------- 1.1/2.6 GB 18.2 MB/s eta 0:01:21\n",
      "   ----------------- ---------------------- 1.1/2.6 GB 18.1 MB/s eta 0:01:21\n",
      "   ----------------- ---------------------- 1.1/2.6 GB 18.4 MB/s eta 0:01:19\n",
      "   ----------------- ---------------------- 1.1/2.6 GB 18.4 MB/s eta 0:01:19\n",
      "   ----------------- ---------------------- 1.1/2.6 GB 18.5 MB/s eta 0:01:18\n",
      "   ----------------- ---------------------- 1.2/2.6 GB 18.7 MB/s eta 0:01:17\n",
      "   ----------------- ---------------------- 1.2/2.6 GB 18.7 MB/s eta 0:01:17\n",
      "   ----------------- ---------------------- 1.2/2.6 GB 18.6 MB/s eta 0:01:17\n",
      "   ----------------- ---------------------- 1.2/2.6 GB 18.5 MB/s eta 0:01:18\n",
      "   ------------------ --------------------- 1.2/2.6 GB 18.5 MB/s eta 0:01:17\n",
      "   ------------------ --------------------- 1.2/2.6 GB 18.5 MB/s eta 0:01:17\n",
      "   ------------------ --------------------- 1.2/2.6 GB 18.5 MB/s eta 0:01:17\n",
      "   ------------------ --------------------- 1.2/2.6 GB 18.3 MB/s eta 0:01:17\n",
      "   ------------------ --------------------- 1.2/2.6 GB 18.4 MB/s eta 0:01:17\n",
      "   ------------------ --------------------- 1.2/2.6 GB 18.4 MB/s eta 0:01:16\n",
      "   ------------------ --------------------- 1.2/2.6 GB 18.5 MB/s eta 0:01:16\n",
      "   ------------------ --------------------- 1.2/2.6 GB 18.6 MB/s eta 0:01:15\n",
      "   ------------------ --------------------- 1.2/2.6 GB 18.6 MB/s eta 0:01:15\n",
      "   ------------------ --------------------- 1.2/2.6 GB 18.8 MB/s eta 0:01:14\n",
      "   ------------------ --------------------- 1.2/2.6 GB 19.0 MB/s eta 0:01:13\n",
      "   ------------------ --------------------- 1.2/2.6 GB 18.8 MB/s eta 0:01:13\n",
      "   ------------------ --------------------- 1.2/2.6 GB 18.9 MB/s eta 0:01:12\n",
      "   ------------------- -------------------- 1.2/2.6 GB 19.0 MB/s eta 0:01:12\n",
      "   ------------------- -------------------- 1.2/2.6 GB 19.2 MB/s eta 0:01:11\n",
      "   ------------------- -------------------- 1.2/2.6 GB 19.1 MB/s eta 0:01:11\n",
      "   ------------------- -------------------- 1.2/2.6 GB 19.2 MB/s eta 0:01:10\n",
      "   ------------------- -------------------- 1.2/2.6 GB 19.7 MB/s eta 0:01:08\n",
      "   ------------------- -------------------- 1.3/2.6 GB 20.1 MB/s eta 0:01:06\n",
      "   ------------------- -------------------- 1.3/2.6 GB 20.6 MB/s eta 0:01:05\n",
      "   ------------------- -------------------- 1.3/2.6 GB 20.7 MB/s eta 0:01:04\n",
      "   ------------------- -------------------- 1.3/2.6 GB 20.7 MB/s eta 0:01:04\n",
      "   ------------------- -------------------- 1.3/2.6 GB 21.1 MB/s eta 0:01:02\n",
      "   ------------------- -------------------- 1.3/2.6 GB 21.4 MB/s eta 0:01:01\n",
      "   -------------------- ------------------- 1.3/2.6 GB 22.0 MB/s eta 0:00:59\n",
      "   -------------------- ------------------- 1.3/2.6 GB 22.1 MB/s eta 0:00:59\n",
      "   -------------------- ------------------- 1.3/2.6 GB 22.4 MB/s eta 0:00:58\n",
      "   -------------------- ------------------- 1.3/2.6 GB 22.6 MB/s eta 0:00:57\n",
      "   -------------------- ------------------- 1.3/2.6 GB 22.6 MB/s eta 0:00:57\n",
      "   -------------------- ------------------- 1.3/2.6 GB 22.6 MB/s eta 0:00:56\n",
      "   -------------------- ------------------- 1.3/2.6 GB 22.4 MB/s eta 0:00:57\n",
      "   -------------------- ------------------- 1.3/2.6 GB 22.4 MB/s eta 0:00:57\n",
      "   -------------------- ------------------- 1.3/2.6 GB 21.8 MB/s eta 0:00:58\n",
      "   -------------------- ------------------- 1.3/2.6 GB 21.8 MB/s eta 0:00:58\n",
      "   -------------------- ------------------- 1.3/2.6 GB 22.0 MB/s eta 0:00:57\n",
      "   -------------------- ------------------- 1.3/2.6 GB 22.1 MB/s eta 0:00:57\n",
      "   -------------------- ------------------- 1.3/2.6 GB 21.9 MB/s eta 0:00:57\n",
      "   -------------------- ------------------- 1.3/2.6 GB 21.8 MB/s eta 0:00:57\n",
      "   -------------------- ------------------- 1.3/2.6 GB 22.2 MB/s eta 0:00:56\n",
      "   -------------------- ------------------- 1.4/2.6 GB 22.3 MB/s eta 0:00:56\n",
      "   -------------------- ------------------- 1.4/2.6 GB 22.0 MB/s eta 0:00:56\n",
      "   -------------------- ------------------- 1.4/2.6 GB 21.7 MB/s eta 0:00:57\n",
      "   --------------------- ------------------ 1.4/2.6 GB 21.5 MB/s eta 0:00:58\n",
      "   --------------------- ------------------ 1.4/2.6 GB 21.2 MB/s eta 0:00:58\n",
      "   --------------------- ------------------ 1.4/2.6 GB 21.0 MB/s eta 0:00:59\n",
      "   --------------------- ------------------ 1.4/2.6 GB 20.9 MB/s eta 0:00:59\n",
      "   --------------------- ------------------ 1.4/2.6 GB 20.7 MB/s eta 0:00:59\n",
      "   --------------------- ------------------ 1.4/2.6 GB 20.6 MB/s eta 0:00:59\n",
      "   --------------------- ------------------ 1.4/2.6 GB 20.4 MB/s eta 0:01:00\n",
      "   --------------------- ------------------ 1.4/2.6 GB 20.3 MB/s eta 0:01:00\n",
      "   --------------------- ------------------ 1.4/2.6 GB 20.0 MB/s eta 0:01:01\n",
      "   --------------------- ------------------ 1.4/2.6 GB 19.9 MB/s eta 0:01:01\n",
      "   --------------------- ------------------ 1.4/2.6 GB 19.8 MB/s eta 0:01:01\n",
      "   --------------------- ------------------ 1.4/2.6 GB 19.6 MB/s eta 0:01:02\n",
      "   --------------------- ------------------ 1.4/2.6 GB 19.4 MB/s eta 0:01:02\n",
      "   --------------------- ------------------ 1.4/2.6 GB 19.3 MB/s eta 0:01:02\n",
      "   --------------------- ------------------ 1.4/2.6 GB 19.0 MB/s eta 0:01:03\n",
      "   --------------------- ------------------ 1.4/2.6 GB 18.7 MB/s eta 0:01:04\n",
      "   --------------------- ------------------ 1.4/2.6 GB 18.6 MB/s eta 0:01:05\n",
      "   --------------------- ------------------ 1.4/2.6 GB 18.5 MB/s eta 0:01:05\n",
      "   --------------------- ------------------ 1.4/2.6 GB 18.4 MB/s eta 0:01:05\n",
      "   --------------------- ------------------ 1.4/2.6 GB 18.2 MB/s eta 0:01:06\n",
      "   --------------------- ------------------ 1.4/2.6 GB 18.0 MB/s eta 0:01:06\n",
      "   --------------------- ------------------ 1.4/2.6 GB 17.9 MB/s eta 0:01:07\n",
      "   --------------------- ------------------ 1.4/2.6 GB 17.9 MB/s eta 0:01:06\n",
      "   --------------------- ------------------ 1.4/2.6 GB 17.7 MB/s eta 0:01:07\n",
      "   --------------------- ------------------ 1.4/2.6 GB 17.6 MB/s eta 0:01:07\n",
      "   --------------------- ------------------ 1.4/2.6 GB 17.6 MB/s eta 0:01:07\n",
      "   --------------------- ------------------ 1.4/2.6 GB 17.4 MB/s eta 0:01:08\n",
      "   --------------------- ------------------ 1.4/2.6 GB 17.3 MB/s eta 0:01:08\n",
      "   --------------------- ------------------ 1.4/2.6 GB 17.3 MB/s eta 0:01:08\n",
      "   --------------------- ------------------ 1.4/2.6 GB 17.3 MB/s eta 0:01:08\n",
      "   ---------------------- ----------------- 1.4/2.6 GB 17.2 MB/s eta 0:01:08\n",
      "   ---------------------- ----------------- 1.4/2.6 GB 17.1 MB/s eta 0:01:08\n",
      "   ---------------------- ----------------- 1.4/2.6 GB 17.0 MB/s eta 0:01:08\n",
      "   ---------------------- ----------------- 1.4/2.6 GB 17.0 MB/s eta 0:01:08\n",
      "   ---------------------- ----------------- 1.4/2.6 GB 16.6 MB/s eta 0:01:10\n",
      "   ---------------------- ----------------- 1.4/2.6 GB 16.6 MB/s eta 0:01:10\n",
      "   ---------------------- ----------------- 1.4/2.6 GB 16.5 MB/s eta 0:01:10\n",
      "   ---------------------- ----------------- 1.4/2.6 GB 16.5 MB/s eta 0:01:10\n",
      "   ---------------------- ----------------- 1.4/2.6 GB 16.4 MB/s eta 0:01:10\n",
      "   ---------------------- ----------------- 1.4/2.6 GB 16.3 MB/s eta 0:01:10\n",
      "   ---------------------- ----------------- 1.4/2.6 GB 16.1 MB/s eta 0:01:11\n",
      "   ---------------------- ----------------- 1.4/2.6 GB 16.1 MB/s eta 0:01:11\n",
      "   ---------------------- ----------------- 1.5/2.6 GB 15.9 MB/s eta 0:01:12\n",
      "   ---------------------- ----------------- 1.5/2.6 GB 15.9 MB/s eta 0:01:11\n",
      "   ---------------------- ----------------- 1.5/2.6 GB 15.8 MB/s eta 0:01:12\n",
      "   ---------------------- ----------------- 1.5/2.6 GB 15.7 MB/s eta 0:01:12\n",
      "   ---------------------- ----------------- 1.5/2.6 GB 15.6 MB/s eta 0:01:12\n",
      "   ---------------------- ----------------- 1.5/2.6 GB 15.5 MB/s eta 0:01:12\n",
      "   ---------------------- ----------------- 1.5/2.6 GB 15.4 MB/s eta 0:01:13\n",
      "   ---------------------- ----------------- 1.5/2.6 GB 15.3 MB/s eta 0:01:13\n",
      "   ---------------------- ----------------- 1.5/2.6 GB 15.2 MB/s eta 0:01:14\n",
      "   ---------------------- ----------------- 1.5/2.6 GB 15.0 MB/s eta 0:01:15\n",
      "   ---------------------- ----------------- 1.5/2.6 GB 14.9 MB/s eta 0:01:15\n",
      "   ---------------------- ----------------- 1.5/2.6 GB 14.8 MB/s eta 0:01:15\n",
      "   ---------------------- ----------------- 1.5/2.6 GB 14.7 MB/s eta 0:01:16\n",
      "   ---------------------- ----------------- 1.5/2.6 GB 14.6 MB/s eta 0:01:16\n",
      "   ---------------------- ----------------- 1.5/2.6 GB 14.5 MB/s eta 0:01:16\n",
      "   ---------------------- ----------------- 1.5/2.6 GB 14.3 MB/s eta 0:01:17\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 14.2 MB/s eta 0:01:18\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 14.1 MB/s eta 0:01:18\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 14.0 MB/s eta 0:01:19\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 14.0 MB/s eta 0:01:19\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 13.9 MB/s eta 0:01:19\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 13.8 MB/s eta 0:01:19\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 13.8 MB/s eta 0:01:19\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 13.7 MB/s eta 0:01:20\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 13.6 MB/s eta 0:01:20\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 13.5 MB/s eta 0:01:20\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 13.4 MB/s eta 0:01:21\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 13.3 MB/s eta 0:01:21\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 13.2 MB/s eta 0:01:21\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 13.2 MB/s eta 0:01:22\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 13.0 MB/s eta 0:01:22\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 12.9 MB/s eta 0:01:23\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 12.8 MB/s eta 0:01:24\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 12.8 MB/s eta 0:01:24\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 12.6 MB/s eta 0:01:25\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 12.5 MB/s eta 0:01:25\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 12.4 MB/s eta 0:01:26\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 12.3 MB/s eta 0:01:26\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 12.3 MB/s eta 0:01:27\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 12.1 MB/s eta 0:01:28\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 12.1 MB/s eta 0:01:28\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 12.0 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 11.9 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 11.8 MB/s eta 0:01:30\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 11.7 MB/s eta 0:01:31\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 11.6 MB/s eta 0:01:31\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 11.5 MB/s eta 0:01:32\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 11.4 MB/s eta 0:01:32\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 11.3 MB/s eta 0:01:33\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 11.3 MB/s eta 0:01:33\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 11.2 MB/s eta 0:01:34\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 11.1 MB/s eta 0:01:34\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 11.1 MB/s eta 0:01:34\n",
      "   ----------------------- ---------------- 1.5/2.6 GB 11.0 MB/s eta 0:01:35\n",
      "   ------------------------ --------------- 1.6/2.6 GB 11.0 MB/s eta 0:01:35\n",
      "   ------------------------ --------------- 1.6/2.6 GB 10.9 MB/s eta 0:01:35\n",
      "   ------------------------ --------------- 1.6/2.6 GB 10.8 MB/s eta 0:01:35\n",
      "   ------------------------ --------------- 1.6/2.6 GB 10.8 MB/s eta 0:01:36\n",
      "   ------------------------ --------------- 1.6/2.6 GB 10.7 MB/s eta 0:01:36\n",
      "   ------------------------ --------------- 1.6/2.6 GB 10.7 MB/s eta 0:01:36\n",
      "   ------------------------ --------------- 1.6/2.6 GB 10.6 MB/s eta 0:01:37\n",
      "   ------------------------ --------------- 1.6/2.6 GB 10.6 MB/s eta 0:01:37\n",
      "   ------------------------ --------------- 1.6/2.6 GB 10.5 MB/s eta 0:01:37\n",
      "   ------------------------ --------------- 1.6/2.6 GB 10.5 MB/s eta 0:01:37\n",
      "   ------------------------ --------------- 1.6/2.6 GB 10.4 MB/s eta 0:01:37\n",
      "   ------------------------ --------------- 1.6/2.6 GB 10.4 MB/s eta 0:01:37\n",
      "   ------------------------ --------------- 1.6/2.6 GB 10.4 MB/s eta 0:01:37\n",
      "   ------------------------ --------------- 1.6/2.6 GB 10.3 MB/s eta 0:01:38\n",
      "   ------------------------ --------------- 1.6/2.6 GB 10.3 MB/s eta 0:01:38\n",
      "   ------------------------ --------------- 1.6/2.6 GB 10.2 MB/s eta 0:01:39\n",
      "   ------------------------ --------------- 1.6/2.6 GB 10.2 MB/s eta 0:01:39\n",
      "   ------------------------ --------------- 1.6/2.6 GB 10.0 MB/s eta 0:01:40\n",
      "   ------------------------ --------------- 1.6/2.6 GB 10.1 MB/s eta 0:01:39\n",
      "   ------------------------ --------------- 1.6/2.6 GB 10.1 MB/s eta 0:01:40\n",
      "   ------------------------ --------------- 1.6/2.6 GB 10.0 MB/s eta 0:01:40\n",
      "   ------------------------ --------------- 1.6/2.6 GB 10.0 MB/s eta 0:01:41\n",
      "   ------------------------ --------------- 1.6/2.6 GB 9.9 MB/s eta 0:01:41\n",
      "   ------------------------ --------------- 1.6/2.6 GB 9.8 MB/s eta 0:01:42\n",
      "   ------------------------ --------------- 1.6/2.6 GB 9.8 MB/s eta 0:01:42\n",
      "   ------------------------ --------------- 1.6/2.6 GB 9.7 MB/s eta 0:01:42\n",
      "   ------------------------ --------------- 1.6/2.6 GB 9.7 MB/s eta 0:01:42\n",
      "   ------------------------ --------------- 1.6/2.6 GB 9.6 MB/s eta 0:01:43\n",
      "   ------------------------ --------------- 1.6/2.6 GB 9.6 MB/s eta 0:01:43\n",
      "   ------------------------ --------------- 1.6/2.6 GB 9.5 MB/s eta 0:01:44\n",
      "   ------------------------ --------------- 1.6/2.6 GB 9.5 MB/s eta 0:01:44\n",
      "   ------------------------ --------------- 1.6/2.6 GB 9.4 MB/s eta 0:01:44\n",
      "   ------------------------ --------------- 1.6/2.6 GB 9.4 MB/s eta 0:01:44\n",
      "   ------------------------ --------------- 1.6/2.6 GB 9.4 MB/s eta 0:01:45\n",
      "   ------------------------ --------------- 1.6/2.6 GB 9.4 MB/s eta 0:01:45\n",
      "   ------------------------ --------------- 1.6/2.6 GB 9.4 MB/s eta 0:01:45\n",
      "   ------------------------ --------------- 1.6/2.6 GB 9.3 MB/s eta 0:01:46\n",
      "   ------------------------ --------------- 1.6/2.6 GB 9.2 MB/s eta 0:01:46\n",
      "   ------------------------ --------------- 1.6/2.6 GB 9.2 MB/s eta 0:01:46\n",
      "   ------------------------ --------------- 1.6/2.6 GB 9.1 MB/s eta 0:01:47\n",
      "   ------------------------ --------------- 1.6/2.6 GB 9.1 MB/s eta 0:01:48\n",
      "   ------------------------ --------------- 1.6/2.6 GB 9.0 MB/s eta 0:01:49\n",
      "   ------------------------ --------------- 1.6/2.6 GB 9.0 MB/s eta 0:01:49\n",
      "   ------------------------ --------------- 1.6/2.6 GB 8.9 MB/s eta 0:01:49\n",
      "   ------------------------ --------------- 1.6/2.6 GB 8.9 MB/s eta 0:01:50\n",
      "   ------------------------- -------------- 1.6/2.6 GB 8.8 MB/s eta 0:01:50\n",
      "   ------------------------- -------------- 1.6/2.6 GB 8.8 MB/s eta 0:01:50\n",
      "   ------------------------- -------------- 1.6/2.6 GB 8.8 MB/s eta 0:01:51\n",
      "   ------------------------- -------------- 1.6/2.6 GB 8.7 MB/s eta 0:01:52\n",
      "   ------------------------- -------------- 1.6/2.6 GB 8.7 MB/s eta 0:01:51\n",
      "   ------------------------- -------------- 1.6/2.6 GB 8.7 MB/s eta 0:01:52\n",
      "   ------------------------- -------------- 1.6/2.6 GB 8.6 MB/s eta 0:01:52\n",
      "   ------------------------- -------------- 1.6/2.6 GB 8.6 MB/s eta 0:01:52\n",
      "   ------------------------- -------------- 1.6/2.6 GB 8.6 MB/s eta 0:01:52\n",
      "   ------------------------- -------------- 1.6/2.6 GB 8.6 MB/s eta 0:01:52\n",
      "   ------------------------- -------------- 1.6/2.6 GB 8.6 MB/s eta 0:01:52\n",
      "   ------------------------- -------------- 1.6/2.6 GB 8.6 MB/s eta 0:01:52\n",
      "   ------------------------- -------------- 1.6/2.6 GB 8.5 MB/s eta 0:01:53\n",
      "   ------------------------- -------------- 1.6/2.6 GB 8.5 MB/s eta 0:01:52\n",
      "   ------------------------- -------------- 1.6/2.6 GB 8.5 MB/s eta 0:01:52\n",
      "   ------------------------- -------------- 1.6/2.6 GB 8.4 MB/s eta 0:01:53\n",
      "   ------------------------- -------------- 1.6/2.6 GB 8.4 MB/s eta 0:01:53\n",
      "   ------------------------- -------------- 1.6/2.6 GB 8.4 MB/s eta 0:01:53\n",
      "   ------------------------- -------------- 1.6/2.6 GB 8.4 MB/s eta 0:01:52\n",
      "   ------------------------- -------------- 1.6/2.6 GB 8.4 MB/s eta 0:01:52\n",
      "   ------------------------- -------------- 1.6/2.6 GB 8.4 MB/s eta 0:01:52\n",
      "   ------------------------- -------------- 1.6/2.6 GB 8.4 MB/s eta 0:01:52\n",
      "   ------------------------- -------------- 1.6/2.6 GB 8.4 MB/s eta 0:01:52\n",
      "   ------------------------- -------------- 1.6/2.6 GB 8.4 MB/s eta 0:01:52\n",
      "   ------------------------- -------------- 1.7/2.6 GB 8.4 MB/s eta 0:01:51\n",
      "   ------------------------- -------------- 1.7/2.6 GB 8.3 MB/s eta 0:01:52\n",
      "   ------------------------- -------------- 1.7/2.6 GB 8.4 MB/s eta 0:01:52\n",
      "   ------------------------- -------------- 1.7/2.6 GB 8.3 MB/s eta 0:01:52\n",
      "   ------------------------- -------------- 1.7/2.6 GB 8.3 MB/s eta 0:01:53\n",
      "   ------------------------- -------------- 1.7/2.6 GB 8.3 MB/s eta 0:01:52\n",
      "   ------------------------- -------------- 1.7/2.6 GB 8.2 MB/s eta 0:01:52\n",
      "   ------------------------- -------------- 1.7/2.6 GB 8.2 MB/s eta 0:01:53\n",
      "   ------------------------- -------------- 1.7/2.6 GB 8.1 MB/s eta 0:01:54\n",
      "   ------------------------- -------------- 1.7/2.6 GB 8.1 MB/s eta 0:01:54\n",
      "   ------------------------- -------------- 1.7/2.6 GB 8.1 MB/s eta 0:01:54\n",
      "   ------------------------- -------------- 1.7/2.6 GB 8.0 MB/s eta 0:01:55\n",
      "   ------------------------- -------------- 1.7/2.6 GB 8.1 MB/s eta 0:01:54\n",
      "   ------------------------- -------------- 1.7/2.6 GB 8.0 MB/s eta 0:01:55\n",
      "   ------------------------- -------------- 1.7/2.6 GB 8.0 MB/s eta 0:01:55\n",
      "   ------------------------- -------------- 1.7/2.6 GB 7.9 MB/s eta 0:01:56\n",
      "   ------------------------- -------------- 1.7/2.6 GB 7.8 MB/s eta 0:01:57\n",
      "   ------------------------- -------------- 1.7/2.6 GB 7.7 MB/s eta 0:01:59\n",
      "   ------------------------- -------------- 1.7/2.6 GB 7.7 MB/s eta 0:02:00\n",
      "   ------------------------- -------------- 1.7/2.6 GB 7.6 MB/s eta 0:02:00\n",
      "   ------------------------- -------------- 1.7/2.6 GB 7.6 MB/s eta 0:02:01\n",
      "   ------------------------- -------------- 1.7/2.6 GB 7.5 MB/s eta 0:02:01\n",
      "   ------------------------- -------------- 1.7/2.6 GB 7.5 MB/s eta 0:02:02\n",
      "   ------------------------- -------------- 1.7/2.6 GB 7.4 MB/s eta 0:02:03\n",
      "   -------------------------- ------------- 1.7/2.6 GB 7.3 MB/s eta 0:02:04\n",
      "   -------------------------- ------------- 1.7/2.6 GB 7.2 MB/s eta 0:02:05\n",
      "   -------------------------- ------------- 1.7/2.6 GB 7.2 MB/s eta 0:02:06\n",
      "   -------------------------- ------------- 1.7/2.6 GB 7.1 MB/s eta 0:02:07\n",
      "   -------------------------- ------------- 1.7/2.6 GB 7.1 MB/s eta 0:02:07\n",
      "   -------------------------- ------------- 1.7/2.6 GB 7.1 MB/s eta 0:02:07\n",
      "   -------------------------- ------------- 1.7/2.6 GB 7.1 MB/s eta 0:02:08\n",
      "   -------------------------- ------------- 1.7/2.6 GB 7.1 MB/s eta 0:02:08\n",
      "   -------------------------- ------------- 1.7/2.6 GB 7.0 MB/s eta 0:02:08\n",
      "   -------------------------- ------------- 1.7/2.6 GB 7.0 MB/s eta 0:02:09\n",
      "   -------------------------- ------------- 1.7/2.6 GB 6.9 MB/s eta 0:02:09\n",
      "   -------------------------- ------------- 1.7/2.6 GB 6.9 MB/s eta 0:02:10\n",
      "   -------------------------- ------------- 1.7/2.6 GB 6.9 MB/s eta 0:02:09\n",
      "   -------------------------- ------------- 1.7/2.6 GB 6.9 MB/s eta 0:02:09\n",
      "   -------------------------- ------------- 1.7/2.6 GB 6.9 MB/s eta 0:02:08\n",
      "   -------------------------- ------------- 1.7/2.6 GB 6.9 MB/s eta 0:02:09\n",
      "   -------------------------- ------------- 1.7/2.6 GB 6.9 MB/s eta 0:02:09\n",
      "   -------------------------- ------------- 1.7/2.6 GB 6.8 MB/s eta 0:02:10\n",
      "   -------------------------- ------------- 1.7/2.6 GB 6.9 MB/s eta 0:02:09\n",
      "   -------------------------- ------------- 1.7/2.6 GB 6.8 MB/s eta 0:02:09\n",
      "   -------------------------- ------------- 1.7/2.6 GB 6.8 MB/s eta 0:02:10\n",
      "   -------------------------- ------------- 1.7/2.6 GB 6.8 MB/s eta 0:02:10\n",
      "   -------------------------- ------------- 1.7/2.6 GB 6.8 MB/s eta 0:02:09\n",
      "   -------------------------- ------------- 1.7/2.6 GB 6.8 MB/s eta 0:02:09\n",
      "   -------------------------- ------------- 1.7/2.6 GB 6.8 MB/s eta 0:02:09\n",
      "   -------------------------- ------------- 1.7/2.6 GB 6.7 MB/s eta 0:02:09\n",
      "   -------------------------- ------------- 1.7/2.6 GB 6.7 MB/s eta 0:02:10\n",
      "   -------------------------- ------------- 1.7/2.6 GB 6.7 MB/s eta 0:02:09\n",
      "   -------------------------- ------------- 1.7/2.6 GB 6.7 MB/s eta 0:02:09\n",
      "   -------------------------- ------------- 1.7/2.6 GB 6.8 MB/s eta 0:02:07\n",
      "   -------------------------- ------------- 1.7/2.6 GB 6.9 MB/s eta 0:02:04\n",
      "   -------------------------- ------------- 1.7/2.6 GB 7.0 MB/s eta 0:02:03\n",
      "   -------------------------- ------------- 1.7/2.6 GB 6.9 MB/s eta 0:02:03\n",
      "   -------------------------- ------------- 1.7/2.6 GB 7.0 MB/s eta 0:02:03\n",
      "   -------------------------- ------------- 1.7/2.6 GB 7.0 MB/s eta 0:02:02\n",
      "   -------------------------- ------------- 1.7/2.6 GB 7.1 MB/s eta 0:02:00\n",
      "   -------------------------- ------------- 1.7/2.6 GB 7.2 MB/s eta 0:01:58\n",
      "   --------------------------- ------------ 1.7/2.6 GB 7.2 MB/s eta 0:01:57\n",
      "   --------------------------- ------------ 1.7/2.6 GB 7.3 MB/s eta 0:01:55\n",
      "   --------------------------- ------------ 1.8/2.6 GB 7.4 MB/s eta 0:01:54\n",
      "   --------------------------- ------------ 1.8/2.6 GB 7.4 MB/s eta 0:01:52\n",
      "   --------------------------- ------------ 1.8/2.6 GB 7.6 MB/s eta 0:01:50\n",
      "   --------------------------- ------------ 1.8/2.6 GB 7.7 MB/s eta 0:01:48\n",
      "   --------------------------- ------------ 1.8/2.6 GB 7.7 MB/s eta 0:01:46\n",
      "   --------------------------- ------------ 1.8/2.6 GB 7.8 MB/s eta 0:01:46\n",
      "   --------------------------- ------------ 1.8/2.6 GB 7.8 MB/s eta 0:01:44\n",
      "   --------------------------- ------------ 1.8/2.6 GB 7.9 MB/s eta 0:01:42\n",
      "   --------------------------- ------------ 1.8/2.6 GB 8.0 MB/s eta 0:01:41\n",
      "   --------------------------- ------------ 1.8/2.6 GB 8.0 MB/s eta 0:01:40\n",
      "   --------------------------- ------------ 1.8/2.6 GB 8.1 MB/s eta 0:01:39\n",
      "   --------------------------- ------------ 1.8/2.6 GB 8.2 MB/s eta 0:01:37\n",
      "   --------------------------- ------------ 1.8/2.6 GB 8.3 MB/s eta 0:01:36\n",
      "   --------------------------- ------------ 1.8/2.6 GB 8.3 MB/s eta 0:01:34\n",
      "   --------------------------- ------------ 1.8/2.6 GB 8.3 MB/s eta 0:01:34\n",
      "   ---------------------------- ----------- 1.8/2.6 GB 8.5 MB/s eta 0:01:32\n",
      "   ---------------------------- ----------- 1.8/2.6 GB 8.6 MB/s eta 0:01:30\n",
      "   ---------------------------- ----------- 1.8/2.6 GB 8.7 MB/s eta 0:01:28\n",
      "   ---------------------------- ----------- 1.8/2.6 GB 8.8 MB/s eta 0:01:27\n",
      "   ---------------------------- ----------- 1.8/2.6 GB 8.8 MB/s eta 0:01:26\n",
      "   ---------------------------- ----------- 1.8/2.6 GB 8.9 MB/s eta 0:01:25\n",
      "   ---------------------------- ----------- 1.8/2.6 GB 9.0 MB/s eta 0:01:23\n",
      "   ---------------------------- ----------- 1.8/2.6 GB 9.3 MB/s eta 0:01:20\n",
      "   ---------------------------- ----------- 1.9/2.6 GB 9.6 MB/s eta 0:01:17\n",
      "   ---------------------------- ----------- 1.9/2.6 GB 9.8 MB/s eta 0:01:14\n",
      "   ---------------------------- ----------- 1.9/2.6 GB 10.1 MB/s eta 0:01:12\n",
      "   ---------------------------- ----------- 1.9/2.6 GB 10.2 MB/s eta 0:01:11\n",
      "   ---------------------------- ----------- 1.9/2.6 GB 10.2 MB/s eta 0:01:10\n",
      "   ----------------------------- ---------- 1.9/2.6 GB 10.6 MB/s eta 0:01:07\n",
      "   ----------------------------- ---------- 1.9/2.6 GB 10.9 MB/s eta 0:01:05\n",
      "   ----------------------------- ---------- 1.9/2.6 GB 11.2 MB/s eta 0:01:03\n",
      "   ----------------------------- ---------- 1.9/2.6 GB 11.5 MB/s eta 0:01:01\n",
      "   ----------------------------- ---------- 1.9/2.6 GB 11.8 MB/s eta 0:00:59\n",
      "   ----------------------------- ---------- 1.9/2.6 GB 11.8 MB/s eta 0:00:59\n",
      "   ----------------------------- ---------- 1.9/2.6 GB 12.1 MB/s eta 0:00:57\n",
      "   ----------------------------- ---------- 1.9/2.6 GB 12.3 MB/s eta 0:00:55\n",
      "   ----------------------------- ---------- 1.9/2.6 GB 12.7 MB/s eta 0:00:53\n",
      "   ----------------------------- ---------- 1.9/2.6 GB 13.0 MB/s eta 0:00:52\n",
      "   ----------------------------- ---------- 1.9/2.6 GB 13.1 MB/s eta 0:00:51\n",
      "   ----------------------------- ---------- 1.9/2.6 GB 13.7 MB/s eta 0:00:49\n",
      "   ----------------------------- ---------- 1.9/2.6 GB 14.3 MB/s eta 0:00:46\n",
      "   ----------------------------- ---------- 1.9/2.6 GB 15.0 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 1.9/2.6 GB 15.8 MB/s eta 0:00:41\n",
      "   ------------------------------ --------- 1.9/2.6 GB 17.3 MB/s eta 0:00:37\n",
      "   ------------------------------ --------- 2.0/2.6 GB 17.9 MB/s eta 0:00:36\n",
      "   ------------------------------ --------- 2.0/2.6 GB 18.3 MB/s eta 0:00:35\n",
      "   ------------------------------ --------- 2.0/2.6 GB 18.6 MB/s eta 0:00:34\n",
      "   ------------------------------ --------- 2.0/2.6 GB 19.0 MB/s eta 0:00:33\n",
      "   ------------------------------ --------- 2.0/2.6 GB 19.2 MB/s eta 0:00:33\n",
      "   ------------------------------ --------- 2.0/2.6 GB 19.1 MB/s eta 0:00:33\n",
      "   ------------------------------ --------- 2.0/2.6 GB 19.5 MB/s eta 0:00:32\n",
      "   ------------------------------ --------- 2.0/2.6 GB 19.7 MB/s eta 0:00:31\n",
      "   ------------------------------ --------- 2.0/2.6 GB 20.0 MB/s eta 0:00:31\n",
      "   ------------------------------ --------- 2.0/2.6 GB 20.0 MB/s eta 0:00:30\n",
      "   ------------------------------ --------- 2.0/2.6 GB 20.2 MB/s eta 0:00:30\n",
      "   ------------------------------ --------- 2.0/2.6 GB 20.6 MB/s eta 0:00:29\n",
      "   ------------------------------ --------- 2.0/2.6 GB 20.7 MB/s eta 0:00:29\n",
      "   ------------------------------- -------- 2.0/2.6 GB 21.0 MB/s eta 0:00:28\n",
      "   ------------------------------- -------- 2.0/2.6 GB 21.2 MB/s eta 0:00:28\n",
      "   ------------------------------- -------- 2.0/2.6 GB 21.4 MB/s eta 0:00:27\n",
      "   ------------------------------- -------- 2.0/2.6 GB 21.4 MB/s eta 0:00:27\n",
      "   ------------------------------- -------- 2.0/2.6 GB 21.5 MB/s eta 0:00:27\n",
      "   ------------------------------- -------- 2.0/2.6 GB 21.6 MB/s eta 0:00:26\n",
      "   ------------------------------- -------- 2.0/2.6 GB 21.8 MB/s eta 0:00:26\n",
      "   ------------------------------- -------- 2.0/2.6 GB 21.8 MB/s eta 0:00:26\n",
      "   ------------------------------- -------- 2.0/2.6 GB 21.9 MB/s eta 0:00:25\n",
      "   ------------------------------- -------- 2.0/2.6 GB 21.9 MB/s eta 0:00:25\n",
      "   ------------------------------- -------- 2.0/2.6 GB 22.0 MB/s eta 0:00:25\n",
      "   ------------------------------- -------- 2.1/2.6 GB 21.9 MB/s eta 0:00:25\n",
      "   ------------------------------- -------- 2.1/2.6 GB 21.8 MB/s eta 0:00:25\n",
      "   ------------------------------- -------- 2.1/2.6 GB 21.7 MB/s eta 0:00:25\n",
      "   ------------------------------- -------- 2.1/2.6 GB 21.7 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 2.1/2.6 GB 21.7 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 2.1/2.6 GB 21.7 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 2.1/2.6 GB 21.4 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 2.1/2.6 GB 21.4 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 2.1/2.6 GB 21.3 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 2.1/2.6 GB 21.4 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 2.1/2.6 GB 21.4 MB/s eta 0:00:23\n",
      "   -------------------------------- ------- 2.1/2.6 GB 21.3 MB/s eta 0:00:23\n",
      "   -------------------------------- ------- 2.1/2.6 GB 21.2 MB/s eta 0:00:23\n",
      "   -------------------------------- ------- 2.1/2.6 GB 21.2 MB/s eta 0:00:23\n",
      "   -------------------------------- ------- 2.1/2.6 GB 21.1 MB/s eta 0:00:23\n",
      "   -------------------------------- ------- 2.1/2.6 GB 21.0 MB/s eta 0:00:23\n",
      "   -------------------------------- ------- 2.1/2.6 GB 20.7 MB/s eta 0:00:23\n",
      "   -------------------------------- ------- 2.1/2.6 GB 20.7 MB/s eta 0:00:23\n",
      "   -------------------------------- ------- 2.1/2.6 GB 20.5 MB/s eta 0:00:23\n",
      "   -------------------------------- ------- 2.1/2.6 GB 20.3 MB/s eta 0:00:23\n",
      "   --------------------------------- ------ 2.1/2.6 GB 20.6 MB/s eta 0:00:22\n",
      "   --------------------------------- ------ 2.1/2.6 GB 20.4 MB/s eta 0:00:22\n",
      "   --------------------------------- ------ 2.1/2.6 GB 20.5 MB/s eta 0:00:22\n",
      "   --------------------------------- ------ 2.1/2.6 GB 20.5 MB/s eta 0:00:22\n",
      "   --------------------------------- ------ 2.1/2.6 GB 20.4 MB/s eta 0:00:22\n",
      "   --------------------------------- ------ 2.2/2.6 GB 20.3 MB/s eta 0:00:22\n",
      "   --------------------------------- ------ 2.2/2.6 GB 20.3 MB/s eta 0:00:22\n",
      "   --------------------------------- ------ 2.2/2.6 GB 20.3 MB/s eta 0:00:21\n",
      "   --------------------------------- ------ 2.2/2.6 GB 20.4 MB/s eta 0:00:21\n",
      "   --------------------------------- ------ 2.2/2.6 GB 20.3 MB/s eta 0:00:21\n",
      "   --------------------------------- ------ 2.2/2.6 GB 20.2 MB/s eta 0:00:21\n",
      "   --------------------------------- ------ 2.2/2.6 GB 20.1 MB/s eta 0:00:21\n",
      "   --------------------------------- ------ 2.2/2.6 GB 20.1 MB/s eta 0:00:20\n",
      "   --------------------------------- ------ 2.2/2.6 GB 20.0 MB/s eta 0:00:20\n",
      "   --------------------------------- ------ 2.2/2.6 GB 20.1 MB/s eta 0:00:20\n",
      "   ---------------------------------- ----- 2.2/2.6 GB 20.2 MB/s eta 0:00:20\n",
      "   ---------------------------------- ----- 2.2/2.6 GB 20.1 MB/s eta 0:00:19\n",
      "   ---------------------------------- ----- 2.2/2.6 GB 19.9 MB/s eta 0:00:19\n",
      "   ---------------------------------- ----- 2.2/2.6 GB 19.8 MB/s eta 0:00:19\n",
      "   ---------------------------------- ----- 2.2/2.6 GB 19.6 MB/s eta 0:00:19\n",
      "   ---------------------------------- ----- 2.2/2.6 GB 19.5 MB/s eta 0:00:19\n",
      "   ---------------------------------- ----- 2.2/2.6 GB 19.3 MB/s eta 0:00:20\n",
      "   ---------------------------------- ----- 2.2/2.6 GB 19.0 MB/s eta 0:00:20\n",
      "   ---------------------------------- ----- 2.2/2.6 GB 19.0 MB/s eta 0:00:20\n",
      "   ---------------------------------- ----- 2.2/2.6 GB 18.9 MB/s eta 0:00:20\n",
      "   ---------------------------------- ----- 2.2/2.6 GB 18.7 MB/s eta 0:00:20\n",
      "   ---------------------------------- ----- 2.2/2.6 GB 18.4 MB/s eta 0:00:20\n",
      "   ---------------------------------- ----- 2.2/2.6 GB 18.4 MB/s eta 0:00:20\n",
      "   ---------------------------------- ----- 2.2/2.6 GB 18.7 MB/s eta 0:00:19\n",
      "   ---------------------------------- ----- 2.2/2.6 GB 18.7 MB/s eta 0:00:19\n",
      "   ---------------------------------- ----- 2.2/2.6 GB 18.6 MB/s eta 0:00:19\n",
      "   ---------------------------------- ----- 2.2/2.6 GB 18.6 MB/s eta 0:00:19\n",
      "   ---------------------------------- ----- 2.2/2.6 GB 18.4 MB/s eta 0:00:19\n",
      "   ---------------------------------- ----- 2.2/2.6 GB 18.4 MB/s eta 0:00:19\n",
      "   ---------------------------------- ----- 2.3/2.6 GB 18.4 MB/s eta 0:00:18\n",
      "   ---------------------------------- ----- 2.3/2.6 GB 18.3 MB/s eta 0:00:18\n",
      "   ---------------------------------- ----- 2.3/2.6 GB 18.1 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 2.3/2.6 GB 18.1 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 2.3/2.6 GB 17.9 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 2.3/2.6 GB 17.8 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 2.3/2.6 GB 17.7 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 2.3/2.6 GB 17.6 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 2.3/2.6 GB 17.7 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 2.3/2.6 GB 17.7 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 2.3/2.6 GB 17.6 MB/s eta 0:00:17\n",
      "   ----------------------------------- ---- 2.3/2.6 GB 17.6 MB/s eta 0:00:17\n",
      "   ----------------------------------- ---- 2.3/2.6 GB 17.6 MB/s eta 0:00:17\n",
      "   ----------------------------------- ---- 2.3/2.6 GB 17.6 MB/s eta 0:00:17\n",
      "   ----------------------------------- ---- 2.3/2.6 GB 17.6 MB/s eta 0:00:17\n",
      "   ----------------------------------- ---- 2.3/2.6 GB 17.6 MB/s eta 0:00:17\n",
      "   ----------------------------------- ---- 2.3/2.6 GB 17.6 MB/s eta 0:00:17\n",
      "   ----------------------------------- ---- 2.3/2.6 GB 16.7 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 2.3/2.6 GB 16.5 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 2.3/2.6 GB 16.6 MB/s eta 0:00:17\n",
      "   ----------------------------------- ---- 2.3/2.6 GB 16.6 MB/s eta 0:00:17\n",
      "   ----------------------------------- ---- 2.3/2.6 GB 16.6 MB/s eta 0:00:17\n",
      "   ----------------------------------- ---- 2.3/2.6 GB 16.6 MB/s eta 0:00:16\n",
      "   ----------------------------------- ---- 2.3/2.6 GB 16.6 MB/s eta 0:00:16\n",
      "   ------------------------------------ --- 2.3/2.6 GB 16.7 MB/s eta 0:00:16\n",
      "   ------------------------------------ --- 2.3/2.6 GB 16.7 MB/s eta 0:00:15\n",
      "   ------------------------------------ --- 2.3/2.6 GB 16.7 MB/s eta 0:00:15\n",
      "   ------------------------------------ --- 2.3/2.6 GB 16.7 MB/s eta 0:00:15\n",
      "   ------------------------------------ --- 2.3/2.6 GB 16.7 MB/s eta 0:00:15\n",
      "   ------------------------------------ --- 2.3/2.6 GB 16.6 MB/s eta 0:00:15\n",
      "   ------------------------------------ --- 2.4/2.6 GB 16.5 MB/s eta 0:00:15\n",
      "   ------------------------------------ --- 2.4/2.6 GB 16.4 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 2.4/2.6 GB 16.4 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 2.4/2.6 GB 16.4 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 2.4/2.6 GB 16.4 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 2.4/2.6 GB 16.3 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 2.4/2.6 GB 16.2 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 2.4/2.6 GB 16.1 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 2.4/2.6 GB 16.0 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 2.4/2.6 GB 16.1 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 2.4/2.6 GB 16.1 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 2.4/2.6 GB 15.7 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 2.4/2.6 GB 15.5 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 2.4/2.6 GB 15.4 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 2.4/2.6 GB 15.4 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 2.4/2.6 GB 15.0 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 2.4/2.6 GB 14.9 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 2.4/2.6 GB 14.7 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 2.4/2.6 GB 14.7 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 2.4/2.6 GB 14.4 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 2.4/2.6 GB 14.3 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 2.4/2.6 GB 14.3 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 2.4/2.6 GB 14.1 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 2.4/2.6 GB 14.0 MB/s eta 0:00:14\n",
      "   ------------------------------------- -- 2.4/2.6 GB 13.9 MB/s eta 0:00:14\n",
      "   ------------------------------------- -- 2.4/2.6 GB 13.7 MB/s eta 0:00:14\n",
      "   ------------------------------------- -- 2.4/2.6 GB 13.7 MB/s eta 0:00:14\n",
      "   ------------------------------------- -- 2.4/2.6 GB 13.7 MB/s eta 0:00:14\n",
      "   ------------------------------------- -- 2.4/2.6 GB 13.6 MB/s eta 0:00:14\n",
      "   ------------------------------------- -- 2.4/2.6 GB 13.5 MB/s eta 0:00:14\n",
      "   ------------------------------------- -- 2.4/2.6 GB 13.5 MB/s eta 0:00:14\n",
      "   ------------------------------------- -- 2.4/2.6 GB 13.2 MB/s eta 0:00:14\n",
      "   ------------------------------------- -- 2.4/2.6 GB 13.1 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 13.1 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 13.1 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 12.8 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 12.6 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 12.6 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 12.5 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 12.5 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 12.3 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 12.2 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 12.1 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 12.0 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 12.0 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 12.0 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 11.9 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 11.8 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 11.7 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 11.6 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 11.5 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 11.4 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 11.3 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 11.2 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 11.1 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 11.0 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 11.0 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 10.9 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 10.8 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 10.8 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 10.7 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 10.7 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 10.6 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.6 GB 10.6 MB/s eta 0:00:14\n",
      "   ------------------------------------- -- 2.4/2.6 GB 10.6 MB/s eta 0:00:14\n",
      "   ------------------------------------- -- 2.4/2.6 GB 10.5 MB/s eta 0:00:14\n",
      "   ------------------------------------- -- 2.4/2.6 GB 10.5 MB/s eta 0:00:14\n",
      "   ------------------------------------- -- 2.4/2.6 GB 10.5 MB/s eta 0:00:13\n",
      "   ------------------------------------- -- 2.5/2.6 GB 10.4 MB/s eta 0:00:13\n",
      "   -------------------------------------- - 2.5/2.6 GB 10.4 MB/s eta 0:00:13\n",
      "   -------------------------------------- - 2.5/2.6 GB 10.4 MB/s eta 0:00:12\n",
      "   -------------------------------------- - 2.5/2.6 GB 10.4 MB/s eta 0:00:12\n",
      "   -------------------------------------- - 2.5/2.6 GB 10.4 MB/s eta 0:00:11\n",
      "   -------------------------------------- - 2.5/2.6 GB 10.5 MB/s eta 0:00:11\n",
      "   -------------------------------------- - 2.5/2.6 GB 10.6 MB/s eta 0:00:10\n",
      "   -------------------------------------- - 2.5/2.6 GB 10.6 MB/s eta 0:00:10\n",
      "   -------------------------------------- - 2.5/2.6 GB 10.6 MB/s eta 0:00:10\n",
      "   -------------------------------------- - 2.5/2.6 GB 10.8 MB/s eta 0:00:09\n",
      "   -------------------------------------- - 2.5/2.6 GB 10.8 MB/s eta 0:00:09\n",
      "   -------------------------------------- - 2.5/2.6 GB 10.8 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 2.5/2.6 GB 10.9 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 2.5/2.6 GB 10.9 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 2.5/2.6 GB 10.9 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 2.5/2.6 GB 10.9 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 2.5/2.6 GB 10.8 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 2.5/2.6 GB 10.8 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 2.5/2.6 GB 10.7 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 2.5/2.6 GB 10.7 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 2.5/2.6 GB 10.6 MB/s eta 0:00:07\n",
      "   ---------------------------------------  2.5/2.6 GB 10.6 MB/s eta 0:00:07\n",
      "   ---------------------------------------  2.5/2.6 GB 10.6 MB/s eta 0:00:06\n",
      "   ---------------------------------------  2.5/2.6 GB 10.6 MB/s eta 0:00:06\n",
      "   ---------------------------------------  2.5/2.6 GB 10.5 MB/s eta 0:00:06\n",
      "   ---------------------------------------  2.5/2.6 GB 10.5 MB/s eta 0:00:06\n",
      "   ---------------------------------------  2.5/2.6 GB 10.5 MB/s eta 0:00:06\n",
      "   ---------------------------------------  2.5/2.6 GB 10.4 MB/s eta 0:00:05\n",
      "   ---------------------------------------  2.5/2.6 GB 10.4 MB/s eta 0:00:05\n",
      "   ---------------------------------------  2.5/2.6 GB 10.3 MB/s eta 0:00:05\n",
      "   ---------------------------------------  2.5/2.6 GB 10.3 MB/s eta 0:00:05\n",
      "   ---------------------------------------  2.5/2.6 GB 10.3 MB/s eta 0:00:04\n",
      "   ---------------------------------------  2.5/2.6 GB 10.2 MB/s eta 0:00:04\n",
      "   ---------------------------------------  2.5/2.6 GB 10.2 MB/s eta 0:00:04\n",
      "   ---------------------------------------  2.6/2.6 GB 10.2 MB/s eta 0:00:04\n",
      "   ---------------------------------------  2.6/2.6 GB 10.2 MB/s eta 0:00:03\n",
      "   ---------------------------------------  2.6/2.6 GB 10.1 MB/s eta 0:00:03\n",
      "   ---------------------------------------  2.6/2.6 GB 10.0 MB/s eta 0:00:03\n",
      "   ---------------------------------------  2.6/2.6 GB 10.0 MB/s eta 0:00:03\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:03\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:03\n",
      "   ---------------------------------------  2.6/2.6 GB 9.8 MB/s eta 0:00:03\n",
      "   ---------------------------------------  2.6/2.6 GB 9.8 MB/s eta 0:00:03\n",
      "   ---------------------------------------  2.6/2.6 GB 10.0 MB/s eta 0:00:03\n",
      "   ---------------------------------------  2.6/2.6 GB 10.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  2.6/2.6 GB 10.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  2.6/2.6 GB 10.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 GB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 GB 7.6 MB/s eta 0:00:00\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.9.0\n",
      "    Uninstalling torch-2.9.0:\n",
      "      Successfully uninstalled torch-2.9.0\n",
      "Successfully installed torch-2.9.1+cu126 torchvision-0.24.1+cu126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\~orch'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.7.1 requires torch==2.7.1, but you have torch 2.9.1+cu126 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    " !pip install torch torchvision --index-url https://download.pytorch.org/whl/cu126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bc60a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1+cu126\n",
      "True\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__ )\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15af4f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allocated: 0.0 GB\n"
     ]
    }
   ],
   "source": [
    "print(\"allocated:\", torch.cuda.memory_allocated(0) / 1e9, \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f10335a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env in project root\n",
    "load_dotenv()\n",
    "\n",
    "googleAPIKey = os.getenv('googleAPIKey')\n",
    "gptkey =  os.getenv('myAPIKey')\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = googleAPIKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f489afdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoModelForSequenceClassification,AutoTokenizer , pipeline\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain import hub\n",
    "\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import json\n",
    "import glob\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f13b12",
   "metadata": {},
   "source": [
    "## Load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fa42b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dir = \"C:\\\\uit_HK5\\\\CS431\\\\final_project\\\\data\\\\metadata.json\"\n",
    "transcript_dir = \"C:\\\\uit_HK5\\\\CS431\\\\final_project\\\\data\\\\transcripts_final\"\n",
    "output_dir = \"C:\\\\uit_HK5\\\\CS431\\\\final_project\\\\data\\\\semantic_chunks\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3d51e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "class Loader:\n",
    "    @staticmethod\n",
    "    def parse_transcript(file_path: str) -> tuple[str, list[dict], str]:\n",
    "        \"\"\"c file transcript, tch tng dng thnh block c start-end-text\"\"\"\n",
    "        full_text = \"\"\n",
    "        position_map = []  # lu v tr start ca mi on text trong full_text\n",
    "\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line or \"[m nhc]\" in line.lower():\n",
    "                    continue\n",
    "                filename = os.path.basename(file_path).replace(\".txt\", \"\") # ly file name\n",
    "                match = re.match(r\"(\\d+:\\d+:\\d+)\\s*-\\s*(\\d+:\\d+:\\d+),\\s*(.+)\", line)\n",
    "                if match:\n",
    "                    start, end, text = match.groups()\n",
    "                    pos = len(full_text)\n",
    "                    full_text += text + \" \"\n",
    "                    position_map.append({\n",
    "                        \"start\": start,\n",
    "                        \"end\": end,\n",
    "                        \"text\": text,\n",
    "                        \"pos_start\": pos, # v tr bt u ca on text trong full_text\n",
    "                        \"pos_end\": len(full_text) # v tr kt thc ca on text trong full_text\n",
    "                    })\n",
    "\n",
    "        return full_text.strip(), position_map, filename\n",
    "    \n",
    "    def map_metadata(self, metadata_path: str, filename: str) -> tuple[Union[str, None], Union[str, None]]:\n",
    "        \"\"\"c file metadata v tr v dict mapping id -> metadata\"\"\"\n",
    "\n",
    "        with open(metadata_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            metadata_list = json.load(f)\n",
    "        metadata = metadata_list[\"videos\"]\n",
    "\n",
    "        video_title, video_url = next(((item[\"title\"], item[\"url\"]) for item in metadata if item[\"video_id\"] == filename), (None, None))\n",
    "\n",
    "        return video_title, video_url\n",
    "    \n",
    "    def load_dir(self, transcript_dir: str, metadata_path: str) -> list[dict]:\n",
    "        \"\"\"c tt c file transcript trong th mc v tr v danh sch dict cha full_text, position_map, filename, title, url\"\"\"\n",
    "        import glob\n",
    "\n",
    "        file_paths = glob.glob(os.path.join(transcript_dir, \"*.txt\"))\n",
    "        data = []\n",
    "\n",
    "        for file_path in file_paths:\n",
    "            full_text, position_map, filename = self.parse_transcript(file_path)\n",
    "            title, url = self.map_metadata(metadata_path, filename)\n",
    "\n",
    "            data.append({\n",
    "                \"full_text\": full_text,\n",
    "                \"position_map\": position_map,\n",
    "                \"filename\": filename,\n",
    "                \"title\": title,\n",
    "                \"url\": url\n",
    "            })\n",
    "\n",
    "        return data\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3959c9a9",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9260c581",
   "metadata": {},
   "source": [
    "## Semantic"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "7573b359",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec452405",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyparsing import line\n",
    "\n",
    "\n",
    "class TranscriptChunker:\n",
    "    def __init__(self, open_api_key: str):\n",
    "        self.embeddings = OpenAIEmbeddings(\n",
    "            model=\"text-embedding-3-large\",\n",
    "            openai_api_key=open_api_key\n",
    "        )\n",
    "        self.splitter = SemanticChunker(\n",
    "            embeddings=self.embeddings,\n",
    "            breakpoint_threshold_type=\"percentile\",\n",
    "            breakpoint_threshold_amount=85,\n",
    "            min_chunk_size=300,\n",
    "\n",
    "            add_start_index=True,\n",
    "            buffer_size=1\n",
    "        )\n",
    "        self.loader = Loader()\n",
    "\n",
    "    def chunk_dir(self, transcript_dir: str, metadata_path: str, output_dir: str) -> list:\n",
    "        data = self.loader.load_dir(transcript_dir, metadata_path)\n",
    "        all_chunks = []\n",
    "\n",
    "        for item in data:\n",
    "            full_text = item[\"full_text\"]\n",
    "            position_map = item[\"position_map\"]\n",
    "            filename = item[\"filename\"]\n",
    "            title = item[\"title\"]\n",
    "            url = item[\"url\"]\n",
    "\n",
    "            # dng li logic mapping timestamp\n",
    "            chunks = self.splitter.create_documents(\n",
    "                texts=[full_text],\n",
    "                metadatas=[{\n",
    "                    \"video_url\": url,\n",
    "                    \"filename\": filename,\n",
    "                    \"title\": title\n",
    "                }]\n",
    "            )\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                start_index = chunk.metadata.pop(\"start_index\")\n",
    "                end_index = start_index + len(chunk.page_content)  # t tnh end_index\n",
    "\n",
    "                \n",
    "                # tm timestamp u tin bao ph on text ny\n",
    "                matched_ts = [\n",
    "                    pos for pos in position_map\n",
    "                    if not (pos[\"pos_end\"] < start_index or pos[\"pos_start\"] > end_index)\n",
    "                ]\n",
    "\n",
    "                if matched_ts:\n",
    "                    chunk.metadata[\"start_timestamp\"] = matched_ts[0][\"start\"]\n",
    "                    chunk.metadata[\"end_timestamp\"] = matched_ts[-1][\"end\"]\n",
    "                else:\n",
    "                    chunk.metadata[\"start_timestamp\"] = None\n",
    "                    chunk.metadata[\"end_timestamp\"] = None\n",
    "\n",
    "                chunk.metadata[\"chunk_id\"] = i\n",
    "            all_chunks.extend(chunks)\n",
    "        # lu tt c chunks vo file json\n",
    "        output_path = os.path.join(output_dir, \"semantic_chunks.json\")\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump([{\n",
    "                \"page_content\": chunk.page_content,\n",
    "                \"metadata\": chunk.metadata\n",
    "            } for chunk in all_chunks], f, ensure_ascii=False, indent=4)\n",
    "        print(f\"Saved {len(all_chunks)} chunks to {output_path}\")\n",
    "        return all_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "990fd650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 460 chunks to D:\\DAI_HOC\\CS431\\DoAn\\Rag_QABot\\data\\semantic_chunks\\semantic_chunks.json\n"
     ]
    }
   ],
   "source": [
    "splitter = TranscriptChunker(\n",
    "    open_api_key= gptkey\n",
    ")\n",
    "data = splitter.chunk_dir(transcript_dir, metadata_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60d6dde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nh vy th trong phn s 2 ny th chng ta  cng tm hiu v nhng ch  sau. u tin l chng ta tm hiu v maximum likelihood cho ci log ca PX. Chng ta mong mun c c mt m hnh  to ra mt ci nh x ging tht, ging vi li ci Pdata. Th th  t c ci vic ny th ci likelihood ca log P ny phi l ln nht. V khi a ci log ca PX ny ln cc i th n s a n mt ci gii php,  l chng ta s y ci chn di ca log P. Th  chnh l ci ELBO l evidence lower bound.\n",
      "0:00:14 0:01:06\n",
      "https://youtube.com/watch?v=--6FInuIyys\n",
      "[CS315 - Chng 3] Deep Generative Models (2) - Tng kt\n",
      "-----\n",
      "y ci ELBO ny ln, maximum ELBO ny ln. V khi chng ta maximum ELBO ny ln th chng ta s c hai ci m hnh,  l VAE v m hnh diffusion. V i vi ci m hnh diffusion th chng ta s c ci bc gi l khuch tn thun. V trong ci khuch tn thun ny th chng ta s thm nhiu vo ci nh ca mnh. V  y l chng ta khng c tham s  hc, khng c tham s hun luyn. Ci iu ny n gip cho chng ta n gin ha ci vic hun luyn ca ci m hnh diffusion m ch dnh ci d a  hun luyn cho ci phn denoising, phn kh nhiu. Chng ta ch hc kh nhiu v hc bng c ba cch. Cch u tin  l chng ta s ti u  sao cho ci x m theta xp x vi li x0. Cch th hai  l chng ta ti u ci epsilon theta sao cho xp x vi li ci epsilon. V cch s ba  l chng ta s ti u  cho ci x m theta xp x vi li ci gradient ca log p theta. Th y ging nh l ci hng  kh nhiu ca mnh.\n",
      "0:00:58 0:02:29\n",
      "https://youtube.com/watch?v=--6FInuIyys\n",
      "[CS315 - Chng 3] Deep Generative Models (2) - Tng kt\n",
      "-----\n",
      "Th y l ba ci cch. V sau  th chng ta  tm hiu v cch  iu hng vi hai k thut  l classifier guidance. Vi mi mt ci condition mi, th mt ci condition chng ta s ra mt ci classifier. Nh vy th n s khng c linh ng trong ci vic l update hoc l thay ci condition. Chng ta s c k thut khc ci tin  chnh l classifier free guidance. Tc l chng ta s b lun ci classifier ny m chng ta ch i fine-tune li ci m hnh diffusion. Ch fine-tune li diffusion, khng c dng thm ci classifier no  cho n c th l train c t u, fine-tune t u n cui. Sau  chng ta  ni qua nhng ci vn  v  phn gii khi chng ta lm vic vi latent, xin li khi lm vic vi diffusion. V ci k thut m cascade diffusion th n rt l cng knh. V n phi s dng n hai ba ci m hnh ni tip nhau v c lp nhau.\n",
      "0:02:26 0:03:43\n",
      "https://youtube.com/watch?v=--6FInuIyys\n",
      "[CS315 - Chng 3] Deep Generative Models (2) - Tng kt\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "#test print first 3 chunks\n",
    "for chunk in data[:3]:\n",
    "    print(chunk.page_content)\n",
    "    print(chunk.metadata[\"start_timestamp\"], chunk.metadata[\"end_timestamp\"])\n",
    "    print(chunk.metadata[\"video_url\"])\n",
    "    print(chunk.metadata[\"title\"])\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97fcf4a",
   "metadata": {},
   "source": [
    "## recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ef65d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "class TranscriptChunker:\n",
    "    def __init__(self):\n",
    "        # Recursive chunker\n",
    "        self.splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,        # kch thc chunk ti a\n",
    "            chunk_overlap=50       # overlap gia cc chunk\n",
    "        )\n",
    "        self.loader = Loader()  # gi s bn  nh ngha Loader\n",
    "\n",
    "    def chunk_dir(self, transcript_dir: str, metadata_path: str, output_dir: str) -> list:\n",
    "        data = self.loader.load_dir(transcript_dir, metadata_path)\n",
    "        all_chunks = []\n",
    "\n",
    "        for item in data:\n",
    "            full_text = item[\"full_text\"]\n",
    "            position_map = item[\"position_map\"]\n",
    "            filename = item[\"filename\"]\n",
    "            title = item[\"title\"]\n",
    "            url = item[\"url\"]\n",
    "\n",
    "            # chia chunk bng recursive splitter\n",
    "            text_chunks = self.splitter.split_text(full_text)\n",
    "\n",
    "            chunks = []\n",
    "            start_idx = 0\n",
    "            for i, chunk_text in enumerate(text_chunks):\n",
    "                end_idx = start_idx + len(chunk_text)\n",
    "\n",
    "                # tm timestamp u tin bao ph on text ny\n",
    "                matched_ts = [\n",
    "                    pos for pos in position_map\n",
    "                    if not (pos[\"pos_end\"] < start_idx or pos[\"pos_start\"] > end_idx)\n",
    "                ]\n",
    "\n",
    "                metadata = {\n",
    "                    \"video_url\": url,\n",
    "                    \"filename\": filename,\n",
    "                    \"title\": title,\n",
    "                    \"chunk_id\": i,\n",
    "                    \"start_timestamp\": matched_ts[0][\"start\"] if matched_ts else None,\n",
    "                    \"end_timestamp\": matched_ts[-1][\"end\"] if matched_ts else None\n",
    "                }\n",
    "\n",
    "                chunks.append(Document(page_content=chunk_text, metadata=metadata))\n",
    "                start_idx = end_idx\n",
    "\n",
    "            all_chunks.extend(chunks)\n",
    "\n",
    "        # lu tt c chunks vo file json\n",
    "        output_path = os.path.join(output_dir, \"recursive_chunks.json\")\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump([{\n",
    "                \"page_content\": chunk.page_content,\n",
    "                \"metadata\": chunk.metadata\n",
    "            } for chunk in all_chunks], f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        print(f\"Saved {len(all_chunks)} chunks to {output_path}\")\n",
    "        return all_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d1f024a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1476 chunks to D:\\DAI_HOC\\CS431\\DoAn\\Rag_QABot\\data\\semantic_chunks\\recursive_chunks.json\n"
     ]
    }
   ],
   "source": [
    "splitter = TranscriptChunker()\n",
    "data = splitter.chunk_dir(transcript_dir, metadata_dir, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23d4c43",
   "metadata": {},
   "source": [
    "## lu db recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea04c070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c746f31",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\langchain_huggingface\\embeddings\\huggingface.py:66\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\Phuc3\\lib\\site-packages\\sentence_transformers\\__init__.py:15\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     export_dynamic_quantized_onnx_model,\n\u001b[0;32m     12\u001b[0m     export_optimized_onnx_model,\n\u001b[0;32m     13\u001b[0m     export_static_quantized_openvino_model,\n\u001b[0;32m     14\u001b[0m )\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     CrossEncoder,\n\u001b[0;32m     17\u001b[0m     CrossEncoderModelCardData,\n\u001b[0;32m     18\u001b[0m     CrossEncoderTrainer,\n\u001b[0;32m     19\u001b[0m     CrossEncoderTrainingArguments,\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\Phuc3\\lib\\site-packages\\sentence_transformers\\cross_encoder\\__init__.py:5\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_card\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderModelCardData\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderTrainer\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining_args\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderTrainingArguments\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\Phuc3\\lib\\site-packages\\sentence_transformers\\cross_encoder\\trainer.py:22\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceEvaluator, SequentialEvaluator\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformerTrainer\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_datasets_available, is_training_available\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\Phuc3\\lib\\site-packages\\sentence_transformers\\trainer.py:16\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BatchSampler, ConcatDataset, DataLoader, RandomSampler\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EvalPrediction, PreTrainedTokenizerBase, Trainer, TrainerCallback\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m transformers_version\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\Phuc3\\lib\\site-packages\\transformers\\utils\\import_utils.py:2317\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2316\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2317\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2318\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\Phuc3\\lib\\site-packages\\transformers\\utils\\import_utils.py:2347\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   2346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 2347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\Phuc3\\lib\\site-packages\\transformers\\utils\\import_utils.py:2345\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   2344\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\Phuc3\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\Phuc3\\lib\\site-packages\\transformers\\trainer.py:220\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_peft_available():\n\u001b[1;32m--> 220\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpeft\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PeftModel\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_accelerate_available():\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\peft\\__init__.py:17\u001b[0m\n\u001b[0;32m     15\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.17.1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     18\u001b[0m     MODEL_TYPE_TO_PEFT_MODEL_MAPPING,\n\u001b[0;32m     19\u001b[0m     AutoPeftModel,\n\u001b[0;32m     20\u001b[0m     AutoPeftModelForCausalLM,\n\u001b[0;32m     21\u001b[0m     AutoPeftModelForFeatureExtraction,\n\u001b[0;32m     22\u001b[0m     AutoPeftModelForQuestionAnswering,\n\u001b[0;32m     23\u001b[0m     AutoPeftModelForSeq2SeqLM,\n\u001b[0;32m     24\u001b[0m     AutoPeftModelForSequenceClassification,\n\u001b[0;32m     25\u001b[0m     AutoPeftModelForTokenClassification,\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PeftConfig, PromptLearningConfig\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\peft\\auto.py:31\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     22\u001b[0m     AutoModel,\n\u001b[0;32m     23\u001b[0m     AutoModelForCausalLM,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m     AutoTokenizer,\n\u001b[0;32m     29\u001b[0m )\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PeftConfig\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpeft_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     33\u001b[0m     PeftModel,\n\u001b[0;32m     34\u001b[0m     PeftModelForCausalLM,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m     PeftModelForTokenClassification,\n\u001b[0;32m     40\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\peft\\config.py:24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PushToHubMixin, http_user_agent\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CONFIG_NAME, PeftType, TaskType\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# we expect at least these keys to be present in a PEFT adapter_config.json\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\peft\\utils\\__init__.py:16\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m map_cache_to_layer_device_map\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloftq_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m replace_lora_weights_loftq\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mother\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     18\u001b[0m     CONFIG_NAME,\n\u001b[0;32m     19\u001b[0m     INCLUDE_LINEAR_LAYERS_SHORTHAND,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     56\u001b[0m     transpose,\n\u001b[0;32m     57\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\peft\\utils\\loftq_utils.py:25\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01maccelerate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmemory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clear_device_cache\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m snapshot_download\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'clear_device_cache' from 'accelerate.utils.memory' (c:\\Users\\ADMIN\\anaconda3\\envs\\Phuc3\\lib\\site-packages\\accelerate\\utils\\memory.py)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_huggingface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceEmbeddings\n\u001b[0;32m      5\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBAAI/bge-m3\u001b[39m\u001b[38;5;124m\"\u001b[39m            \u001b[38;5;66;03m# a ngn ng, gn nh, khuyn dng\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[43mHuggingFaceEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m## lu vo db\u001b[39;00m\n\u001b[0;32m     10\u001b[0m vector_db_recursive \u001b[38;5;241m=\u001b[39m Chroma(embedding_function\u001b[38;5;241m=\u001b[39membedding, persist_directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../database_recursive\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\langchain_huggingface\\embeddings\\huggingface.py:68\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import sentence_transformers python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install sentence-transformers`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackend\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mipex\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_optimum_intel_available() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_ipex_available():\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`."
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "model_name = \"BAAI/bge-m3\"            # a ngn ng, gn nh, khuyn dng\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=model_name,model_kwargs={\"device\": \"cpu\"})\n",
    "\n",
    "## lu vo db\n",
    "vector_db_recursive = Chroma(embedding_function=embedding, persist_directory=\"../database_recursive\")\n",
    "# vector_retriever = vector_db.as_retriever( search_type=\"mmr\", search_kwargs={\"k\": 40, \"fetch_k\": 80, \"lambda_mult\": 0.3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99a29d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allocated: 0.0 GB\n"
     ]
    }
   ],
   "source": [
    "print(\"allocated:\", torch.cuda.memory_allocated(0) / 1e9, \"GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6704daf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "#  Ly ton b embedding v metadata t Chroma\n",
    "# (nu bn  load vector_db = Chroma.from_documents(...) nh trn)\n",
    "data = vector_db.get()  \n",
    "\n",
    "vectors = vector_db.get(include=[\"embeddings\"])\n",
    "vectors = np.array(vectors[\"embeddings\"])\n",
    "documents = data[\"documents\"]\n",
    "metadatas = data[\"metadatas\"]\n",
    "\n",
    "#  Nu bn c nhiu loi document, c th trch ra t metadata\n",
    "doc_types = [m.get(\"title\", \"unknown\") for m in metadatas]\n",
    "colors = [\"blue\" if t == \"unknown\" else \"red\" for t in doc_types]\n",
    "\n",
    "#  Gim s chiu xung 2D  trc quan ha\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=1)\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "#  V biu  scatter 2D\n",
    "fig = go.Figure(data=[go.Scatter(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=6, color=colors, opacity=0.8),\n",
    "    text=[\n",
    "        f\"<b>Loi:</b> {t}<br><b>Vn bn:</b> {d[:200]}...\" \n",
    "        for t, d in zip(doc_types, documents)\n",
    "    ],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=' Phn b embedding trong Chroma Vector Store (2D)',\n",
    "    xaxis_title='TSNE Dimension 1',\n",
    "    yaxis_title='TSNE Dimension 2',\n",
    "    width=900,\n",
    "    height=700,\n",
    "    margin=dict(r=20, b=10, l=10, t=40),\n",
    ")\n",
    "\n",
    "#  Hin th trc tip trn browser\n",
    "fig.show(renderer=\"browser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb517874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allocated: 2.271151104 GB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"allocated:\", torch.cuda.memory_allocated(0) / 1e9, \"GB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956e70cc",
   "metadata": {},
   "source": [
    "## Reranking by crossencoder + create hybrid search with semantic search + bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d62483",
   "metadata": {},
   "source": [
    "## Load db + vector retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adf85b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "model_name = \"BAAI/bge-m3\"            # a ngn ng, gn nh, khuyn dng\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=model_name,model_kwargs={\"device\": \"cpu\"})\n",
    "\n",
    "## lu vo db\n",
    "vector_db_semantic = Chroma(embedding_function= embedding, persist_directory=\"../database_semantic\")\n",
    "vector_retriever = vector_db_semantic.as_retriever( search_type=\"mmr\", search_kwargs={\"k\": 40, \"fetch_k\": 80, \"lambda_mult\": 0.3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db13b3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allocated: 0.0 GB\n"
     ]
    }
   ],
   "source": [
    "print(\"allocated:\", torch.cuda.memory_allocated(0) / 1e9, \"GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61de74fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.23804426193237305 seconds\n",
      "[Document(metadata={'title': '[CS315 - Chng 1] M hnh hc my da trn Gradient (Phn 1)', 'chunk_id': 6, 'end_timestamp': '0:09:04', 'start_timestamp': '0:06:45', 'video_url': 'https://youtube.com/watch?v=80PUcgaI5Y0', 'filename': '80PUcgaI5Y0'}, page_content='Tc l n s mau chng  m tm ra c ci tham s tt nht. Ri ci vic thit k hm m hnh cng vy n cng s da trn ci tnh cht ca y, ci gi tr thc t vx  m chng ta s thit k. V d nh nu y m ph thuc mt cch tuyn tnh vx th chng ta s c cc ci hm tuyn tnh. Nhng nu m y ph thuc mt cch phi tuyn vi l x th chng ta s c cc ci hm l phi tuyn tnh. Ri sau ny l ty thuc vx ca mnh,  l d liu dng vector, dng ma trn hay l d liu nh th no  m chng ta cng s c nhng ci kiu thit k khc nhau. V ci cng vic cui cng khi chng ta lm vi mt ci m hnh m da trn Gradient,  chnh l chng ta s tm mt ci tham s ti u ca hm m hnh. Tc l chng ta s i tm ci theta sao, sao cho ci li  y l nh nht, th li m nh nht l ci d on cng chnh xc. Th so vi li cc ci m hnh khc, chng ta s c rt nhiu nhng ci m hnh m khng da trn Gradient. V d nh m hnh l k-nearest neighbor, th thc s m hnh ny n khng phi l hun luyn m n s da trn cc ci mu gn nht.  n ging nh l ci c ch l voting, tc l chng ta s ly ra nhng ci mu gn nht, ri da trn nhn ca nhng ci mu gn nht, chng ta s a ra ci phn on. Ci m hnh theo  l Naive Bayes l da trn xc sut, y l mt ci hm  m c lng ci tham s mt cch tng minh. Ri decision tree, v d nh thut ton ID3, ri C4.5 th  y l s da trn lut  chia cc ci nhnh quyt nh. Random forest s kt hp nhiu m hnh cy thnh phn, tc l nhiu ci m hnh cy  trn  to thnh mt ci random forest. Cc ci thut ton m h khng gim st, v d nh l K-means, DBScan, vn vn l lp li ci vic cp nht ci tm cm, nhng m n l lp li khng c da trn Gradient.'), Document(metadata={'end_timestamp': '0:09:44', 'start_timestamp': '0:08:53', 'filename': '-2bJ_8EO9ZE', 'video_url': 'https://youtube.com/watch?v=-2bJ_8EO9ZE', 'title': '[CS315 - Chng 3] Deep Generative Models (1) - Part 4', 'chunk_id': 8}, page_content='Tun theo ci phn b Gaussian. Th v ci node ny l tt nh, l deterministic, nn khi chng ta lan truyn ngc v, ri chng ta li lan truyn ngc v y,  i tnh ci o hm theo ci tham s phi, th khi  chng ta s hun luyn c. Hc l cp nht li c ci tham s ca m hnh. Cn ci bc ny l chng ta s khng c i qua y c, l v n b chn bi ci node stochastic ny. Nh vy th chng ta tm tt ci kin trc VAE, l Variational Autoencoder. VAE mt ci nhim v ca n  l biu din d liu tht.'), Document(metadata={'title': '[CS116 - Bui 13] Part 1', 'end_timestamp': '0:10:17', 'start_timestamp': '0:09:06', 'video_url': 'https://www.youtube.com/watch?v=yPGYgh-J3uY', 'playlist': 'PLb62OySGqC9yGRvUaSe-iWFuXYuM8X6_n', 'filename': 'yPGYgh-J3uY', 'chunk_id': 7}, page_content='v chng ta s c c mt chin thut  kt hp, t hp cc kt qu ca N m hnh ny li  to ra mt gi tr output duy nht. Ngoi ra, Ensemble Learning cn gip chng ta gii quyt c vn  Bias. Vn  BIAS c ngha l ci m hnh ca mnh rt khc xa so vi m hnh thc t M hnh thc t l khi chng ta lm trn mt d liu tng qut khch quan Cn m hnh ca mnh ch c th tm ra c nhng hm d on v mang tnh cht gi l cc b trn nhng mu d liu cc b thi Ch khng c tnh tng qut. V vy th mi mt m hnh yu, mt weak classifier th n ch c th on ng cho mt s tnh hung d liu.'), Document(metadata={'start_timestamp': '0:11:23', 'title': '[CS315 - Chng 3] Deep Generative Models (2) - Part 3', 'filename': 'qCEs0PIGwek', 'chunk_id': 11, 'end_timestamp': '0:13:16', 'video_url': 'https://youtube.com/watch?v=qCEs0PIGwek'}, page_content='Ci v th hai  l ci thnh phn chnh quy ha l ci nhiu ny, th n s tun theo ci phn b 0.1. Cn i vi ci m hnh diffusion  di y th thay v mt bc, Th nht, ci s khc bit th nht  l thay v mt bc th  y chng ta s c nhiu bc encoding, nhiu bc nh encoding. V cui cng chng ta cng n c ci random noise nh th ny theo ci phn b normal distribution. Nhng ci s khc bit th hai  l trong m hnh VAE th n s c tham s, c ci tham s phi. Cn  y l khng c tham s, cc encoding ny l khng c tham s. Th  chnh l ci s khc bit ln nht m chng ta thy c gia hai ci m hnh VAE v AE. VAE th s c tham s v ch c mt bc, mt bc nhy l n c ci random noise. Th th chng ta thy l ci vic m chng ta nh x trc tip t nh th gii thc sang ci random noise ny m ch qua mt bc, th y l mt ci bi ton kh. V cha k khi chng ta decode ngc tr li t ci random noise ny th y cng l mt ci bi ton kh. Tuy nhin khi thay v chng ta gii mt ci bi ton kh vi mt ci encoder th chng ta s chia nh n ra thnh nhiu bc. Th nhng ci bc encoding ny n s l mt ci m hnh d hn, d hn rt l nhiu. Chng ta phun mt t nhiu ln trn ci X0  c ci X1, ri sau  phun mt t nhiu ln  thnh X2.'), Document(metadata={'chunk_id': 20, 'start_timestamp': '0:18:22', 'filename': 'vqDSl2cle2o', 'end_timestamp': '0:20:01', 'video_url': 'https://www.youtube.com/watch?v=vqDSl2cle2o', 'playlist': 'PLb62OySGqC9wDaL2dnF_5J8f49e_YNi2f', 'title': '[CS114 - Tutorial] Neural Network (Phn 1)'}, page_content='Th y chng ta s in ra l wave 0. . Ri sau  s l ci trng s wave 1 tc l tng ng l ci bias. Th chng ta s in ra trng s ca cc ci bias ri. [V tay] Ri v nu cn th chng ta s in ra ci set ca n. Ri th  ci trng s ca ci hidden  th n s c kch thc l 2 x 8. L do  l v  y chng ta kt ni y , u vo ca chng ta l c 2 v u ra ca chng ta l c 8 narol nn n l mt ci ma trn kch thc l 2 x 8. Cn bias ca chng ta th v chng ta c 8 naron nn n s c tm ci bias.'), Document(metadata={'filename': 'NEK5lIyST0M', 'video_url': 'https://youtube.com/watch?v=NEK5lIyST0M', 'end_timestamp': '0:05:30', 'chunk_id': 3, 'title': '[CS315 - Chng 1] M hnh hc my da trn Gradient (Phn 10)', 'start_timestamp': '0:03:19'}, page_content='Mo s khc ch ch khng th no m mo nh hn ch hoc l mo ln hn ch. Th  l ci cch  chng ta c th bit  l bi ton hi quy hay bi ton tuyn tnh. Th i vi ci bi ton hi quy th chng ta s c ci m hnh l hi quy tuyn tnh hay cn gi l linear regression. V i vi ci bi ton phn loi th chng ta s c hai tnh hung. Tnh hung u tin  l phn loi nh phn, tc l ci s phn lp ca ca mnh l c hai phn lp. V chng ta s c ci m hnh  l hi quy logistic hay l logistic regression. i vi trng hp m ca ln hn 2 th  s l chng ta s c ci m hnh  l hi quy softmax hay cn gi l softmax regression. Cn trong ci trng hp m ci m hnh ca mnh phi tuyn tnh th chng ta s c rt nhiu nhng ci m hnh hin i tp trung vo gii quyt ci bi ton m y ca mnh ph thuc mt cch phi tuyn tnh vi l x u vo. V mt trong nhng ci m hnh u tin m gii quyt ci bi ton m c tnh cht phi tuyn tnh  l m hnh Neural Network. Neural Network hay cn gi l mng Neural Nhn to, ANN. Th y c th ni l mt trong nhng ci m hnh u tin  t nn mng cho hc su. V cc ci m hnh v sau th chng ta thy n c ci ch A, c ci ch NN, v d nh l CNN. Th ci ch NN  y n cng chnh l Neural Network. V cn ANN th n cng c ci ch NN l Neural Network. V thm ch l Transformer th rt nhiu nhng ci, k c Transformer th rt nhiu nhng ci module  trong Transformer n cng da trn ci kin trc ca Neural Network. Do  th chng ta mi gi Neural Network l mt trong nhng ci m hnh nn tng u tin v hc su. V chng ta s n vi ci m hnh u tin.'), Document(metadata={'video_url': 'https://youtube.com/watch?v=Hrmm1B6sR8g', 'end_timestamp': '0:12:47', 'title': '[CS315 - Chng 3] Deep Generative Models (2) - Part 2', 'start_timestamp': '0:10:56', 'chunk_id': 10, 'filename': 'Hrmm1B6sR8g'}, page_content='Vy th lm sao chng ta c th tnh tch phn c cho tt c cc ci gi tr n trn ci khng gian phn b Gaussian. Th y l cng vic rt l kh. Th th thay v lm ci cng vic ny, th chng ta c th a v ci cng thc  l log ca Px.  y chng ta s b ci tham s theta ra  cho n n gin. Cn  y  ngha  l chng ta xc nh ci phn b Px khi theta ca mnh c tham gia v.  y chng ta b theta ra  cho n d nhn. Th log ca P s l bng log ca Pxz, tc l log ca Pxz chia cho Pxz. Vy th Pxz th y chnh l ci cng thc ca Bayes. y l cng thc ca Bayes. Tc l xc sut ca x v z. Khi chng ta chia cho xc sut ca z cho trc x th  chnh l xc sut ca P. Hay ni cch khc l khi chng ta nhn ln th Px nhn vi li Pz cho trc x th  chnh l bng Pxz. Tc l xc sut ca x v z cng xut hin th n s l bng xc sut x nhn vi li xc sut ca z cho trc x. Th y l da trn a l ca Bayes. Tuy nhin da trn cng thc ny th chng ta li c cu hi  l lm sao chng ta  bit c ci ny.'), Document(metadata={'video_url': 'https://www.youtube.com/watch?v=K9YoXQq0TjI', 'end_timestamp': '0:13:54', 'start_timestamp': '0:00:00', 'playlist': 'PLb62OySGqC9yGRvUaSe-iWFuXYuM8X6_n', 'chunk_id': 0, 'filename': 'K9YoXQq0TjI', 'title': '[CS116 - Bui 13] Part 4'}, page_content='cui cng  l k thut boosting th y l mt trong nhng ci k thut rt l quan trng ca ensemble model  boosting n s hun luyn mt cch tun t nu nh ci thut ton bagging  l cc ci Model c thc hin mt cch l song song v c lp vi nhau th boosting n s thc hin mt cch tun t v m hnh sau m hnh sau s c train da theo ci kt qu ca ci m hnh trc v nhim v ca n  l c gng i sa sai i i sa sai nhng m ci sai ny l nhng ci sai cn li thi ci sai ca cc ci m hnh trc  n  n   hnh thnh v cng lc v sau n s cng gim xung v c thm mt ci m hnh mi th ci sai s ca mnh n s cng lc cng gim th ci hnh bn phi minh ha ci  tng ca thut ton boosting u tin  l chng ta s c mt ci tp d liu  gc v tp d liu ny th cng tng t n s chia ra lm cc ci data 1 2 3 cho n data th N. Ta s thc hin ci thao tc l chia ra v chng ta s tin hnh hun luyn trn ci model s 1 trc ri sau  Ci model s 1 ny chng ta s thc hin trn ci data chng ta s tin hnh i predict trn ci data s 2 v chng ta s ra c ci sai s vi ci sai s ny th chng ta s tip tc khai thc ci sai s   m i train trn ci model s 2 Model s 2 sau khi  c train xong s i predict trn ci d liu s 3 v chng ta s ra c ci sai s v da trn ci sai s ca model s 3 chng ta s tip tc i train cho ci model s 3 ri li tip tc c nh vy cho n data th N v chng ta s train ci model th N v N ci model ny s c tng hp li vi mt ci k thut ensemble th ensemble ny c th l nhng k thut c bn nh l voting averaging hoc bn thn ci phng php ensemble ny n c xut pht t ci thut ton ca mnh tc l ci thut ton kt hp gia Model s 1 Model s 2 Model s 3 vi nhng ci trng s m m hnh ca mnh n  c hc trong ci qu trnh boosting th  hiu r hn v k thut Boosting th chng ta s ly mt ci thut ton i din  chnh l thut ton Gradient Boost v Gradient Boost  tng ca n  l n s xy dng mt ci chui mt ci chui cc ci cy quyt nh lin tip vi nhau th nu nh bagging n ch ni chung chung l mt ci m hnh th trong trng hp ny chng ta s s dng l cy quyt nh l mt ci m hnh c th v k tha ci  tng ca bagging trong ci thut ton bagging th n s c ci random Forest v random Forest th ci model thnh phn ca mnh l h cng s dng cy quyt nh decision tree th boosting n cng s s dng ci m hnh thnh phn l decision tree, cy quyt nh v nhim v  l ci cy sau s c gng lm gim ci sai s d on ca cc ci cy trc  v d nh chng ta thy  y l c ci ct l residual tc l ci sai s d on nu nh vi vi ci kt qu khi to ci cy u tin l tht ra n cng khng phi l cy  l ci gi tr trung bnh ca ci ct gi tr d on th sai s nu nh chng ta s dng ci gi tr trung bnh ny nh l mt ci gi tr d on th sai s ca mnh s l ci ci gi tr  trn ci ct th nht nhng nu nh chng ta kt hp vi li ci cy th hai v vi mt ci h s kt hp th ci sai s ca mnh n gim t 16.8 xung cn 15.1 t 4.8 xung cn 4.3 t -15.2 xung cn - 13.7 V khi chng ta kt hp thm vi ci cy th ba th ci ci sai s mnh n  gim t 15 xung cn 13 t 4.3 xung cn 3.9 t - 13.7 xung cn -12.1. th ci hnh ny n ly t ci ngun video vi ci ng dn nh sau v bn phi  l mt ci hnh hnh nh minh ha khc s dng animation  th ci ng mu xanh chnh l ci hm ng ca mnh cn ci ng mu  chnh l ci ng m do thut ton boosting to lp ra th chng ta thy  l ti nhng ci bc u tin th ci ng mu  n s rt l cch xa nhng m sau khi hun luyn xong th ci ng mu  n  xp x vi ci ng mu mu xanh  th y chnh l ci hnh nh  minh ha cho ci thut ton . V nh chng ta thy  y mi vng lp u tin th ci ng ca mnh n rt l th v n s i ra khng c ging lm N s khng c m phng ging lm ci ng m xanh nhng m cng chy th ci ng Zig zc ny s cng lc n cng mn hn v n s cng tin st hn n ci ng mu xanh ca mnh th  c th hiu r hn v trc quan hn cho ci thut ton Gradient Boost th chng ta s cng theo di ci video  YouTube nh sau chng ta s c mt ci bng d liu ba ci ct u tin s l ba ci ct c trng u vo v ci ct khi lng ci ct khi lng cui cng chnh l ci ct m mnh cn phi d on th thut ton Gradient Boost s chy ln ci ct ny  gi tr ca ci ct khi lng ny th bc u tin  l chng ta s on ci gi tr trung bnh  chng ta s on bng cch  l ly mt ci gi tr trung bnh th tt c nhng ci mu no m a vo chng ta cng s a ra ci Phn on l ci gi tr m khi lng trung bnh ny  l 71.2 v ng nhin l ci vic s dng gi tr trung bnh ny n s dn n l ci sai s n s dn n ci sai s th vi ci sai s ny  th chng ta s tip tc chnh sa li  V d nh  y chng ta c ci mu d liu u tin ha mu ci ci dng u tin ci dng d liu u tin khi chng ta ly ci  gi tr D on m s dng ci gi tr trung bnh l 71.2 ny th khi chng ta Tr ly ci gi tr thc l y l  y l 88 tr cho ci gi tr trung bnh m mnh d on l 71.2 th chng ta s ra c ci sai s l 16.8 v c tng t nh vy th chng ta s ra c ci nguyn ci sai s ny  l 4.8 76 tr cho gi tr l 71.2 y chng ta s ra l 4.8 ri sai s l -15.2 vn vn v by gi chng ta s khng cn quan tm chng ta s khng cn quan tm n ci ci ct khi lng ban u ny na m ci ct m chng ta cn phi d on tip theo  chnh l ci ct sai s ny v vi input feature n vn l ba ci ct u tin v sau khi xy dng ci thut ton decision tree trn ci ct d liu mi ny th chng ta s ra c mt ci cy quyt nh chng ta s ra mt ci cy quyt nh v chng ta s khng s dng ci cy quyt nh ny mt cch trn vn 100% m chng ta s phi s dng kt hp c tham s  n gi l h s learning rate bnh thng ci h s ny l 1 nhng m c mi mt ci vng lp th ci ci ci ci ci mc  m chng ta khai thc ci cy mi n ch l mt ci h s di mt thi tc l chng ta s  cng vi li mt ci h s tng i nh  cho ci qu trnh ny ca mnh n s cp nht dn dn v ng nhin ci h s learning rate cng nh th ci s cy m mnh to ra n cng s cng nhiu cng s cng ln  khc phc ci sai st do ci qu trnh d on th trong trng hp ny chng ta s s dng   l ci trng s l 0.1 nh vy th vi mt ci mu d liu l u tin l ci hng u tin th ci gi tr d on ca mnh n s l bng 71.2 Tc l ci gi tr trung bnh u tin  ci bc u tin cng cho cng cho gi s nh vi ci c trng l height, color v gender ny n i theo ci con ng ny n ra ci gi tr d on ca ci sai s l 16.8 nhng 16.8 ny n phi nhn vi h s learning rate l 0.1 Tc l n ch cng vi mt ci t l l 10% ci thng tin t ci cy quyt nh ny ra thi nh vy th 71.2 cng cho 0.1 nhn cho 16.8 n ra l 71 72.9 chng ta s ly ci tnh ci sai s tip theo chng ta s tnh ci sai s tip theo ri ci sai s tip theo n s c tnh bng cch  l n vn s ly ci gi tr trng khi lng gc ban u l 88 tr cho ci gi tr D on khi  c s kt hp ca gi tr trung bnh  y vi li ci cy m chng ta  to ra  ci lp trc  Ci bin i trc  th 88 tr cho ci gi tr D on mi ny th n s ra ci sai s ca mnh l 15.1 v chng ta thc hin tng t nh vy cho tt c cc ci dng d liu cn li ri v sau khi chng ta  thc hin th chng ta  c mt ci gi tr  li mi n khc so vi li ci  li  ci bc tnh l ch c mi ci gi tr trung bnh thi th vi ci cy mi ny chng ta c mt ci gi tr  li mi v lp li  ci vic ci ci ci qu trnh thc hin ny chng ta li i tip tc hun luyn  chng ta s tip tc i hun luyn cho ci residual mi ny v chng ta to ra c mt ci cy mi C lp i lp li nh vy chng ta s to ra c mt ci cy mi V ci cy mi ny s c kt hp n s c kt hp vi li hai ci cy trc   l ci cy  y v ci gi tr trung bnh  y v cch m chng ta kt hp l chng ta vn phi phi nhn vi mt ci h s learning rate l 0.1 tc l chng ta ch ly khong 10% ci gi tr D on m thi ri v  y th chng ta s c ci ba ci residual tng ng cho ba ci ln m chng ta hc ci m hnh ca mnh  ci ln u tin vi ch c duy nht mt ci gi tr trung bnh l 71.2 th chng ta thy l ci  li ca mnh n l 16.8 nhng khi c ci s kt hp 0.1 tc l 10% ca ci cy th hai th  li ca mnh l n rt xung cn 15.1 v khi kt hp vi li ci cy th ba th ci  li ca mnh n s gim xung Khong 13.6 V c nh vy chng ta c to ra thm nhiu ci cy v khi to ra mt ci cy mi th chng ta li to ra mt ci residual mi mt ci sai s mi ci ct sai s mi V ci cy hun luyn n s c hun luyn trn ci ct sai s mi ch khng phi l da trn ci  ci ci ci ct m Weight Tc l ci ct khi lng ban u  th c nh vy th thut ton ca mnh n s chy th y chnh l ci  tng ca  thut ton Gradient Boost v quay tr li ci k thut boosting th bn cnh thut ton Gradient Boost th chng ta s c rt nhiu nhng ci thut ton boosting ni ting khc  chnh l adaboost ri XGBoost, LightGBM v CatBoost v tt c nhng ci thut ton ny u l nhng ci thut ton m rt l ni ting v t c nhng ci gii cao trong cuc thi Kaggle trong  ni ting nht  chnh l ba ci ci thut ton ny: L GBM, LightGBM v CatBoost. y l ba ci thut ton m c s dng rt l nhiu trong cc ci cuc thi Kaggle v t c th hng rt l cao trong  XGBoost l mt ci ci tin ca Gradient Boost. CatBoost cng l ci tin. LightGBM th nghe ci t Light thi l chng ta  bit l mc tiu ca n l lm g ri ng khng?'), Document(metadata={'end_timestamp': '0:19:28', 'start_timestamp': '0:07:26', 'title': '[CS315 - Chng 1] M hnh hc my da trn Gradient (Phn 5)', 'chunk_id': 1, 'video_url': 'https://youtube.com/watch?v=xgJniBOVdL8', 'filename': 'xgJniBOVdL8'}, page_content='Ti v khi tham s ca mnh cng tin v im cc tiu cc b, m im cc tiu cc b c tnh cht  l o hm gn bng 0 M khi o hm xp x bng 0 th tc l, tc l ci v, v ny ca chng ta, v l bng alpha nhn o hm th n cng s xp x bng 0 V khi  th theta bng theta tr c mt con s rt l b, tc l n s i rt l chm Ti khi ci v c xu hng gim dn v tin v 0 nh vy th n s gy ra ci vic hi t chm V chng ta s mn ci khi nim trong vt l l momentum  gii quyt vn  ny Momentum l g? Gi s nh ban u, chng ta t mt ci qu banh  y Th  trn cao n s c mt ci th nng, n s khin cho ci tri banh n s rt xung Nhng khi m tri banh n rt xung n ci im cc tiu cc b  y V lc  ci th nng n  b trit tiu bng 0, th nng trong trng hp ny l chnh l o hm N s tng ng vi o hm  trn V th nng th n bng 0, nhng b li n s c ci ng nng l do qu banh i t trn xung di Ban u ng nng l bng 0, nhng m sau  rt xung di th ci ng nng ca qu banh n ln ln V nh c ci ng nng ny, n s to ra mt ci moment  cho ci qu banh ny tng ng vi o hm  trn Rt xung c ci im cc tiu m tt hn V  chnh l ci  tng cho gii php s 2  l ci vn tc ca chng ta th s c k tha t ci vn tc ca qu kh V bng beta nhn V y l ci qu kh Nu khng c ci thnh phn beta V ny th V ca chng ta ch bao gm ci thnh phn th nng chnh l ci o hm  y Nh n khai thc c ci lng ng nng ca qu kh th khi n chm n ci im cc tiu cc b N s gip cho chng ta thot ra khi ci bng ny Th ci cng thc ci tin ca chng ta s rt l n gin nh trn V beta lc ny n gi l momentum factor v beta cng l t 0 cho n 1 iu g xy ra nu beta bng 0, beta bng 1 Nu beta bng 0 th n s b ra mt ci vn tc ca chng ta iu g xy ra nu beta bng 0, beta bng 1 Nu beta bng 0, tc l chng ta khng c ci thnh phn ng nng ny Vy th beta bng 0 chnh l ci trng hp khng c ci tin Ri, khi beta bng 1 th lc ny V s l bng 9V cng dn vo ci th nng Th khi  ci tc  tng ca V ny rt l cao V n s l cng dn ln, cng dn ln, cng dn ln Nh vy th n s tng rt l nhanh N c th khin cho ci vn tc ca mnh qu ln v n s khng c hi t m n s b phn k Do  th beta n nn l mt con s nh hn mt Tc l n ch ly mt phn, v d nh trong trng hp l beta bng 0.9 th n ly 90% ca ci V qu kh thi Th chng ta s c ci gii php y  cho ci momentum u tin chng ta s khi to alpha l mt ci gi tr kh l ln V sau  th alpha s c cp nht li l bng delta nhn cho alpha, tc l n ang gim dn Ci alpha, ri chng ta s khi to vn tc ban u Khi chng ta tng tng qu banh  trn y th ci ng nng ca n l bng 0, n khng c ng nng m n ch c th nng thi Th lc ny V ca mnh l bng 0, tc l tng trng cho ng nng ti thi im bt u Delta l ci h s gim, tc l alpha ban u l 0.5 nhng m sau  n s gim 10 ln V 0.1 c ngha l chia cho 10 th n s gim 10 ln, c mi ln lp n s gim 10 V beta l bng 0.9 Tc l ci ng nng, ci vn tc ca mnh s l bng 90% ca ci vn tc qu kh Sau  chng ta cng thm ci thnh phn th nng hin ti, tc l ci o hm Ci ny tng trng cho ci th nng hin ti Nu nh n ci im, gn n ci im cc tiu, cc b  y Th ci thnh phn o hm ny n s xp x bng 0 nhng n s k tha c 90% ci ng nng ca qu kh Nn n s khng c b dng li, b ng li V vn cn  ln  c th c chuyn c V  y chng ta thy l khi chng ta, ci im mu  n ti v tr ny N s vn cn mt ci ng nng  nhy qua y Sau  tip tc nhy ln, nhy ln, nhy ln V nu nh ci ng nng ny  ln th n s gip cho chng ta thot ra khi ci im, ci khu vc bn ny Thot ra khi ci khu vc cc tiu cc b V  qua mt ci khu vc khc Vi hy vng rng l chng ta c th tm ra c mt ci cc tiu tt hn V  y th chng ta s th tnh ton trn nhng ci con s u tin  l gi s nh ci momentum ca mnh l bng 0.99 Th khi  3 ci bc cp nht u tin, 3 ci bc cp nht u tin ca mnh V ban u th s l bng G, trong  G chnh l ci gradient Ti ci v tr khi to chnh l G1  y Tc l n ch bao gm th nng thi, ng nng lc ny l 0  y ng ra l 0 cng cho G1 Sau  V2 s l bng 90% ca ci c Sau  cng thm 1 thng G2, th n chnh l bng 0.99 v.1 v.1 trc ny l G N chnh l 0.99 v.1 cng cho G2 Tip tc sang ci im th 3 V3 s l bng 0.99 v.2 cng cho G3 Tc l ci o hm ti thi im hin ti G3  y, cng cho, n s cng cho khong 0.99 v.2 Chng ta th ci V2  ci cng thc  trn xung y Th n s l bng 0.99 v.1 cng cho G2 Chng ta trin khai vo th n s ra l 0.81 v.1 v 0.99 v.2 cng cho G3 Nh vy th  y chng ta s c mt ci nhn xt  l khi cp nht tham s, th gradient ti nhng ci bc cng gn N s ng gp cng nhiu Tc l V ti ci thi im th 3, tc l ci thi im hin ti chng ta ang xt N s bao gm l 0.81 v.1 cng cho 0.991 v.2 cng cho G3 Tc l ci th nng tc thi, tc l o hm tc thi ca mnh Th chng ta thy l ti ci v tr s 3 G3 ng vai tr l ci t l, ci h s l 1 Tc l cao nht Sau  l G2 s ng gp l 0.9 v G3 l 0.81 Nh tng t nh vy th khi G, khi V m cng ln Th n s l bng ci h s ca nhng ci V Gn cng cho Gn-1 cng cho Gn-2 V sau  n s nhn vi nhng ci h s thp dn Ban u s l 1, 0.9, 0.81 Tip theo th n s l 0.9 nhn cho 0.81 N s cng cho 0.9 nhn cho 0.81 Tc l u  khong xp x l 0.72 ca ci G th n-3 Cng sau  h s n cng thp y chnh l ci  tng ca thut ton momentum V n  gip cho chng ta thot ra c khi ci im cc tiu cc b Nh ci vic l chng ta khai thc c nhng ci ng nng ca qu kh 90% ca Gn-1, 80% ca Gn-2 v 70% ca Gn-3 N khin cho chng ta thot ra c V khi thot ra c th cu hi l lt c khi no m n c i ln hoi hay khng Th cu tr li l khng, ti v khi m n thot ra n y Ri, th n y ci lc ny th n s k tha nhng ci th nng ca cch y Trc  th th nng ti nhng thi im ny rt l thp Ci khu vc ny rt l thp Th nhng ci Gn rt thp ny n li ng gp t trng cao vo ci v tr ca ci tham s hin gi Cn nhng ci im m c ng nng th nng cao, v d nh ch ny Th th nng ca n rt l cao, nhng m n  i xa so vi ci v tr ny Nn ci h s  y n ch c th ng gp l tm 0.1, 0.2 thi Cn nhng ci ng gp nhiu nht vo y  l nhng ci th nng ti v tr ny Tc l o hm  nhng ci khu vc rt l thp,  th n dn n n s ko ci ny xung ngc tr li Ri, v khi ko ngc tr li th n li tip tc chy qua chy li v cho n khi no m chm c n ci im ny Th  chnh l ci  tng ca momentum'), Document(metadata={'video_url': 'https://youtube.com/watch?v=ZMtZ2jeujIU', 'start_timestamp': '0:00:14', 'chunk_id': 0, 'end_timestamp': '0:12:26', 'filename': 'ZMtZ2jeujIU', 'title': '[CS315 - Chng 3] Deep Generative Models (1) - Part 3 (Phn 2)'}, page_content='Chng ta s la chn mt phn b xc sut prior tc l tin nghim, l Normal Gaussian Tc l chng ta c rt nhiu nhng dng phn b khc nhau, tuy nhin mt trong nhng phn b rt ph bin  l phn b chun l Normal Gaussian Chng ta mong mun phn b khng gian n ca mnh s l mt phn b ging vi phn b Gauss V c th lun l Normal Gaussian, tc l vi mu l bng 0 v sigma bnh phng l bng 1, th y l phn b n tin nghim V mnh s hun luyn m hnh  cho Q ca z cho trc x vi tham s phi l tun theo phn b Gauss V vy, phn b ng u s xoay xung quanh tm ca khng gian n, v d nh chng ta c mt khng gian n th mnh s tm cch a n v cng mt tm vi nhau V vy, phn b ca mnh s xoay xung quanh tm khng gian n, tc l mu bng 0, khuyn khch cho c trng phn b ng u xoay xung quanh tm khng gian n V vy, phn b u s xoay xung quanh tm khng gian n, tc l nu nh  trong m hnh autoencoder khng c hnh thng thng, th mnh s tm cch a n v cng mt tm V vy, phn b ca mnh s xoay xung quanh tm khng gian n, tc l nu nh  trong m hnh autoencoder khng c hnh thng thng, th mnh s tm cch a n v cng mt tm V vy, phn b ca mnh s xoay xung quanh tm khng gian n, tc l mu bng 0, khuyn khch cho c trng phn b ng u xoay xung quanh tm khng gian n V vy, phn b ca mnh s tm cch a n v cng mt tm Ci cng thc khong cch  li gia qi v p th n c tnh nh th no? N s c tnh da trn cng thc KL divergence gia hai phn phi V khi chng ta trin khai vi p l bng phn b Normal Gauss l mu bng 0 v sigma bnh bng 1, th chng ta s c cng thc  l bng mt phn tng ca g chy t 0 cho n k tr 1 ca sigma z cng cho mu z bnh phng tr 1 Tr cho log ca sigma z, trong  k chnh l s chiu ca vector ca mnh K chnh l s chiu ca khng gian n V khi  n cng chnh l s chiu ca mu, n cng chnh l s chiu ca sigma lun Ri, khi chng ta hun luyn mt m hnh VAE, thnh phn chnh quy ha ny n khuyn khch ci chuyn g?  l khi chng ta cho ci loss ny cng tin v 0, tc l cng gim R rng l vi cng thc ny chng ta s thy sigma z s c xu hng tin v 0 Ngc li,  y chng ta thy c ci du tr log ca sigma z, th n li khuyn khch ci sigma ny l khng qu nh N s khuyn khch Ci sigma z khng qu nh Cn ci mu tin v 0, tc l ci phn b ca mnh, n s ko t mt ci khu vc rt l xa, n s ko v tin v ci gc ta  00 ny y l mt ci mu ban u, n s ko ci mu ny v gc ta  Ri, ng thi sigma z nu nh ci phn b ca mnh n qu ln, th n s ko cho ci sigma ny tin v  nh Nhng nh c ci log ca sigma z ny th n s khin cho ci sigma ca mnh khng qu nh Ch cn nu m n nh qu th c phi l thay v chng ta a v mt phn b th cui cng n s a v mt im khng? Phn b ca mnh n s tin v mt im, nh vy l n tng t nh autoencoder ri Nh vy th ci sigma n s ko v, ng c qu ln nhng m cng ng c qu nh  hy vng rng l ci phn b ca mnh n thc s l mt ci phn b c yu t ngu nhin Ch cn nu m sigma m tin v bng 0, tc l n s co v mt im, tc l n s a v mt ci m hnh deterministic, tc l mt ci m hnh tt nh Ch khng c yu t xc sut nh trong ci m hnh VAE Th vi ci cng thc ny n s khuyn khch hai ci chuyn y, mt  l ci phn b Q ny s tin v 0, tin v ci gc ta  Ci th hai  l mu z, n s tin v mt ci phn b m c ci  lch va , ch n khng c qu nh nhng n cng khng qu to Th y l ci cng thc chnh quy ha V chng ta c nhng ci tnh cht g t ci vic chnh quy ha ny, n s c nhng tnh cht g u tin  l ci tnh lin tc, tc l nhng ci im gn nhau trong khng gian th ni dung hon ton tng t nhau khi gii m Chng ta ang ni n ci  ny Th  bn tri l mt ci m hnh khng c c chnh quy, tc l chng ta ch c ci sai s gia x tr cho x m thi Sai s ti to thi, ch c sai s ti to Th nu khng c thnh phn chnh quy ha th n s khng m bo c Th nht  l hai im gn nhau trong khng gian n, l ci im mu xanh l m v mu   y th n gn nhau trong khng gian tin n Nhng khi m gii m th n khng c tng t nhau, v d ci im mu xanh l ny, xanh l m ny th n s ra hnh vung Trong khi ci im mu  th li to ra mt ci hnh ging hnh tam gic, th hai ci hnh ny n khng c tng t nhau, mc d hai ci im ny n gn nhau Ci th hai  l i vi ci vic m khng chnh quy ha, n s c th khin cho ci im ca ci khng gian n c gii m nhng m khng c  ngha V d nh  y chng ta ch c hnh tam gic, hnh trn, hnh vung, nhng m c mt ci im  y l ci im m n khng qu gn ba ci im ny th khi chng ta gii m n ra mt ci hnh g y m n khng c  ngha V d nh trong ci ch s vit tay th khi chng ta decode ra l ra n phi ra l s, ch s th 0 cho n 9 nhng cui cng n s ra mt ci g y, n khng phi l con s Tc l mt ci d liu khng c  ngha, th nu nh khng c chnh quy ha n s khin cho chng ta b hai ci vn  ny Ngoi ra th nh c chnh quy ha n s gip cho chng ta gii quyt c ci vn  ,  l ci tnh lin tc ca d liu ca ci im biu din trong khng gian n Th hai ci vector z v z phi nm trong khng gian n m ging nhau, gn nhau th khi decode ra n cng phi ging nhau Tnh cht th hai,  l tnh y  l ly mu t khng gian n th ci ni dung ca mnh n s phi c  ngha, th y l mt ci v d ny khng c  ngha Cn nu nh chng ta s dng mt ci m hnh chnh quy ha, tc l bn cnh ci sai s ti to n c thm ci thnh phn chnh quy ha l c biu din bi ci cng thc l d ca kl,  l KL divergence ca qi v p Ci ny l vit tt nha, th cc ci im gn nhau th c gii m tng t v c  ngha, v d chng ta thy ci im mu cam v ci im mu tm th hai ci hnh ny khi chng ta gii m th chng ta thy ci dng dp n cng ging nhau Mc d ci im mu tm th n s hi bo  y mt cht, hi bo trn, nhng nu xt v hnh th th n cng gn ging vi hnh tam gic, do  th hai ci im ny khi chng ta dy n s c ci tnh tng t nhau v n hon ton l c  ngha ca n, n c ci l do ca n Ri, th y chnh l ci s khc bit ca vic c chnh quy ha v khng c chnh quy ha khi chng ta hun luyn vi ci m hnh VAE Th th mt ci biu din khc l sau khi chng ta  hun luyn xong m hnh VAE, th ci phn b chun tin nghim s m bo c ci yu t v tnh lin tc v tnh y  Ci tnh lin tc n th hin  ch  l nhng ci im no m gn nhau th khi decode n s ging nhau v ci tnh y   l mi im ca mnh Trong ci khng gian th khi chng ta decode ra n u c ci  ngha ca n ch khng phi l mt ci ni dung v ngha Th sau y chng ta s ni c mt ci v d r hn v ci chuyn ny Chng ta thy  y c 3 ci phn b mu  mu xanh v mu vng Th  y l ci tm cm mu  th khi chng ta decode ra n s ra ci hnh tam gic Cn y l tm cm ca b mu xanh decode ra l ra hnh trn Th th mt ci im  lng chng ngay chnh gia trn v tam gic th chng ta thy ci hnh ny n u c ci  ngha kh l ph hp ng khng? l ci hnh ny n s c ci bo trn ging nh ci hnh trn Nhng ng thi n s c ci nt thng, 3 ci nt thng Ging nh tam gic , th ci im trung im ny n s ging ging, n s gip chng ta to ra ci tnh gi l ci tnh lin tc V ng thi n cng c  ngha, n cng c  ngha ch khng phi l khng Nu m ci  gia ny m n ra mt ci im no  m chng ta khng th gii thch c th  l khng c  ngha Ri khi chng ta tin cng gn hn v ci tm th chng ta thy l ci tam gic n bt bo trn i ng khng?'), Document(metadata={'video_url': 'https://youtube.com/watch?v=hrxNKadDpw4', 'start_timestamp': '0:15:50', 'chunk_id': 17, 'filename': 'hrxNKadDpw4', 'title': '[CS315 - Chng 3] Deep Generative Models (1) - Part 1', 'end_timestamp': '0:18:04'}, page_content='Trong ci qu trnh m hun luyn  trnh c nhng ci tnh hung khng th on c. Ti v khi chng ta mun xy dng ci d liu cho ci h thng xe t li, chng ta phi lng trc nhng ci tnh hung m xe s gp nhng ci tnh hung m him xut hin. V d nh c mt ngi bng qua trc mt, hoc l ng th gp ghnh, ng b quanh co, hoc l thi tit xu. Th th ci m chng ta mong mun c ci d liu  cho m hnh ca mnh,  ci thin ci m hnh ca mnh,  l nhng ci tnh hung l phn b  bn ngoi vi, tc l outlier. y l ci outlier m chng ta mong mun c d liu  cho m hnh n hc. V d  l c ci gii phn cch, hoc l c ci tnh hung l my bay ln i trn u, hoc l thi tit xu, thi tit cc oan, v d nh l ma to, bo tuyt, hoc l c tnh hung ngi i b bng qua t ngt trc mt mnh, hoc l a gin, v.v. Th  chnh l nhng ci tnh hung ngoi vi m chng ta mong mun c ci d liu ny  cho m hnh ca mnh n hc c. Th  chnh l ci l do ti sao chng ta cn c m hnh to sinh,  khi chng ta sampling vi nhng ci tnh hung ngoi l ny, th chng ta s c c nhng ci d liu ny, n s gip cho ci b d liu hun luyn ca chng ta n cn bng hn. N gip cn bng hn v dn n l m hnh ca mnh n s khng b bias vo 95% nhng ci d liu m p, d liu bnh thng  y. V mt trong nhng ci hng tip cn  m to ra cc ci m hnh to sinh,  l chng ta s s dng m hnh l Latent Variable, tc l m hnh da trn bin tim n v c hai ci m hnh chng ta s cng tm hiu trong ci bui ngy hm nay,  l m hnh v Autoencoder,  l Autoencoder phin bn gc v Variational Autoencoder hay vit tt l VAE v Generative Adversarial Network, tc l m hnh to sinh i khng GAN. Th y l hai ci m hnh da trn ci bin tim n.'), Document(metadata={'video_url': 'https://www.youtube.com/watch?v=lG95Eg3Hv7c', 'start_timestamp': '0:00:00', 'end_timestamp': '0:15:35', 'filename': 'lG95Eg3Hv7c', 'title': '[CS116 - Bui 3] Part 2', 'playlist': 'PLb62OySGqC9yGRvUaSe-iWFuXYuM8X6_n', 'chunk_id': 0}, page_content='trong phn tip theo th chng ta s cng tm hiu v cc ci thnh phn ca mt ci machine learning pipeline u tin  chnh l Raw data Raw data hay cn gi l d liu th d liu ban u ca ci m hnh ca mnh th Raw data  l ci g  l tng hp ci d liu m chng ta tng hp t nhiu ngun khc nhau v d nh l trong log ca cc ci h thng hoc l trong cc ci h qun tr c s d liu ca cc ci h thng m ang c trin khai ng dng no  m chng ta ang mun xy dng  chun b sp ti l chng ta tch hp cc ci tnh nng v ai cc ci tnh nng v my hc trong ci vic l d on xu hng ca ngi dng chng hn ri N c th l nhng ci d liu m  c survey ca khch hng cch gi l trc tip hoc l gin tip th y chnh l nhng ci ngun d liu m gip cho chng ta c th tng hp nhng ci d liu thnh cc ci liu th  a vo cho my c th hun luyn c v ngoi ra th chng ta cng c th c rt nhiu nhng ci d liu khc nhau V d nh d liu ny l n t ngun internet chng ta c th cw  chng ta c th cw d liu t trn cc ci trang mng x hi  ly cc ci d liu  v tng hp thnh mt ci kho d liu th  y v d liu ny th hon ton c th l cha c kim tra hoc l tin x l ngha l ci d liu ny u   chng ta vn c kh nng l c cha nhng ci d liu nhiu  trong  hoc l ci d liu ny u  l n  ci dng thc m m hnh my hc n cha c kh nng thc hin tnh ton c v d liu ny th n cng c kh nng  l khng y  v c cha nhiu bn trong cng nh l cha nhng ci thng tin nhy cm th th ti sao chng ta cn phi quan tm n nhng vn  ny Ti v khi chng ta xy dng cc ci m hnh my hc th n rt d b nh hng bi ci yu t khng y  v ci yu t v nhiu nu nh d liu ca mnh c cha qu nhiu nhng ci gi tr n gy nhiu Tc l nhng ci gi tr n khng ng th dn n l ci my hc ca mnh n s d on sai v n s c  chnh xc khng cao cn cha thng tin nhy cm tc l nu nh ci m hnh ca mnh n bng cch no  n vn nh c nhng ci thng tin  bn trong ci d liu th ny th khi chng ta trin khai ra dng c kh nng n s gy ra hin tng l LCK d liu r r d liu th nu nh cha nhng ci thng tin nhy cm ny th ci m hnh ca mnh n cng kh m c th trin khai trong thc t cha k  l nu cha nhng ci thng tin nhy cm th ci i ng pht trin h cng c th tip cn c nhng ci ngun thng tin ny th h c th thy c cc ci thng tin nhy cm lin quan n yu t v c nhn no  ca ci h thng ca mnh v bc th hai trong ci ci machine learning pipeline  chnh l data validation th Data validation l mt ci bc thc hin rt l quan trng n rt l quan trng trong ci quy trnh xy dng m hnh my hc n m bo c l ci d liu u vo ca mnh n ph hp n ph hp vi ci bi ton m mnh ang n ti v n m bo c ci cht lng th ci bc kim nh d liu ny n Ging nh l mt ci bc sn lc u tin  kim tra xem l data ny c  tiu chun  c th a vo cho ci m hnh my hc c th hun luyn c hay khng v ci bc data validation ny  th n s thc hin cc ci cng vic v d nh l kim tra ci tnh nht qun ca d liu trnh ci vic  l cng l ni v mt ci i tng nhng m  ci dng d liu trc th n n li c th hin l cc ci c trng khc nhng m sang ci dng d liu sau cng l ni v ci i tng  nhng n li c mt ci tn khc v d nh tn ca mt cng ty lc th n  dng l vit tt lc th n n l  dng vit  y  Lc th n  dng vit hoa  th  l ci tnh nht qun ca d liu ci tnh y  ca d liu  l trong ton b cc ci c trng ca d liu th liu n c b thiu thng tin no hay khng n thiu ny th l thiu do c ch ch hay l thiu do s v tnh ri d liu ca mnh n c b ngoi l hay khng Tc l s c nhng ci tnh hung d liu ca mnh  c y   nhng m ci gi tr ca mnh n khng c hp l hoc l ci gi tr ca mnh n nm ngoi ci khong gi tr m ph bin th n s gy ra ci hin tng gi l nhiu nhiu cho ci m hnh ca mnh khi m hun luyn ri v ci bc data validation ny th thng c thc hin vi ci bc l edi tc l phn tch d liu th y c th ni l mt trong nhng ci bc tin  u tin khi chng ta lm vi bt c bt c mt ci m hnh my hc no mt ci bc tip theo  chnh l tin x l d liu data reprocessing th trong ci bc tin x l d liu chng ta s phi thc hin cc ci cng vic sau  l chng ta da trn nhng ci phn tch v kim nh d liu  ci bc trc  chng ta s tin hnh lm sch d liu v chun ha d liu ca mnh ri chng ta s phi x l nhng ci d liu b thiu  chng ta s phi x l nhng ci d liu ngoi l d liu  thiu ngha l nhng d liu m trong ci dng c trng ca mnh n s c nhng ci gi tr V d nh l nan Tc l khng xc nh th lm sao chng ta phi in c cho cc ci gi tr y  ny mt cch gi l khoa hc v hp l nht ri x l d liu ngoi l  l trong trng hp  C ci s liu  y v d nh y l mt ci s l th hin l ci  tui ca mt ngi no  th v d nh tui  y chng ta  l 100 th liu l cc ci trng thng tin trc  n c m bo c l ci tui ca mnh  y l 100 l mt ci con s nhiu hay khng hay thc s ngi  l ch   100 tui Ti v y l mt ci gi tr m n nm trong ci khong rt l c bit ca  tui ca mnh ng khng  Do  th chng ta phi kim tra xem l ci d liu ny n c thc s l nhiu hay khng V khi m n khng phi l nhiu th chng ta s  nguyn Nhng m nu n l nhiu th chng ta s tm cch xc nh xem ci gi tr thc ca n  l gi tr g hoc l chng ta lm gim ci vai tr ca ci dng d liu ny i thng qua mt s ci phng php chun ha ri to mi c trng feature instruction v transformation ci bc to mi c trng ny th n c th l to ra thm nhng ci ci ct d liu thm ci ci c trng t nhng ci c trng trc  ri chng ta c th bin i ci d liu ca mnh sang mt ci dng thch m ci m hnh my hc n c th x l d dng hoc l n hun luyn hiu qu nhanh hn chn la c trng th nu nh trong ci bng d liu ca mnh n c qu nhiu n c qu nhiu c trng V d nh y l c trng X v y l ci c trng y th X ca mnh n bao gm nhiu ct v khng phi tt c cc ct trong y n u ng gp cho ci vic m a ra ci d on output cui cng  khng phi l ci ct thng tin no n cng c ci vai tr hoc l c ci tm quan trng th chng ta phi lm sao xc nh c Ct no l ci ct quan trng nht chng ta s a vo cho m hnh my hc Ha hc Ct no m khng lin quan hoc l t quan trng th chng ta c th loi b i  trnh gy nhu cho ci m hnh v sau trong ci bc Model Training th n s bao gm ci bc l chng ta xy dng ci m hnh v hun luyn ci m hnh t ci d liu m  tin x l trc  th u tin  l chng ta s phi khi to m hnh vi cc ci tham s u tin v c mt s m hnh th n khng c tham s do   y chng ta s  l nu c v d nh mt s m hnh nh l kis neighbor th n khng c ci tham s nhng m n c siu tham s l k hoc l i vi ci m hnh nh l n bys th n s khng c n s khng c tham s th khi  m hnh ca chng ta ch n thun  l  thit k xy dng v to ra mt ci c s d liu hoc l to ra mt ci cu trc bn d liu  chun b a v cho m hnh n hun luyn hun luyn m hnh vi ci d liu hoc l ci c trng  chun b trc  tc l chng ta s truyn cc ci d liu  c chun ha  c tin x l  c la chn c trng vo bn trong ci m hnh  m mnh c th tm ra c nhng ci tham s ph hp v Bc tip theo th chng ta s nh gi ci m hnh th y c th ni l mt trong nhng bc rt l quan trng Ti v nu nh chng ta khng nh gi c ci m hnh th chng ta s khng th bit trc  khng th bit c l ci m hnh ny n c  hiu qu  c th trin khai ra thc t hay khng v ci model Evaluation ny  th chng ta phi da vo nhng ci  o may tnh cht nh lng chng ta khng th no m da vo ci cm quan l  Chng ta th vi mt vi mu v cm gic l m hnh n chy tt chng ta phi c mt ci  o nh gi trn mt ci quy trnh khch quan v hon thin th  y chng ta s phi s dng nhng ci b d liu khch quan th no l mt ci b d liu khch quan b d liu khch quan phi l b d liu m cha c thy trc  kh Nu m chng ta nh gi trn chnh ci b d liu m mnh hun luyn th khi  ci  chnh xc ca mnh n cng ch mang tnh cht tng i khng c th hin c ci tnh hiu qu ca m hnh ca mnh chng ta s phi dng nhng ci  o hoc l metric rt l c th th ci  o  y th hm   l phi l  o nh lng tc l n phi ra cc ci con s v nu nh ci kt qu tt th chng ta s qua ci Bc tip theo l ci bc kim nh m hnh y l ci bc m quan trng  m chun b trin khai cho thc t cn nu nh ci m hnh ny ca mnh n cha tt th khi  chng ta s quay ngc tr li v khi quay ngc tr li th cng ty vo tnh hung chng ta c th quay ngc n ci bc u tin  l ci bc tin x l d liu bao gm l cc ci bc nh l chn la c trng to thm c trng hoc l chuyn i c trng hoc chng ta ch chuyn quay ngc tr li n ci m hnh Training tc l chng ta to ra mt ci m hnh khc hoc l chng ta hun luyn li ci m hnh vi ci b siu tham s khc Chng hn v cui cng  l nu nh ci m hnh khng tt th  y chng ta  ni ri Ha tc l nu khng c t c ci mc ci chun th chng ta s phi quay li cc ci bc trc v n ci bc tip theo  chnh l Model validation kim nh m hnh th y l ci bc tin hnh kim nh m hnh mang tnh cht h thng Tc l khng phi chng ta ch nh gi  ci gc  l  chnh xc m chng ta phi kim tra xem m hnh ca mnh c   c th trin khai ra n ci ngi dng cui hay khng  th n s bao gm rt nhiu nhng ci yu t khc ch khng phi l yu t v mt i chnh xc  th y l mt ci qu trnh thng c thc hin mt cch c lp vi ci i ng pht trin Tc l  hng trn l chng ta s c mt ci i ng data Engineer kt hp vi li machine learning Engineer hoc l ai Engineer  thc hin Nhng m sang ci hng th hai th do  s l nhng ci i ng khc c lp thc hin mt cch c lp th ci model validation ny th c th thc kim nh cc ci vn  ngoi ci vn  v   chnh xc tc l  chnh xc n vn s thc hin li thc c thc hin mt cch khch quan bi mt ci i ng mi th chng ta c th thc hin cc ci vn  nh l v tc  liu l ci m hnh ny c m bo c l trin khai trong thi gian thc hay khng ri chng ta s kim nh xem ci m  ny n c r r d liu hay khng Tc l u  n s lm gy ra ci vic l lm l nhng ci d liu th ban u hay khng ri m hnh ny c   m c th lu tr c bn trn cc ci h thng m ci ci h thng m ang c hay khng V d nh m hnh ny Gi s nh l mt ci m hnh hc su i gi s Vy th n phi tn rt nhiu ci b nh v i hi rt nhiu ci ti nguyn tnh ton th liu l c th p ng c vi ci h tng h thng hin ti hay khng  th  l nhng ci vn  m chng ta phi trin khai phi kim kim nh trc khi m trin khai chnh thc ri  c chnh xc trn ci d liu cha tng thy hay khng th y s l c mt ci  ng khc h nh gi li mt ln na v  chnh xc tc  thc thi c R R R d liu hay khng vn vn v sang ci bc tip theo  chnh l Model deployment Th ci ny n thng lin quan n mt ci nhn s trong ci h thng ca mnh  gi l ml up th ci ngi k s ml up n s trin khai ci m hnh ca mnh trn ci mi trng thc t nh l ng gi m hnh chuyn giao m hnh th y l mt ci bc m gn nht  m c th a ci m hnh ca mnh n vi ci ngi s dng cui cui cng  chnh l Model feedback Model feedback tc l chng ta s theo di ci phn hi v m hnh v  y chng ta c hai cch  theo di ci phn hi ny mt  l ci phn hi mang tnh cht ch quan chng ta s a ra nhng ci nh gi  xp hng cho ngi dng v ngi dng h s ch ng h s ch ng a ra nhng ci nhn xt a ra nhng ci rating nh gi xem l  ci tnh nng mi ny l mt sao hai sao hay l n sao ri a ra nhng ci comment nhng ci nhn xt  mang tnh chc ch quan ca tng ngi dng  xem coi l ci tnh nng mi ny c p ng c nhng ci nhu cu ca hi khng phn hi khch quan tc l chng ta s da Vo cc ci ch bo trung gian Tc l  y chng ta s khng c  ngi dng nh gi mt cch trc tip m chng ta s theo di ci hnh vi ca ngi dng c thay i hay khng V d  m thc hin c mt ci chc nng no  th trc y h tn ht ba giy Nhng nh ci tnh nng mi ny th n  gip cho h gim xung thc hin ch cn trong vng l 1 giy thi  th chng ta c mt s ci cng c  theo di ci phn mm o lng xem l h thc hin mt ci tnh nng no  c tin hn hay khng c nhanh hn hay khng th  chnh l ci phn hi Khch quen'), Document(metadata={'title': '[CS315 - Chng 3] Deep Generative Models (2) - Part 6 (Phn 1)', 'start_timestamp': '0:02:22', 'video_url': 'https://youtube.com/watch?v=ZS8Ny8QSPQQ', 'chunk_id': 1, 'filename': 'ZS8Ny8QSPQQ', 'end_timestamp': '0:13:35'}, page_content=' y l cng thc ca sinh nh khng c iu kin. i vi sinh nh m c iu kin, chng ta s thm v mt bin na l bin y. y chnh l conditional signal. y l conditional signal. Sau ny khi tng qut ln, y ny khng nht thit phi l vn bn. n c th l mt ci mask, n c th l mt ci im v.v. th cng thc ca chng ta thay v l S theta ca Xt, t th chng ta s thm ci thnh phn l y vo y v khi  th ci St ny s xp x vi li ci gradient ca log p Xt cho trc y y l conditional score Cng thc trc l unconditional score By gi chng ta s chuyn sang conditional score chng ta s a v mt xc sut c iu kin l i Ch cho trc i, th xc sut  tm ra xt khi cho trc i l bao nhiu? Chng ta s trin khai V da trn nh l Bayes th cng thc ny xut pht t trin khai nh sau  l ci log ca Px t cho trc y th n s l bng log ca Pxt cho trc y th n s l bng Pxt nhn vi li Pi cho trc xt tt c chia cho Pi Vi cng thc ny, chng ta s trin khai ra v c c l bng o hm ca log ca PxT Nhn th chng ta s a v du cng,  l cng cho log ca Py cho trc xT Chia th chng ta s chuyn thnh l du tr cho log ca Pi Vi cng thc ny, chng ta thy l v chng ta ang mun tnh o hm theo XT chng ta ang tnh o hm theo XT y l o hm theo XT Trong con mt ca XT, th y ca mnh l hng s Do  chng ta s loi b i thnh phn ny i Ti v o hm ca mt ci hng s i vi xt th n s l bng 0 Do  th cng thc ny s a v cng thc  trn  l log ca pxt cng cho log ca pi cho trc xt V vi ci cng thc ny th chng ta s thy l ci xt ca mnh Khi chng ta khi phc, chng ta decode Bnh thng n s i theo con ng ny l Unconditioned l mu xanh l Mu xanh l tng ng cho Unconditioned Bnh thng n s i theo ng mu xanh dng V qua mu xanh l th chng ta s iu hng i qua mi tn mu xanh v cng 2 ci  li th n s ra ci mi tn mu cam. Th th bnh thng l chng ta s i theo ci con ng ny. Nh c ci vector gradient ca log y cho trc xt, n b li  bin thnh ci vector mu cam ny. Chng ta lu   y n s c thm mt ci h s na, n gi l classifier guidance. Nu nh trong cng thc chng ta bin i  pha trc l chng ta khng c ci gamma  y th hm   l mt ci Unconditional Score n s kt hp vi mt ci Adversarial Gradient tc l ci vector iu hng theo t l  l 1,1 nhng m chng ta mun n nhanh iu hng th chng ta s tng ci h s t l  ln hoc l chng ta mun chm li th chng ta s gim ci h s t l  xung Nh vy trong cng thc ny, gamma s l h s  gim tc  iu hng ca mnh Vector mu cam s l tng hp ca vector mu  trong iu kin l Unconditional Kt hp vi adversarial th n s a ra, b ci hng, thay v chng ta i theo hng ny  m tm c n y th by gi n b hng li, n s i theo ci hng ny  n ci nh m c ci iu kin ging vi li ci Y ca mnh th  chnh l ci Classifier Guidance th th ci m hnh ny s c thc hin nh th no Trc tin chng ta s ni v vai tr ca Classifier Guidance, tc l gamma hi ny ca mnh Nu chng ta chn gamma l bng mt, tc l dng cng thc gc ban u Th kt qu ca mnh s khng c iu hng  tt v  nhanh Dn n l n s to ra nhng hnh th khng c tht Ti sao khng c tht? Ti v n va pha trn ca mt ci nh, ca mt i tng c mt i tng tht m l ra vi vector Z to ra to ra ci x0 khi c s tham gia ca gamma vo th gamma ny n b li nhng n b cha  nhanh dn n  l kt qu ca mnh n to ra i tng lai lai  gia y l ci x0 cn y l ci x0 mi th l ra l chng ta hng n ch ny nhng m ci gamma ca chng ta cha  nn thay v l n b li bnh thng l n y ng khng th n s b li n gia chng v  ci khc gia chng ny th n to ra nhng tm nh nh th ny trong khi  nu chng ta cho classifier guidance tc l ci gamma ln hn v d nh gamma trong trng hp ny bng 10 th n s b li mnh hn  m n n c n ci xnew ging vi li ci ni dung m chng ta mong mun  l Pembroke Welsh Corgi y l mt ci ging ch rt l him Vy th qu trnh sinh  trn l qu trnh sinh c iu kin v n c mt ci Classifier Guidance Vy th chng ta s hun luyn ci m hnh ny nh th no Th ci cch thc hun luyn  l chng ta s c thm mt ci module chng ta s c thm mt ci mng na, n gi l mt ci Classifier hay cn gi l Off-the-shelf Classifier V c vi mi ci i m chng ta a vo th chng ta s i hun luyn cho mt ci classifier nh vy l mt ci i s c mt ci classifier ring V nh vy th n s khin cho ci m hnh ca mnh n khng c tnh linh ng N khng c tnh linh ng v khi chng ta mun to ra mt ci i tng mi Bnh thng chng ta to ra 2 con mo eo knh, by gi chng ta mun to ra 1 con ch Welsh Corgi eo knh chng hn th lc  chng ta s phi train 1 ci classifier mi cho ci y  th n s khin cho ci m hnh ca mnh n chy khng c tnh thc tin cao do  th chng ta s chuyn sang 1 ci m hnh, n gi l ci m hnh m sinh c iu kin nhng m vi Classifier Free Guidance, tc l khng c classifier Vy th cng thc ca mnh s c sa li  l bng 1 tr gamma nhn cho log ca PXT th y l ci Unconditional Score kt hp vi Conditional Score v  y chng ta s hun luyn trn chnh m hnh Diffusion ca mnh lun y chnh l U-Net trong diffusion. U-Net trong diffusion ny chng ta s hun luyn bng cch a 2 tnh hung. Tnh hung th nht l chng ta s a mt vector rng vo. Mc tiu ca mnh tng ng nh mt m hnh sinh nh nhng m khng c iu hng. v chng ta s a y vo, th y ny s l mu d liu hun luyn ca chng ta v y ny s cho trc mt s mu condition m chng ta mun hun luyn  t  n s estimate ra ci x, xt, t, y Th nht l chng ta s khng c thm, khng c classifier m chng ta s hun luyn trn chnh ci m hnh ca diffusion ca mnh lun trn chnh ci decoder ca mnh lun v khi chng ta hun luyn trn ci decoder ny th chng ta s c hai tnh hung mt  l chng ta s truyn v mt ci condition l rng y l mt ci condition rng Mc tiu ca n l to ra tm nh khng c cn iu hng v a vo 1 condition trong data set ca mnh  chun b trc,  chnh l y. Mc tiu ca mnh l iu hng n ci ny l khng iu hng, cn ci ny l c iu hng. sau khi chng ta hun luyn xong, chng ta c s dng decoder ny  a y vo v n s to sinh ra m hnh ca mnh th ci s  ny s tng t nh n s ly t m hnh m chng ta  hc trong nhng slide trc bnh thng l chng ta ch a vo xt v t, by gi chng ta s a vo thm y na  lm c vic ny th chng ta c th s dng cc m hnh ca Transformer vi attention s dng key-value ca attention  iu hng th ci i ny c th l query'), Document(metadata={'playlist': 'PLb62OySGqC9yGRvUaSe-iWFuXYuM8X6_n', 'title': '[CS116 - Bui 3] Part 3 (tt)', 'filename': 'oZa-m3pb1SQ', 'end_timestamp': '0:13:55', 'video_url': 'https://www.youtube.com/watch?v=oZa-m3pb1SQ', 'chunk_id': 1, 'start_timestamp': '0:08:34'}, page_content=' mi mu ny tng ng l mt ci gi tr trong ci ct  trong ci c trng dng phn loi  tng t nh vy th chng ta c th s dng ci biu  dng boxplot th trc honh  l biu tng biu tng cho ci  gi tr  l ci c trng  l gii tnh v n nhn hai ci gi tr  l Male v Female trc tung  l gi tr dng s  numeric ri Trong  th vi mt ci gi tr ca ci bin  gii tnh th chng ta li c hai ci boxplot tng ng cho ci feature th ba ng khng th y l ci feature s 1 n y l ci feature s 2 n V khi chng ta chia ra lm hai loi nh th ny v mi loi l mt mu th n tng ng l chng ta ang phn tch cho ci feature s 3 v  pht hin ci d liu b thiu th chng ta c th s dng cc ci hm l isna ca dataframe Nh vy th trong ci slide T y tr v sau th chng ta s lin quan n ci cng vic  l pht hin ra nhng ci vn  trong ci d liu ca mnh th ci vn  u tin  chnh l vn  d liu b thiu chng ta nhn v ci bn d liu y chng ta s thy c mt s ci v tr l d liu ca mnh n b NaN  th y chnh l mt s ci tnh hung d liu b thiu v chng ta c th loi b cc ci gi tr b thiu ny thng qua ci hm l drop NA ri pht hin d liu b nhiu th chng ta s da trn cc ci phng php  l thng k V d nu nh ci d liu ca mnh m n tun theo ci phn b Gaussian hoc l tng t nh Gaussian th chng ta c th s dng cc ci gi tr  l gi tr trung bnh (mu) v vi ci gi tr  y chng ta s c cc ci khong gi tr nu nh mu m tr 2 Sigma ng khng Chng ta c gi tr  y  th nu nh ci gi tr no m nh hn mu tr 2 Sigma (Tc l n ch chim khong l 2,1 phn trm thi) th nhng ci gi tr no m rt vo trong ci khong ny th chng ta xem n l outlier tng t nh vy cho mu cng 2 Sigma th nu nh gi tr ca mnh m rt trong khong ny th chng ta s xem n l outlier cn i vi nhng ci d liu m khng c tun theo phn b chun khng theo khng c tun theo phn b Gaussian th chng ta s dng ci phng php l IQR l Interquartile Range bng cch  l chng ta s xc nh cc ci gi tr Q1 v Q3 ri sau  ly Q3 - Q1 th chng ta s c ci khong gi tr l IQR  (Interquartile Range) v vi ci khong gi tr ny chng ta ly Q1 tr cho 1,5 IQR th chng ta ra c ci gi tr ny ly Q3 cng cho 1,5 IQR th chng ta s ra c ci gi tr ny v tt c nhng ci gi tr no m nm ngoi ci gi tr minimum v maximum trong nhy kp ny Tc l  y ci gi tr ny n khng thc s l ci gi tr nh nht v gi tr ny n khng thc s l gi tr ln nht nn mnh mi  du nhy kp  th nu nh ci gi tr no m vt qu ci gi tr ny th n c gi l outlier v gi tr no m vt qua ci gi tr  y th n l outlier th y l ci phng php cc ci phng php  m phn tch v xc nh d liu l nhiu da trn thng k v trong ci phn tin x l d liu th chng ta s  xem thm chng ta s s dng cc ci phn tch thng k ny  a vo ci qu trnh tin x l d liu trong tin x l d liu chng ta s nhc li ci vn  ny mt ln na v chng ta s c cc ci gii php  x l cc ci gi tr outlier ny nh th no nh vy th trong bi Ngy hm nay chng ta  cng tm hiu v Machine Learning Pipeline. Machine Learning Pipeline l mt trong nhng ci ni dung rt l quan trng Ti v n nh hnh cho chng ta bit l ci quy trnh Chng ta cn phi xy dng  Mt ci m hnh my hc l nh th no ri v ng thi l vai tr ca tng ci bc trong ci m hnh my hc trong ci quy trnh xy dng my hc  ra sao v chng ta s tin hnh  phn tch v tm hiu cc ci phng php cho ci bc u tin  l phn tch d liu cc ci phng php  m phn tch d liu  l g ri cc ci vn  chng ta s pht hin cc ci vn  trong ci d liu ca mnh ra sao  lm tin  cho ci bc l data preprocessing tin  cho ci bc l tin x l d liu v sau th  l cc ci phng php c gi l EDA l Exploratory Data Analysis'), Document(metadata={'start_timestamp': '0:00:14', 'end_timestamp': '0:16:13', 'chunk_id': 0, 'video_url': 'https://youtube.com/watch?v=2s07XUliDHY', 'title': '[CS315 - Chng 4] Vision - Language Model (1): Part 2 (Phn 1)', 'filename': '2s07XUliDHY'}, page_content='M hnh u tin chng ta s cng tm hiu trong nhm Vision Language Model l clip trong bi bo Learning Transferable Visual Model from Natural Language Supervision y c th ni l mt trong nhng m hnh ngn ng th gic u Cho n hin nay th clip vn c s dng kh ph bin trong nhiu tc v ca cc bi ton th gic my tnh Th u tin chng ta s pht biu vn  ca cc m hnh th gic trc y Cc m hnh th gic trc y u c hun luyn trn nhng tp d liu ln V d nh tp d liu ni ting m hin nay vn cn c s dng  l tp ImageNet Tp d liu ImageNet ny th n s c s lng rt ln ln n hng triu mu V n bao gm mt tp l nh cng vi li mt ci nhn Th ci nhn ny n s  dng ngn ng t nhin Tuy nhin thc t th chng ta hnh x vi ci nhn ny n ging nh l vi mt ci con s nhiu hn l ngn ng Ti v khi ni v ngn ng th chng ta s phi ni n cu c Chng ta phi ni n cu, phi ni n on vn Phi ni n khi nim l m t chi tit Cn ci nhn  y th n mi ch dng li l i tng ca chng ta  y l i tng g V d  trong hnh bn di chng ta c hnh mt con ch th ci nhn ca chng ta l con ch Tuy nhin khi chng ta xy dng ci m hnh ny xong, hun luyn ci m hnh ny xong th khi chng ta a vo mt ci hnh thuc ci domain khc V d nh hnh hoc hnh hoc l hnh con ch robot Th liu ci m hnh ca mnh n c cn d on y l con ch na hay khng Chng ta  ci du chm hi  y ha  chnh l ci vn  bt cp ca cc ci m hnh hun luyn m da trn ci loi d liu hnh nh v nhn  l v chng ta ang hnh x vi ci nhn ca mnh nh l mt con s m chng ta cha thc s xem n nh l mt ci yu t ngn ng m t Vy th vi tp d liu ImageNet ny th chng ta thy l n c ln n hng ngn class V d liu u ra ca chng ta l ci vector 1000 chiu Tc l chng ta vn xem cc ci nhn ny nh l mt ci vector s hc V n khng c s lin kt gia cc ci nhn vi nhau N khng cho bit l con ch v con mo th n c s ging nhau ra sao Ri ci hnh vi ca n tng t nh nhau nh th no Th th chnh v ci cch m chng ta ang hun luyn m hnh nh vy V cch chng ta s dng tp dataset ImageNet dn n l ci m hnh ca mnh s b gii hn bi s lng class ca mnh Tc l nu chng ta xy dng mt ci m hnh m c 1000 chiu tng ng vi 1000 lp i tng Th sau ny khi c nhng ci i tng mi th n s t c ci kh nng hc ra c hoc l nhn bit ra c V d nh  y chng ta thy l cng l con ch nhng m theo mt ci phong cch khc th ci m hnh ca mnh n s b lng tng V n khng c ci tnh gi l c lp cng nh l tm gi l sng to  m suy ngh Th th  tng chnh ca clip  l thay v chng ta hun luyn da trn mi lin kt gia hnh nh v nhn Ngha l nhn hoc l label th chng ta s da vo, chng ta s hun luyn da vo ci mi lin kt gia hnh nh v ci vn bn m t R rng l trong cc cu khu ng trc y ngi ta hay c cu  l mt hnh nh th l bng 1000 li ni Tc l trong tm nh ca mnh n s c rt nhiu thng tin ch khng phi l n ch c mt ci nhn khng Th th nu chng ta ch c mt thng tin ca mt ci nhn n s gii hn ci ni dung trong tm nh , gii hn ci ni dung ngha Dn n l m hnh ca mnh n s khng c khai thc c ht ci d liu ca mnh V d nh trong tm hnh ny th l ra l chng ta s phi ni chi tit hn, v d nh l con ch mu trng v nm cnh mt con mo mu nu  trong tm chn sc v trn mt ci ging Tc l  y chng ta thy n c rt nhiu nhng thuc tnh, i tng, ri ci ging R rng l mt tm hnh n s c rt nhiu ci thng tin nh vy Th nu nh chng ta c mt ci m hnh m c kh nng va hc c hnh nh v va hc c ci ni dung m t  m khai thc c cc ci thng tin  th r rng l ci m hnh ca mnh n s thng minh hn v chng ta cng s  tn km hn trong ci vic l gn nhn d liu Th ci m hnh ngn ng, ci m t ngn ng n s cha nhiu thng tin hn l mt ci nhn n l Th  chnh l mt trong nhng ci key idea,  tng chnh  khin chng ta xy dng mt ci m hnh thay v hun luyn trn nh v nhn th chng ta s hun luyn trn hnh nh v vn bn V ci ny th thch hp  s dng lm ci thng tin gim st qu trnh hc Tc l ci vn bn ca chng ta n c th l mt ci dng thc, l mt ci loi d liu  gip chng ta gim st ci qu trnh hc, tc l n vn nm trong ci dng hc v gim st Vy th cu hi t ra  l lm sao  m c th hc c mi lin kt gia hnh nh v vn bn  m n c th khai thc c tt ci thng tin ny Th chng ta s s dng ci hng tip cn  l Contrastive Learning, tc l hc tng phn Th th hc tng phn l g? Mc ch ca hc tng phn  l chng ta s hc mt ci b m ha vn bn V b m ha vn bn, tc l Text Encoder V mt ci b m ha hnh nh, tc l Image Encoder Th th  trong ci v d  y, ci ny khng phi l v d m l ci m hnh  y Chng ta thy l khi chng ta hun luyn th n s i mt cp N s i mt cp l hnh nh v vn bn V hai ci cp nh v vn bn ny khi chng ta chiu ln trn ci khng gian latent N s gn nhau, ti v y l ci cp ni dung i chung vi nhau Trong ci khng gian latent, ci biu din ca vn bn ny v nh ny n phi gn nhau V tng t nh vy, hai ci vn bn v hnh nh ny th n cng phi gn nhau Cc ci hnh nh v vn bn m c ci ni dung khng ging nhau th n s phi xa nhau V d nh chng ta thy ci cp nh v vn bn  y C th l n c cha mt ci ni dung khc hon ton th n s nm xa nhau Nh vy th ci khng gian c trng ca chng ta  y l mt ci khng gian c trng m a kiu d liu Hay cn l a th thc V a th thc Ri, th th chng ta s c mt ci hnh nh minh ha bn l cho ci vic hc tng phn  l  trn y chng ta s thy l x1 v x2,  l cng mt ci ging ch Nhng m n  trong nhng ci bi cnh khc nhau, v d nh y l mt ci bi c Cn  y l mt ci vng nn en Th th nhng ci i tng no m ging nhau th n s nm  gn nhau V chng ta thy l gia hai ci nh u tin th n c ci s tng ng rt l cao Do  khi chng ta biu din ln trn ci khng gian Latent Space th hai ci im ny l gn nhau V nhng ci i tng ny u c cng mt ci m t  l French Bulldog Tc l mt ci ging ch bulldog ca Php th n s nm  trong mt ci cm Ri, cn ci con ch x2 th n cng l con ch  Nhng m n trong ci background mu en th n s nm  ngoi ra S d ti sao n nm ngoi ra nh th ny l v n c ci nn n khc i Vy th khi chng ta xy dng ci m hnh hc tng phn th n s phi m bo  l Hai ci i tng m tng t nhau th n s nm gn nhau Cn hai ci i tng v d nh l ch v mo  l hai ci class rt l xa nhau Th  y n s nm hai ci khng gian rt l xa Ri, thm ch l trong ci ging ch th Brittany th n l mt ci ging ch khc Th n s nm  mt ci khu vc khc Cn ci ging ch French Bulldog th n s nm  mt khu vc khc N s b xa nhau ra nh th ny Th  chnh l ci  tng,  l nhng i tng no m gn nhau, ging nhau th n s nm gn nhau Cn i tng no m xa nhau, khng ging nhau th n s cch xa  trn ci khng gian latent V ci vic ny th n cng hon ton tng t khi chng ta lm vic trn ci loi d liu l vn bn N cng hon ton tng t nh trn hnh nh Vy th ci bi bo Clip Contrastive Language, vit tt ca ch l Contrastive Language Image Pre-training T ci bi bo ny, th chng ta thy l c t mu, cc ci mu  y V chng ta s cng gii ngha  ngha ca cc ci t ny u tin  l Transferable Visual Model,  l m hnh c th s dng linh hot cho nhiu ci bi ton khc nhau Ngha l ci m hnh Clip sau khi chng ta  xy dng c ri, th chng ta c th Transfer Learning cho cc ci bi ton lin quan n th gic my tnh khc nhau V d nh chng ta c th dng n cho bi ton phn loi hnh nh, c th dng n cho bi ton segmentation, phn on ng ngha, c th dng n cho bi ton detection Nhng m ng nhin ci cch chng ta s dng nh th no th n s c nhng ci cch thc khc nhau, mt phng php khc nhau Ri, ci cm t th hai  l Natural Language Supervision, tc l tri vi nhng ci m hnh trc y v d nh l VIT hoc l m hnh CNN nh l ResNet v.v. th ci supervision ca n  l Label Cn  y, ci m khin  gip chng ta gim st qu trnh hc  l ngn ng t nhin, n khng phi l Label, Label ch l mt trng hp c bit ca ngn ng t nhin V d Label ca chng ta  l Dog hoc l Cat, cn Natural Language Supervision  l chng ta s c mt cu v d nh l Red Car on a street, v d vy, th y l mt ci ngn ng m t Nh vy th qu trnh hun luyn s da trn ngn ng t nhin v y l ngn ng  m t cho tm nh ca mnh V ci cm t tip theo  l t Contrastive, th ci Contrastive ny n nm trong ci nhm  l Contrastive Learning hay l hc tng phn, th y l mt cng c chnh m chng ta s s dng  hun luyn ci m hnh clip ny Ci cch lm ca Contrastive Learning  l chng ta s c hai ci cp, c cc ci cp, v d nh cp gn nhau v ci cp xa nhau Th nu hai ci i tng m cng nhm vi nhau, c ci ni dung ging nhau th n s ko v gn nhau, nhng m hai ci i tng m n c ci ni dung khc xa nhau th ci khong cch ca n s cng xa, n s y ra Th  l ci t tng ca Contrastive Learning v y chnh l ci cng c chnh cho ci m hnh clip  hun luyn Ci t Pre-training c ngha l tin hun luyn, tc l hun luyn sn, th y l mt ci m hnh c hun luyn sn v c kh nng suy lun khng cn ci d liu hun luyn, tc l Zero Shot Inference V cht na th chng ta s ni l ti sao ci khi nim Zero Shot  y c s dng, v  y l khng hun luyn trn ci khng gian c trng, a th thc ca mnh  c hun luyn sn Trong bn tay phi ca chng ta,  l hnh nh minh ha, nu nh chng ta s dng tp d liu ImageNet v vi m hnh ResNet 101, th clip s cho clip vi backbone,  l ViT-L, cho  chnh xc cao hn V d nh y l 76.2 th l tng ng vi 76.2 ca ResNet 101, nhng cc dataset khc nh ImageNet V2, kh hn phc tp hn v i tng ca mnh ln ln nhiu hn, clip ViT cho kt qu l 70 so vi li 64.3 V ImageNet Rendition, tc l nhng tp ImageNet m c to ra bng render hoc l bng cc phng php to sinh, khng phi l nh tht, th chng ta thy s khc bit ny cng chnh lch hn na Cn tp d liu khng c tht ny th khi p dng vi ImageNet ResNet 101 th  chnh xc ch c 37%, tng t nh vy V i vi tp d liu cui cng th chng ta thy l gn nh l clip hn tuyt i, do ci tnh phc tp ca n, ci tnh phc tp rt l cao Th  nhng tp dataset  trn th chng ta thy n kh l n gin v d, nhng cng xung di th cc dataset ny thuc domain khc v khng c nhiu mu d liu  hun luyn Ri ZeroShot nn dn n l  chnh xc khi chng ta s dng m hnh ResNet 101 th  chnh xc ca chng ta rt l thp, cn clip th n rt l cao Vy th  tng ca clip  l g?'), Document(metadata={'end_timestamp': '0:07:31', 'playlist': 'PLb62OySGqC9wDaL2dnF_5J8f49e_YNi2f', 'filename': '_nPettH0cXg', 'start_timestamp': '0:05:47', 'video_url': 'https://www.youtube.com/watch?v=_nPettH0cXg', 'chunk_id': 4, 'title': '[CS114 - Chng 3] Minh ha Feature Engineering (Phn 1)'}, page_content='ng khng?   y derivative theo W1 th n s l bng NP. Min ca n s l gi tr d on tr cho gi tr thc t. Th gi tr d on ca chng ta chnh l x W1 nhn vi X cng cho W2 nhn vi li  X bnh phng cng cho v tt c th chng ta s tr cho tr cho Y. Ri v  y l ci thnh phn  v chng ta ang xt trn ci thnh phn l W nn n s c nhn vi li ci o hm ca  ca ci W1 theo ci v ny th o hm ca W1 theo ci v ny th n s l bng X. Do   y chng ta s nhn thm vi X. Tng t nh vy th chng ta s c ci o hm bc hai  xin li o hm cho w2 th n s l bng w1x + w2x2 + b - y v nhn cho ci o hm ca ci v bn trong ny theo w2 th o hm ca ci ny theo w2 n s l bng x2 tc l x bnh.  tng t nh vy cho bias B th chng ta s nhn cho ci o hm ca ci v bn trong ny theo B. Th chng r rng l cc ci thnh phn ny i vi B n l hng s do  o hm bng 0. Cn o hm ca B  theo B th n s l bng 1.'), Document(metadata={'video_url': 'https://www.youtube.com/watch?v=NCSIAbS9gWs', 'filename': 'NCSIAbS9gWs', 'playlist': 'PLb62OySGqC9wDaL2dnF_5J8f49e_YNi2f', 'title': '[CS114 - Chng 3] Cu hi tho lun (Phn 1)', 'chunk_id': 2, 'end_timestamp': '0:04:27', 'start_timestamp': '0:02:39'}, page_content=' l nh ci hm e m. E m l mt ci hm a thc m c th c m bo l c th tnh c ci gii gi tr t m bo c ci gii gi tr t -1 cho n  t 0 cho n 1  a v ci khng gian  xc sut. Th th  y chng ta s phn tch xem l vi ci sigmoid nh th ny th n s c nhng ci yu im g hay khng. Th trong ci cng thc ny   l n s b hn hoc bng tng ca hai ci ny th sigmoid nhn vi 1 tr sigmoid th n s l bng 1 tt c bnh phng chia cho 4. . Nh vy th ci y v d nh y chnh l a ha, y l a, y l b th a nhn b s b hn hoc bng a + b tt c bnh chia 4 th sigmoid cng cho 1 - sigmoid n chnh l bng bng 1. Th ci  gi tr ln nht ca mnh cho ci hm sigmoid ny  chnh l  xin li o hm ca sigmoid ny  chnh l 0.25. V nu nh sau ny cc ci m hnh ca mnh hc su  m c nhiu ci hm kch hot ny th c th s gy ra ci hin tng n gi l vanishing gradient. Vanishing gradient th y l mt ci vn  rt l kh khn  trong ci vic m hun luyn ci m hnh ca mnh n c th thc hin c ci bc cp nht tham s mt cch nhanh chng th gradient descent  n s cn tr ci vic . V mt trong nhng ci cn tr  chnh l n t ci hm kch hot ca mnh.'), Document(metadata={'chunk_id': 10, 'video_url': 'https://youtube.com/watch?v=-7JWQptLoMQ', 'title': '[CS315 - Chng 2] S tin ha ca cc m hnh chui (Phn 1)', 'filename': '-7JWQptLoMQ', 'end_timestamp': '0:12:42', 'start_timestamp': '0:11:39'}, page_content='Cn cch bn phi  y th n s cho chng ta thy c ci quy trnh i t u n u. Nhng m n s khin chng ta nhm ln rng l y l mt ci gi tr scalar. Thc t khng phi, n s phi l mt ci vector. Th th chng ta s cng n vi ci bin th u tin,  l Bi-directional ANN. Th ci vn  ca cc ci mng ANN trc y  l g?  l ANN ch c d liu mt chiu. V d chng ta c The Movie World terribly, th nu nh chng ta c n ci ch terribly, th ci t ny n s mang ci  ngha  l negative. N s mang ci  ngha l negative.'), Document(metadata={'chunk_id': 0, 'title': '[CS116 - Bui 8] Part 9', 'filename': '7w5EiDHtIII', 'start_timestamp': '0:00:00', 'video_url': 'https://www.youtube.com/watch?v=7w5EiDHtIII', 'end_timestamp': '0:11:18', 'playlist': 'PLb62OySGqC9yGRvUaSe-iWFuXYuM8X6_n'}, page_content='trong bi trc th chng ta  th nghim m hnh Logistic vi ci d liu tuyn tnh th by gi tip theo chng ta s th nghim vi ci d liu c quan h phi tuyn tnh  y chng ta s th nghim vi hai ci im mu xanh v mu  trong  mu  s nm bn trong mt ci vng trn v mu xanh s nm bn ngoi mt ci vng trn th chng ta thy l ci trng hp ny chng ta khng th chia tch ra hai ci tp mu xanh v mu  ny bi mt ng thng nht ng khng Th  y chng ta s gi li ci hm Logistic Regression ri chng ta s khai bo li Logistic Regression v chng ta s truyn vo ci x v y tng ng l cc ci im xy  bn y  khi to bi ci hm make_circles ca ci module l datasets v chng ta cng s trc quan ha ci d liu ny vi ci hm  v m hnh  ci t  trong phn trc ri chng ta copy ci ni dung ca ci hm ny xung v  y c mt ci lu   l x ca mnh  l n s bt u ci im bn tri ca mnh n s l X1 ca mnh s l bng -1 v X2  Xin li X1 bn tay phi  ci im bn phi ny n N s l 1 X1 = -1 v X1 = 1 th t  mnh s d on vi ci hm m hnh ca mnh mnh d on xem ci im y X1 X2 tng ng l bao nhiu th mnh s c ci hm l calculate_X2 v khi chy ci hm ny ci on code ny th n v ra mt ci ng thng chia ci tp im ny ra lm hai phn nh vy th chng ta c th thy l ci ng thng ny n khng c tch hai ci im mu xanh v mu  ra lm hai v cng d hiu nu nh ci  chnh xc accuracy ca mnh l thp trong trng hp ny chng ta thy l accuracy ca mnh l bng 0.505 tc l khong 50 phn trm Tc l n ch ng cho mt na thi cn mt na l b sai V d  y n s ng cho mt na cc ci im mu xanh v n b sai cho mt na xin li n ng cho mt na ci im mu xanh  bn y v mt na cc im mu  bn y v n b sai bi cc ci im ny v sai bi cc ci im ny ri v by gi chng ta cng tng t nh vy chng ta s tin hnh feature engineering chng ta s to thm cc ci c trng mi th  y chng ta c X1 v X2 chng ta s feature engineering thm l nu nh X1 ng khng th chng ta s to ra thm l X1 m 2 ri tng t nh vy X2 chng ta s c l X2 m 2 v chng ta cng khng nn qun chng ta s to ra thm mt ci c trng na  l X1 nhn vi li X2 th  m bo l c ci s kt hp gia c trng ca X1 vi X2 Nh vy th ci hm ca mnh n mi ph thuc mt cch bc hai v X_new ca mnh chnh l ci c trng mi bao gm X_c ng khng km theo n y chnh l X1 n X[:,0] th y chnh l X1 bnh phng phng X[:,1] bnh phng y chnh l X2 y chnh l ci X2 ca mnh v X2 ca mnh v X[:,0] nhn vi li X[:,1]  chnh l ci thnh phn X1 nhn vi X2 th chng ta s dng horizontal stack ha v chng ta s c ci kch thc ca ci X_new ny chnh l bng 400x5 trong  5  y bao gm  y l 5 features l bao gm l X1 n X2 n ri X1 bnh phng n X2 bnh phng n v X1 nhn vi li X2  th y l nm ci features mi ca mnh v tng t nh vy th chng ta s cng build ci model ny ln  th xem ci accuracy ca mnh trong trng hp ny l bao nhiu ri  y th mnh s fit predict ci X_new ny X_new  y s phi l X_new  nh vy th sau khi chng ta  thc hin ci feature engineering engineering xong th n s ra l  chnh xc l bng 100 phn trm th r rng vi ci phng php feature engineering n  to ra c ci s hiu qu khi chng ta d on c  ci c trng mt cch ng n tc l y l mt ci ci ng phn chia hai ci tp mu xanh v mu  ny  N l mt ci dng bc hai  l mt ci dng bc hai ca hai ci c trng u vo l X1, X2 tuy nhin trong trng hp m chng ta khng bit c ci d liu ca mnh n qu nhiu chiu X ny ca chng ta N khng ch c hai chiu X1, X2 m c th ln n hng trm chiu v chng ta cng khng  ci tri thc  chng ta bit c rng l c nhng ci dng m hnh no  chng ta feature engineering th khi  chng ta s s dng mt ci cng c  chnh l Neural Network mng neuron nhn to cho ci trng hp d liu phi tuyn th  y chng ta  c mt ci cch  m ci t chng ta  c on code  ci t sn  Neural Network N l mt ci tn gi khc trong scikit-learn  l Multi-layer Perceptron Multi-layer Perceptron V N l mt ci dng classifier n nm trong ci lp l scikit-learn Neural Network v  y th mnh s c ci tham s cho ci model ny ca mnh th hidden layer  y  l cho bit l ci mng neural ny s s bao gm layer th  y chng ta s tra cu ha l Neural Network th ci Neural Network ca mnh n s c nhiu layer nhng m trong trng hp ny chng ta s lm mt ci mng n gin l ch bao gm duy nht mt layer l mt ci lp n thi mt hidden layer thi ging nh trong ci hnh  y l mt lp n v lp n ny th trong ci hnh v d ny th n s c l 4 neuron nhng m chng ta  y chng ta s cho n 10 neuron v hm kch hot  y mc nh chng ta s s dng l hm Logistic Regression v cc ci solver Tc l ci thut ton  ti u ci mng neural Network ny th mc nh chng ta cng nn s dng Adam v mt lot cc ci tham s khc v sau khi chng ta khai bo xong th chng ta s tin hnh fit trn ci data c tc l lu   y chng ta s khng s dng ci data X_new Ti v X_new n  c cha ci c trng  c engineered l cc ci c trng m chng ta    thm v  th  y chng ta ang gi nh rng l chng ta s dng ci d liu th raw data s dng d liu th Chng ta khng c ci tri thc g v ci m hnh ca mnh th chng ta s gi ci hm net.fit v sau  th chng ta s dng ci hm nh gi th vi ci hm nh gi ny chng ta thy  chnh xc l 100 phn trm nh vy vi Neural Network chng ta khng cn phi lm ci bc feature engineering V y l cc ci tham s ca bias cng nh l  Xin li y l cc ci tham s ca bias v chng ta s cn mt ci na l chm score v coefficients ri th  y n s phc tp hn so vi li ci Logistic Regression mt cht xu  y l chng ta s c 10  y chng ta s c 10 node 10 ci neuron th tng ng bias ca mnh n cng s c 10 ci gi tr mnh s c 10 ci gi tr cho ci layer th  gia cn  ci lp u tin th chng ta ch c duy nht mt ci bias thi trong lp u tin chng ta s c duy nht mt ci bias cn sang ci lp tip theo th chng ta s c n 10 ci bias v tng t nh vy th cho ci h s th chng ta cng s c cc ci layer mi layer chng ta s c cc ci h s cho cc ci trng s ca mng neuron v  y th chng ta c sn mt ci chng trnh  gip chng ta trc quan ha ci mng cc ci kt qu trng s ca ci mng ha chng ta thy l vi mi mt ci neuron vi mi mt neuron n bn cht chnh l mt ci Logistic Regression m mt ci Logistic Regression th bn cht N l mt ci l ct mt ci ng phn lp nh vy mt ci neuron trong 10 ci neuron ca mnh n s l mt ci ng thng nh th ny v chng ta c 10 neuron th chng ta s c 10 ci on thng v chng ta thy rng mi mt ci neuron s l mt ci weak classifier tc l mt ci b phn lp yu vi mt ci phn lp mu xanh l nh th ny chng ta thy n s phn ra l mu xanh dng l nhng ci im no m nm v pha bn y l chc chn l xanh dng cn nhng im no m nm  pha ngc li th khng chc do  th n s phi phi hp nhiu ci neuron li vi nhau v khi chng ta thy khi phi hp nhiu ci neuron li vi nhau th n  gip cho chng ta tch c cc ci im mu xanh v mu  ra nhng ci im no mu  th n s nm bn trong v nhng ci im mu xanh th n s nm bn ngoi nh y nh vy th y chnh l mt ci cch  cho chng ta c th trc quan ha mng Neural Network vi cc ci node n ca mnh mi mt ci neuron trong ci lp n ny s c  v ln di dng l mt ci ng thng v mt ci mng Neural Network th n s l t hp ca nhiu ci neuron tng ng l t hp ca nhiu cc ci weak classifier cc ci b phn lp yu nhiu b phn lp yu n s to ra thnh mt ci b phn lp mnh v nh vy th n  gip cho chng ta chia tch hai ci tp im mu xanh v mu  ny ra lm hai phn th trn y chnh l ci minh ha cho vic  to ra cc ci b phn lp trn d liu phi tuyn tnh s dng c Logistic Regression v Neural Network i vi Logistic Regression th chng ta i vi d liu phi tuyn th chng ta phi l chu kh chng ta lm thm ci bc feature engineering m  t c ci feature engineering ny m tt th chng ta s phi c ci kinh nghim c ci kin thc v ci d liu ca mnh Mnh bit ci d liu ca mnh n c ci ph thuc nh th no  m mnh chn ci c trng mi cho n ph hp Cn trong trng hp m chng ta khng c c ci c trng mi xin li chng ta khng bit c ci thng tin khng c c ci tri thc th chng ta s s dng mng Neural Network v mng Neural Network ny th mt cch tng qut n c th l c nhiu layer n'), Document(metadata={'playlist': 'PLb62OySGqC9xl1_deMF_UXP5tA2Tvt17_', 'start_timestamp': '0:04:03', 'end_timestamp': '0:06:10', 'title': '[CS431 - Chng 6] Part 2: Hng tip cn Deep learning cho cc bi ton NLP', 'chunk_id': 3, 'filename': 'utOha-d0prc', 'video_url': 'https://www.youtube.com/watch?v=utOha-d0prc'}, page_content='th thnh tu ca cc m hnh hc su hin nay l  gip cho Deep Learning pht trin mt cch vt bc. Ri, v s   bn y th chng ta c th thy l trc y cc h thng ca mnh n s da trn rule, hoc l nhng ci h thng gi l kinh in th n u phi c nhng ci hand-designed programs, tc l cc ci chng trnh ny s do nhng ci tri thc ca cc chuyn gia h thit k ra. V  ci mc  l Classical Machine Learning, th n s c cc feature, c cc cng c  mapping gia cc feature v thm ch l cc chuyn gia h s phi thit k cc c trng ny. V d khi chng ta lm vic trn hnh nh, th chng ta bit l mi quan h gia cc pixel vi cc b lc chp, chng ta s thit k cc php bin i l filter v trng s ca cc filter s l do chuyn gia h thit k. Tng t nh vy, trong lnh vc x l ngn ng, ng nhin chng ta s c nhng ci trick, nhng ci mo  gip cho hc cc m hnh, v d nh LSTM, hoc l m hnh hc su. Tuy nhin th trc y ngi ta khng c s dng cc m hnh m t hun luyn  to ra cc trng s m h phi thit k trc cc trng s da trn mt s lut, v d nh l m hnh da trn Bayes  thng k xem l ci t ny xut hin, th xc sut ca ci t tip theo s l bao nhiu? H s thng k. Ri, v gn y th Representation Learning v in hnh  l Deep Learning, th n s a vo nhng ci simple features v thm ch nh mnh  c  cp ,  l chng ta khng cn phi a c trng ca n v chng ta c th a d liu th u vo th my vn c th hc c. Ri.'), Document(metadata={'title': '[CS431 - Chng 9] Part 1_2: Gii thiu bi ton Dch my', 'playlist': 'PLb62OySGqC9xl1_deMF_UXP5tA2Tvt17_', 'end_timestamp': '0:11:46', 'chunk_id': 2, 'start_timestamp': '0:04:44', 'filename': '--JpgsDEL40', 'video_url': 'https://www.youtube.com/watch?v=--JpgsDEL40'}, page_content='Nh vy th iu  c th ni l trong mt thi gian rt ngn, Seq2Seq  to ra c mt bc t ph c v trong hc thut ln trong lnh vc v cng nghip, v cng ngh. V cc cng ty cng ngh  chuyn i hon ton sang m hnh Seq2Seq ny, th iu  chng t l tnh hiu qu ca m hnh ny v ng thi n c kh nng d dng m rng cho rt nhiu nhng ngn ng khc nhau cng nh l sau ny khi c nhng t kha mi th n cng c th d dng hc v cp nht li c th  chnh l thnh tu ca Neural Machine Translation V  nh gi c m hnh dch my th y l mt trong nhng bi ton kh trong vic l nh gi Ti v mt ci bn dch ca mnh Mt ci vn bn ngun ca mnh Th n c kh nng nhiu Cch dch khc nhau V d nh cng mt ci cu  Nhng m mt ci ngi theo chuyn ngnh V khoa hc Th h s dch theo mt phong cch V ngi theo chuyn ngnh v X hi th s dch theo Mt cch hoc l mt ngi tr V mt ngi ln tui H c th dch theo mt ci cch khc nhau sau  th nh gi mt m hnh dch my th y l mt ci vn  kh nhng m kh th khng c ngha l khng c gii php v mt trong nhng gii php ph bin hin nay  m c th nh gi c m hnh dch my ca mnh c tt hay khng  l s dng  o BLEU BLEU l vit tt ca ch bilingual evaluation understudy th BLEU so snh ci phin bn dch my vi mt hoc l nhiu mt th tuy nhin ri, nhng m n phi l  tng tnh khch quan th n nn l so vi nhiu ci bn dch khc nhau so vi nhiu ci bn dch khc nhau ca cc chuyn gia lu  l ci bn dch ny cng phi l ca chuyn gia nha ch cn nhng ngi m khng chuyn v ngn ng th c th l s dch khng tt v sau  th s tnh c ci  tng ng gia ci bn dch vi li ci bn ca chuyn gia v  y ci cch m ngi ta so snh  l s dng trung bnh iu ha ca cc N-gram Precision tc l thay v chng ta ch so vi tng ch th  y chng ta s so vi cm N ch V d nh l bn dch l mt t, ri ca chuyn gia  l 1 N-gram 3 t, y l 1 N-gram 2 t v y l 1 N-gram 1 t N s tnh trung bnh cho N-gram Precision, trung bnh iu ha V BLEU th mc d l hiu qu nhng m khng c thc s l hon ho, n cng khng hon ho Ti v sao? Ti v n s b bias hay b ch quan bi cc chuyn gia ca mnh V nh   cp, dch my c rt nhiu cch dch khc nhau, rt l uyn chuyn Mnh khng th c nh c mt cch dch Ri cha k l ci yu t v tnh phc tp ca ngn ng na Th th c nhiu ci bn dch tt, hu qu  l g? C nhiu ci bn dch tt nhng m BLEU th li cho ci score thp v ci chuyn ny th cng khng phi l him, chuyn ny cng khng phi l him xy ra Tuy nhin, cho ti thi im hin ti th BLEU l mt trong nhng  o nh gi m tin cy N khng hon ho nhng m n vn c kh nng th hin c s i snh tng i gia cc phng php dch my vi nhau N th hin c s so snh tng i, v d nh phng php ny tt hn phng php kia th ci BLEU ny n s tt hn phng php kia Tuy nhin, nu gi tr BLEU c th hin c bn dch l tht s tt hay khng th n cha th hin c nhng n c th gip chng ta so c phng php ny, n c tt hn phng php kia hay khng Nguyn nhn cho vic score thp l c t s lng N-gram trng vi bn dch ca chuyn gia Nu chng ta a ra mt bn dch m khng khp c, khng khp t no vi cc chuyn gia th n s c score thp. V y l mt v d, y l bn dch ca my v y l bn dch ca mt ngi th chng ta s thy l t D,  y n s khp After D, tc l N-gram, trong trng hp ny l N l bng 2 Ri Attack l 1, N-gram l trong trng hp ny N l bng 1 Ri, so vi li ci bn dch i vi ngi th 2 th chng ta thy l ci cm t International Airport NX th  y l mt ci bn dch N-gram y l khp N-gram vi N l bng 4 Ri, tng t nh vy cho 4 ci bn dch v t  th chng ta s tnh ra c ci score trung bnh, trung bnh iu ha cho 4 ci bn dch ny. V theo dng thi gian th nu nh trc nm 2015, tc l nm 2014 l s ra i ca Seq2Seq th n nm 2015 tr v sau l cc hng tip cn ca Neural Machine Translation, tc l s dng ANN, da trn ANN th n cho tc  tng trng, cho s gia tng v  chnh xc tng ln rt l nhiu v chng ta c th thy l  dc,  dc ca ng mu xanh m ny lm n i rt dc, tc l s tng trng v  chnh xc ca n Trong khi , cc hng tip cn da trn thng k Statistical da trn thng k v d nh  y c 2 hng da trn syntax v da trn phrase th chng ta thy cng c tng trng nhng m tng trng rt l thp  dc ca n rt l thp, tc l khng c s chnh lch g nhiu V cng t 2017 tr v sau, chng ta cng thy l khng cn nhiu nghin cu s dng Phrase-Based hoc l Syntax-Based Machine Translation theo hng tip cn thng k na. Chng ta ch cn cc hng tip cn s dng Neural Machine Translation m thi. iu ny cho thy l tm nh hng ca hng tip cn Neural Machine Translation v n  nh bt nhng phng php truyn thng trc y  to ra mt hng i mi, hiu qu hn v thm ch  c th ng dng c trong cng nghip ngay.'), Document(metadata={'filename': '2NThga7SQ-I', 'start_timestamp': '0:10:47', 'end_timestamp': '0:11:38', 'video_url': 'https://youtube.com/watch?v=2NThga7SQ-I', 'title': '[CS315 - Chng 2] Tutorial - CNN (Phn 1)', 'chunk_id': 11}, page_content='Bias s l bng activation. Ri, nh vy th chng ta  ci t cho ci i tng tn l Convolution2D v chng ta s phi truyn vo cho n l ci input. V tr ra n s ra l ci bin tn l C1, ging nh trong ci s   y. Ri, tip theo th chng ta s th chy. Ok, n s bo li. , 3x3, ok, n khng hiu 3x3 l g. 3,3.'), Document(metadata={'filename': 'RVj2LTBd7IU', 'end_timestamp': '0:13:53', 'chunk_id': 7, 'start_timestamp': '0:12:22', 'title': '[CS315 - Chng 3] Deep Generative Models (1) - Part 5 (Phn 3)', 'video_url': 'https://youtube.com/watch?v=RVj2LTBd7IU'}, page_content=\"V chng ta lun mong mun ci X mu xp x vi li X. Cn i vi GAN l mt ci mng to sinh i khng, th chng ta khng c ci cng on nn nh ny, m chng ta t mt ci vector random noise Z, chng ta s to ra mt ci nh x' (x phy). Nhng m ng nhin trong ci qu trnh hun luyn, khi G m n cng tt, th ci x' (x phy) ny n s c xu hng l cng ging vi l xReal, tc l x ging tht. Th th i vi mng GAN, mc d n khng c ci cng on nn, n khng c ci cng on l nn, nhng m n c mt ci module tng t nh vy,  l discriminator. L mt ci module  gip phn bit nh tht v nh gi. Th th tng l chng ta c th trnh ci vic khng dng mt ci mng generator, dng mt ci mng encoder, nhng cui cng th ci D ny, discriminator ny n s tng ng vi li mt ci mng encoder. Nh vy th chng ta  cng tm hiu qua hai ci kin trc rt l kinh in v vn c rt nhiu nhng ci ng dng hin nay,  chnh l VAE v GAN.\"), Document(metadata={'video_url': 'https://www.youtube.com/watch?v=0ozeUUS9DzQ', 'start_timestamp': '0:09:04', 'filename': '0ozeUUS9DzQ', 'title': '[CS116 - Bui 2] Part 4 (tt)', 'playlist': 'PLb62OySGqC9yGRvUaSe-iWFuXYuM8X6_n', 'end_timestamp': '0:13:39', 'chunk_id': 10}, page_content='Mathematical functions. Ri ngoi ra th trong NumPy s c h tr thao tc `transpose` (hay cn gi l chuyn v) l chuyn mt ci ma trn t dng nh th ny [[1, 2, 3], [4, 5, 6]] lt ngc n li thnh [[1, 4], [2, 5], [3, 6]]. V th y cng l mt trong nhng thao tc dng rt l ph bin trong i s tuyn tnh. Ri, v d array 1D [1,2,3] th transpose vn l [1,2,3]. Ri hm `reshape` tc l hm ny gip cho chng ta nh hnh li ci kch thc ca d liu ca mnh. V d  bn tri chng ta c ci data l 1 2 3 4 5 6, tc l mt ci vector. Chng ta mun bin n thnh mt ci ma trn kch thc l 2 x 3 th chng ta s dng hm l `data.reshape(2,3)`. N s to ra l [[1, 2, 3]], s dng [[4, 5, 6]]. Tng t nh vy cho `data.reshape(3,2)`. Th  y n s to ra mt ci ma trn kch thc l ba dng v hai ct l [[1,2]], xung dng [[3,4]], ri [[5,6]]. Ri th khi chng ta `reshape` th nu nh chng ta truyn vo mt ci gi tr  l -1 th hm   l th vin NumPy ca mnh s tnh xem ci s phn t ca mnh n s l bao nhiu.  v d  y `w` ban u ca mnh  l gm c cc ci l mt array (hoc vector) gm ba phn t, v d nh [1, 2, 3]. Th khi chng ta `reshape(-1)` vector v n khng cn phi ch ra ci s phn t ca mnh l bao nhiu. Chng ta ch cn truyn vo -1 th NumPy n s t bit l ,  y c ba phn t nn kt qu ca mnh n s l 3. Tng t nh vy cho hm `squeeze`. Ri nu nh chng ta mun chuyn ci hm ny v tr li ci ma trn ng khng, th chng ta s truyn vo mt ci `tuple` v chng ta cho n bit l  ci s ct ca mnh l 1, s ct ca mnh n s l 1, cn s hng ca mnh l bao nhiu th t NumPy n s tnh. T NumPy n s tnh l bao nhiu. Th  y `y` ca mnh n c ba phn t, nn nu ch c mt ct th s hng. V cui cng  chnh l c ch `broadcasting`. y l mt trong nhng c ch rt l hiu qu gip cho chng ta n gin ha ci cng thc ca mnh. Th  y chng ta s c cc ci v d nu nh ci array ca mnh, khi chng ta thc hin ci php cng hoc l php nhn hoc cc ci php tnh m kch thc ca cc ci phn t n khng ging nhau. V d bn tri l mt ci vector ba phn t. Nhng B bn phi n l mt gi tr `scalar` th t ng n s chuyn ci gi tr `scalar` ny thnh mt ci vector l `[1,1,1]`. V khi  chng ta s cng li.  y th chng ta s thy l array ca mnh bn tri s l mt ci array hai chiu, trong  th c hai hng Nu hai array c s chiu khc nhau. V d  y ha, array A c `shape` l (3,) (tc l mt chiu), khc s chiu so vi array B (c hai chiu). Th kch thc ca array vi s chiu t hn s c chn thm mt v pha u bn tay tri. Tc l `shape` (3,) ng khng? `Tuple`  y ch c mt phn t l 3 th n s chn thm s 1  trc s 3 ny, tc l n s chuyn v ci `shape` l (1,3). Nh vy s chiu ca array A lc ny'), Document(metadata={'end_timestamp': '0:16:23', 'start_timestamp': '0:03:40', 'title': '[CS114 - Chuong 8] SVM (Part 1)', 'chunk_id': 1, 'filename': 'OKUHDwcQuJo', 'playlist': 'PLb62OySGqC9wDaL2dnF_5J8f49e_YNi2f', 'video_url': 'https://www.youtube.com/watch?v=OKUHDwcQuJo'}, page_content='Th y l nhng ng dng ca thut ton SVM khi m chng ta  c c nhng c trng  tt. V  y chng ta s n vi nhng khi nim c bn trong thut ton SVM. u tin  chnh l ci khi nim siu phng. th y l mt ci khng gian con c nhiu, c s chiu nh hn 1 so vi li khng gian c trng cha d liu v d nh trong khng gian c trng ca mnh l c 2D l khng gian 2 chiu th siu phng ca mnh lc ny n s l mt ci ng thng ti v n ch c 1 chiu l mt ci ng thng v khng gian ca mnh nu l khng gian 3 chiu, th siu phng ca chng ta lc ny s l mt ci mt phng v tng qut ln trong khng gian m n chiu th siu phng ca mnh s c n tr 1 chiu Mc tiu ca SVM l tm ra mt siu phng ti u **sao** cho khong cch t siu phng n im gn nht ca hai lp d liu Bin ca mnh l ln nht, tc l khong cch t siu phng n im gn nht l ln nht **Chi tit** chng ta s c tm hiu trong nhng slide tip theo Khi nim tip theo trong SVM chnh l khi nim v l, l khong l hay l margin l ci khong cch gia siu phng phn tch cc im d liu gn nht thuc 2 lp Ly v d nh  y chng ta c mt ci siu phng ti u l ci ng  **gia** th ci khong cch gia ci im gn nht y l hai ci im gn nht i vi ci siu phng ny y l ci im gn nht i vi ci siu phng ny th khong cch t ci l bn tri sang ci l bn phi n chnh l ci margin v mc tiu ca SVM  l lm sao  c th tm c ci margin ny l ln nht Ti sao margin ln nht? Chng ta s cng tm hiu trong phn tip theo Nhng m ci l do, mt cch ngn gn  l khi margin ln th m hnh ca mnh n s c kh nng tng qut ha cao hay l **tnh generalization** V **tnh** tng qut ha cao ny s gip chng ta gim nguy c b hin tng  l qu khp d liu hay gi l overfitting Ri, chng ta s cng n vi ci khi nim na cng rt quan trng  chnh l Support Vector, tc l nhng **Vector h tr** th y l nhng im d liu y l nhng im d liu m n nm gn n nm gn ci siu phng phn tch v d nh  y l ci siu phng  phn tch th cc im m nm gn ci siu phng ny  chnh l nhng im ny th y l nhng ci im Support Vector hay l nhng **Vector h tr** ti sao c gi n l nhng **Vector h tr**? ti v nhng ci im ny n s c ci vai tr rt l quan trng trong vic l nh hng trc tip n ci m hnh ca mnh nu nh ci im ny m dch chuyn i ln hoc i xung th n s khin cho ci vic l cp nht li ci **Decision Boundary** tc l ci siu phng ny dch chuyn theo cn nhng ci im m khng phi l Support Vector v d nh nhng ci im  bn ngoi nh th ny th cho d n c dch chuyn ln xung, dch chuyn i u trong ci khng gian ny i chng na th n cng khng nh hng n ci siu phng ny cn nhng ci im m nm  st vi li ci **Boundary** ny  l 3 ci im ny th ch cn n dch chuyn vo trong hoc l n i ra ngoi th lp tc l ci ng bao ny cng s c cp nht theo do  ci vai tr ca nhng ci **Support Vector**, nhng ci im d liu h tr nhng ci **Vector h tr** rt l quan trng v  chnh l ci l do ti sao chng ta c ci tn  l **Support Vector Machine** tc l ci my m c to bi cc ci **support vector** Th th chng ta s cng minh ha c 3 ci khi nim m chng ta  ni  trn trong cng mt ci tm hnh th ci siu phng phn lp siu phng phn lp chnh l ci ng  gia  y v margin margin chnh l ci khong cch t ci bin tri sang ci bin phi trong  bin tri s l nhng ci bin gn nht m ci siu phng n chm vo ci im mu  Bn phi l siu phng gn nht **song song** vi siu phng **phn lp**  y v n chm vo nhng im mu xanh th khong cch t bin tri sang bin phi s gi l margin v cc im nm trn cc bin tri v bin phi ny l support vector th y l hnh nh  minh ha cho c 3 khi nim m chng ta  ni  trn th th i vi d liu, chng ta s xem xt mt tnh hung n gin trc  l d liu ca mnh, n c mt mi quan h tuyn tnh hay l Linear Data th y l d liu c th phn tch c bi 1 siu phng th chng ta nhn ci hnh ny chng ta thy mt cch trc quan th chng ta thy l c th phn chia c ra lm 2 phn bng 1 ng thng th phn lp SVM trong d liu **tuyn tnh** cho tp d liu gm 2 lp v d nh  y chng ta c 2 im d liu l mu xanh v mu  th thut ton phn lp SVM trong d liu **tuyn tnh** ny l n s i tm 1 siu phng  c th **tch** n ra lm 2 tc l chng ta s phi i ti u  lm sao tm ra c mt ci ng phn lp ra lm hai phn mt ci mt phng, mt ci siu phng  phn ci tp im ny ra lm hai phn th th  y chng ta s c mt s ci  tng trong ci vic l chn ci ng  c th phn tch ra lm hai th chng ta s c ci gii php A ci gii php A ny l mt ci gii php m chng ta c th d dng thy c rng l n c th **tch** tp im mu xanh v mu  ra lm 2 mt cch d dng v vi ci gii php ny th chng ta thy l n hon ton c th chia ra rt l tt, c th phn loi cc im mu  v mu xanh rt l tt tuy nhin, ci vic kt lun mt ci gii php l tt hay xu th s khc bit n s nm s khc bit ca n l n nm  ci mu **d liu** mi ch n khng phi nm trn nhng mu **d liu** c Ti v n s kim tra xem ci gii php ca chng ta n c tnh **tng qut** hay khng, n nh hay khng Th by gi chng ta s c mt ci mu d liu mi, y l ci im d liu mi Vy th ci im d liu mi ny vi ci gii php A th n s phn vo ci lp no Th vi gii php A n s xp ci d liu ny l mu  ti v n nm cng pha N nm v cng mt pha vi cc im mu **** trong ci tp d liu **Train** y chnh l cc tp d liu hun luyn v y l mu d liu mi By gi chng ta s cng xem xt n mt gii php tip theo,  l gii php B nh th ny V chng ta cng d dng thy l ci gii php B cng gip cho chng ta chia hai tp mu xanh v mu  ra lm 2 phn V cng vi ci mu d liu mi m chng ta   cp trong nhng slide trc l ci im ny trong quan im ca **gii php** B, d liu mi ny s c phn ra l mu xanh ti v n s nm v cng pha vi tp im mu xanh  bn ny Vy th gia 2 **gii php** A v B, chng ta t 2 **gii php** A v B nm chung vi nhau chng ta s thy 2 **gii php** ny **gii php** no l hiu qu hn  l 2 gii php A v B Gii php no hiu qu hn N s da trn vic phn loi im **d liu** mi ca mnh c hiu qu hay khng Bng mt cch trc quan v trc gic, chng ta thy l im mi ny nm gn pha sau nhng im mu  hn Nm gn pha sau nhng im mu  hn do  th mt cch trc quan v trc gic th ci im ny l ra n nn l im mu  l ra n nn l ci im mu  th n s ph hp hn ti v n nm v gn vi li cc im ny th r rng gia 2 ci gii php A v B chng ta thy gii php A n gip cho chng ta phn loi ci im ny thnh ci im mu  do  mt cch trc quan, mt cch trc gic th gii php A l mt ci gii php tt v b l gii php khng tt Vy th tiu ch no  gip chng ta chn la c ng phn tch tt hn so vi gii php cn li th  y chng ta s s dng khi nim Margin l ng bin Th th chng ta s cng xem xt li khi nim Margin trong gii php a ny i vi gii php A ny th margin ca chng ta s l t **bin** l tri sang **bin** l phi ging nh trn hnh y th ti sao ci ny l **bin**? ti v chng ta thy t gii php A tc l ng hyperplane A ny chng ta ni ra 2 bn v khi chng ta chm n 1 im d liu u tin th  chnh l **bin** v  y n chm n im mu  ny u tin i xng i hnh vi **ng ny** l bn phi v i xng bn tng ng l bn tri i xng qua li l margin ca gii php A l khong cch mu xanh ny chng ta s cng xem xt gii php B chng ta s i **song song**, **tnh tin song song** siu **phng** ny v 2 pha khi n chm n im **d liu** u tin  chnh l mt ci **bin** ca **gii php** B ly i xng qua, chng ta s tnh c khong cch mu xanh l ny r rng chng ta thy khong cch xanh l ny rt l b tc l ci **bin** ny rt l nh, rt l hp Vy th i chiu gia 2 gii php A v gii php B th chng ta thy gii php A cho bin ln hn gii php B Nh vy, hi ny chng ta  kt lun rng A tt hn B th tng ng bin ca n cng s ln hn **so** vi B Nh vy, mt cch **tng qut** l lm sao chng ta c th tm c mt ng phn tch  cho n c margin ln nht y l mt v d cho tnh hung ti u nht ca mnh Khi , ci **bin** ca mnh l cc i V cc im m chng ta va tip xc n hai l tri v l phi n chnh l cc support vector m chng ta   cp trong nhng slide trc th chng ta  2 gii php A v B khi chng ta ni ra khi n chm n im u tin th hnh nh n ch chm v 1 pha l hoc mu  hoc l mu xanh v d nh trong tnh hung ny n  chm n im mu  trc cn l tri n khng chm n im mu xanh Tc l n cha tht s ti u Cn ci ng phn tch ti u ca mnh  l khi chng ta ni ra hai bn Th n va chm c n ci im mu  th ng thi n cng s chm c n ci im mu xanh N chm n ci im ny Th n cng ng thi n s chm c n cc ci im ny y l mt ci mo  cho chng ta bit l ng **phn tch**  ti u hay cha'), Document(metadata={'filename': 'Vm18bFk-RsI', 'title': '[CS315 - Chng 0] Gii thiu mn hc (Phn 3)', 'chunk_id': 0, 'end_timestamp': '0:10:17', 'video_url': 'https://youtube.com/watch?v=Vm18bFk-RsI', 'start_timestamp': '0:00:14'}, page_content=\"Tip theo chng ta s cng n tp ton gii tch nu nh i s tuyn tnh l cng c  gip chng ta c th bin i d liu th gii tch l cung cp cho chng ta mt ci cng c  biu din cc ci chui, cc php bin i v ng thi  l mt ci cng c  gip chng ta gii quyt cc ci bi ton ti u v c bit trong ci mn ny ca chng ta,  l my hc nng cao chng ta s da trn cc ci m hnh da Gradient tc l dng vector o hm  m chng ta i cp nht tham s v hun luyn m hnh khi  l chng ta s c mt ci cng c na  chnh l o hm v o hm th ban u s gip chng ta kho st ci hm s ri sau  s gip chng ta tm c cc ci im cc tiu hoc l cc i th chi tit nhng ci kin thc no ca ton gii tch s c tm hiu trong nhng phn tip theo u tin chng ta s c ci khi nim hm hp hm th d ri,  l mt s nh x t x sang ci fx nhng m khi chng ta mun lm vi nhng ci hm phc tp hn trong  c nhiu php bin i ni tip nhau th chng ta s dng ci khi nim gi l hm hp v k hiu  l y s l bng g, chn f trong  f v g l hai ci hm thnh phn, cn y s l mt ci hm hp ca hai ci hm thnh phn  l f v g th khi  l chng ta k hiu nh th ny, hoc ghi dng lin tc th l nh th ny l y bng g ca fx tc l fx chng ta tnh xong, chng ta s lm ci u vo cho hm g v y l mt s ci v d v hm hp v d nh fx l bng x bnh phng cng mt, gx l bng sin x th khi  l hm hp s l ca g v f s l bng sin ca x bnh cng mt tng t nh vy, chng ta s c cc bi tp  chng ta n li kin thc v hm hp khi nim tip theo v cc k quan trng  chnh l o hm th o hm ca mnh trong gii tch l mt cng c  gip chng ta bit  l s bin thin ca hm s ti mt ci im no  l mt cng c  m t s bin thin ca hm ti mt ci im no  v d nh trong ci hm ny chng ta thy l hm y bng fx th ti v tr x0 chng ta thy l ci hm ca mnh, ci  dc ca mnh l n ang hng ln, tc l n ang ng bin th th y l mt cng c  gip chng ta bit trng thi ca hm ti v tr x0 l n ang i ln hay i xung, hoc l i ngang v d nh ti ci v tr ny, chng ta thy l n ang i ngang tm li  l mt cng c  m t s bin thin v n  ngha l h s gc hay l  dc ca ci hm ti ci v tr  v nh c o hm th gip chng ta kho st v tm ra c cc ci im cc tiu v d nh l im  y, hoc l cc ci im cc i th y l mt ci cng c rt l hu hiu  gip chng ta c th ti u ha mt ci hm s phc tp v chng ta s c ci khi nim  l hm n bin th  y l mt ci v d v hm n bin trong  l chng ta s c mt ci hm F nh th ny v khi chng ta kho st ci hm s ny th chng ta s thy l c mt ci im x  cho ci o hm ca mnh bng 0 v d nh trong trng hp ny l x bng 1 th o hm ca mnh s l bng 0 v n s l khi th v ci F phi th ti y l bng 0 v bn tri s l du m v bn phi l du dng th khi chng ta kho st ci hng di chuyn th n s i xung v i ln th t ci s kho st ny, n s gip chng ta xc nh c l hm ca mnh s t c ci gi tr cc tiu khi n i qua ci im x bng 1 ti v tr ny l o hm ca mnh bng 0 th y l mt ci v d  minh ha cho ci vic l dng o hm  kho st hm s v s gip chng ta xc nh c ci v tr c ci im ti u cc tiu hoc l ti u cc i th y l mt ci v d vi ci o hm F phi ca mnh l bng ca ci hm ny th F phi ca mnh s l bng x tr 1 v khi chng ta gii ra c th tng ng l x bng 1 x bng 1, tc l ci gi tr  y ri tip theo  l o hm ca hm hp va ri l o hm ca mt ci hm n bin cn i vi hm hp th chng ta s c ci s phi hp ca nhiu hm ni tip nhau v  gii c, gii quyt c ci vn  ny th chng ta s c cc ci o hm cng thc ca o hm hm hp nh sau i vi ci trng hp m Fx v x l mt ci bin s tc l hm bnh thng ca mnh th o hm ca mt ci hm bc mt n s l nh th ny, o hm cng l hm a thc ri o hm c hm cn, hm sin, cos, tan, v.v. cn bn phi  l ci o hm ca mt ci hm s m dng hm hp, v d nh k nhn vi u trong  u l mt ci hm hp ca x theo x, th khi  l n s l bng k nhn u phi ri sin ca u u ca hp o hm ca n s l bng cos u sau  nhn cho o hm ca u phi tnh theo bin x lu  u  y l mt ci hm ph thuc ca bin x th o hm ca ci hm ny theo bin x th n s l bng cos u nhn vi li u, u', o hm ca u phi x th y l ci bng tra v phc v cho chng ta rt l hiu qu trong ci vic l tnh o hm ca hm hp v ci cng thc ny th c th l c p dng  th nghim v chng ta c th lm bi tp  n tp vi cc ci hm sau th y c nhng ci hm t dng n gin nh l a thc cho n nhng ci hm phc tp hn th chng ta s da vo ci bng tra ny  m chng ta c th tnh c o hm ca cc ci hm hp phc tp ny ri, v sau  th chng ta s cng tm hiu v ci khi nim o hm ca hm ring tc l trong trng hp ci hm f ca mnh n khng phi ph thuc mt bin x, m n ph thuc vo c bin y bin z, v d vy, nhiu bin th khi  chng ta s c ci khi nim l o hm ca f theo bin x o hm ca f theo bin y v o hm ca f theo bin z tc l chng ta s tnh trn tng ci bin thnh phn  xem xt s ph thuc ca hm s theo cc ci bin s mt cch c lp tc l chng ta s xem cho x, f bin thin nh th no theo mt bin x f bin thin nh th no, theo mt bin y f bin thin nh th no, theo mt bin z v y l ci cng thc o hm ring bc 1 th nh c ci o hm ring bc 1 ny th chng ta c th tnh ton c cho cc ci nguyn hm tuy nhin trong ci phm vi ca mn ny l chng ta s khng s dng nhiu n cc ci tch phn hoc l nguyn hm  c chng l trong ci phn ca m hnh diffusion th chng ta phi nhc li ci khi nim tch phn mt cht xu nhng m  gc  l lp trnh th chng ta s khng cn dng n tch phn m chng ta dng nhiu n ci hm tnh tng trn nhng ci di gi tr ci min gi tr th  y chng ta s c mt ci v d hm fxi l mt ci hm nh th ny v chng ta s i tnh o hm ca fxi ny theo x th n s l bng 4x v o hm ca f theo y th n s l bng tr 3 cui cng  l chng ta s cng tm hiu n ci khi nim gradient ton b mn ny th u da trn gradient  chng ta xy dng m hnh n gi l m hnh da trn gradient tc l cc ci m hnh ny u s dng gradient nh l mt ci cng c  cho chng ta ti u ha v hun luyn m hnh vy th khi nim gradient l g? t mt ci khng gian vector n chiu v mt ci gi tr scalar l r l s thc th gradient l ci vector n phn t n l mt ci vector n phn t bao gm cc ci o hm ring ca n v d f ca mnh l mt ci hm theo mt ci tham s theta l mt ci theta trong  theta l thuc r th khi  gradient ca f theo theta n s l bng mt ci vector gm o hm ca f theo bin theta 1...\"), Document(metadata={'title': '[CS116 - Bui 8] Part 7_1', 'end_timestamp': '0:01:41', 'filename': 'sDmzaaAv3Pc', 'playlist': 'PLb62OySGqC9yGRvUaSe-iWFuXYuM8X6_n', 'chunk_id': 1, 'video_url': 'https://www.youtube.com/watch?v=sDmzaaAv3Pc', 'start_timestamp': '0:00:54'}, page_content='Tc l ci s phn t ca X.  y noise ny th n i din cho nhng ci phn  sai s trong qu trnh m chng ta o lng ci d liu ca mnh khi trong thc t. V y th s l c ci cng thc  y chng ta s cho trc mt ci hm phng trnh l y = -6x + 10 v chng ta s cng thm cho mt ci sai s noise theo ci nhiu  tun theo ci phn b  l phn b chun. V sau  th chng ta s tin hnh v cc ci cp im X v y ln trn ci  s  ca mnh bng th vin plt. Ri th chng ta thy  y l s c cc ci im l cc ci sai s ca mnh.'), Document(metadata={'video_url': 'https://www.youtube.com/watch?v=A6vU3I4CK6U', 'filename': 'A6vU3I4CK6U', 'chunk_id': 5, 'playlist': 'PLb62OySGqC9yGRvUaSe-iWFuXYuM8X6_n', 'start_timestamp': '0:06:35', 'title': '[CS116 - Bui 7] Part 1', 'end_timestamp': '0:08:21'}, page_content='u vo ca mnh n s l mt vector 1000 chiu, v d vy. Th khi  l ci ma trn X s rt l ln. V khi  th ci thao tc m tnh ton ny n s rt l tn chi ph, rt l tn chi ph. Do  th chng ta c th thc hin bng cch  l chng ta s dng thut ton gradient  cp nht. V ci cng thc cp nht ca mnh  l beta m bng beta m tr cho alpha nhn cho o hm hay k hiu bng nabla. Nabla chnh l o hm m cho vector ca ci hm L(beta m). V ng nhin  cp nht ny th ban u beta ca mnh n s l bng mt ci vector ngu nhin, mt ci vector ngu nhin. V chng ta s thc hin lp i lp li ci cp nht ny cho n khi no m nabla ca L(beta m) v ci gi tr ny th n b hn mt ci ngng epsilon th khi  thut ton ca chng ta s kt thc. V ton b ci qu trnh hun luyn m hnh my hc ny th u c ci t  trong ci th vin Scikit-learn vi ci module n c tn l Linear Regression. Th trong ci m hnh Linear Regression ny th chng ta  c cung cp cc ci phng thc v d nh l phng thc v phng thc `fit` l  hun luyn v phng thc `predict`  phc v cho qu trnh chng ta inference, thc hin cho ci qu trnh l test vi mt ci mu ring bit mi. , th  c ci t, ci module ny  c ci t trong Scikit-learn.'), Document(metadata={'title': '[CS431 - Chng 5] Part 1-2: ng dng trong bi ton phn loi v bi ton truy vn nh', 'video_url': 'https://www.youtube.com/watch?v=RVFApjx4KKI', 'chunk_id': 5, 'filename': 'RVFApjx4KKI', 'end_timestamp': '0:11:04', 'start_timestamp': '0:06:33', 'playlist': 'PLb62OySGqC9xl1_deMF_UXP5tA2Tvt17_'}, page_content='Th y l ci bi ton ng dng trong lnh vc v y t. V trong nh y t th mt s loi nh c tnh phc tp cao hn v c domain khng ging vi domain ca lnh vc m mnh hay hun luyn trn tp d liu MNIST. V d nh l chp trn nh CT scan hoc l chp trn nh MRI th tt c nhng ci ny u l nhng ci nh dng nh v n khng ph bin trong th gii thc dn n  l khi m chng ta hun luyn cc ci mng CNN trn cc ci domain ny th c khi chng ta s phi hun luyn li t u chng ta cng khng c th ti s dng c nhiu nhng ci c trng trong nh mu nh th gii thc ca mnh. V mt s ci k thut m ng dng ca ci mng CNN cho ci bi ton phn lp  nhng ci bi ton nh va  cp th n c rt nhiu nhng k thut khc nhau. V d, i vi ci bi ton nhn din khun mt th  y ngi ta s tp trung vo ci vic l ci tin hm loss. Nh chng ta  bit l trong mt m hnh my hc th n s c hm m hnh v chng ta s c hm loss Hm loss i vi hm m hnh th h vn s dng kin trc mng hoc l cc thnh phn nh l convolution, pooling, activation, ReLU Nhng m khi tnh ton cc  sai lch gia mu d liu ca mnh vi li nhng mu d liu ca gng mt ca mnh vi li nhng gng mt khc th chng ta s phi s dng ci hm loss c bit ti v gng mt l mt loi i tng c bit. N c nhng b phn rt ging nhau nhng m ng thi n cng khc nhau  cc yu t rt l nh. V gii php ca cc cng ngh tin tin nht hin nay cho bi ton nhn din khun mt u l n t cc ci tin cho hm loss V d nh chng ta c cc m hnh nh l ArcFace, SphereFace, v.v. Th n u s dng cc  o l Angular, Margin Loss V  tng ca hm loss ny l n s p  cho m hnh c gng hc c nhng c trng phn bit cao v nhng c trng phn bit cao  tch bit gia nhng gng mt tng t nhau V d nh chng ta thy trn hnh trn ny, mi mt ci chm i din cho c trng ca mt face, mt gng mt Mnh s vit bng ting Anh  cho n r Mi ci ny l mt gng mt v nhng gng mt no gn ging nhau Thc t chng ta thy l c nhng gng mt 2 ngi khc nhau nhng m c ci nt gng mt n n n ging nhau th nhng ci face  n s t nm  gn nhau trn ci cung hnh trn ny v nhim v ca cc ci hm loss ny l c gng tch cc ci face tng t nhau tch ra xa ci face tng t nhau tch ra xa v d chng ta thy l  y trn ci cung gc ny, ng khng? th n s maximize, tc l cc i ha ci gc ny  tch cc ci im  trn ci hnh trn ny i vi nhng gng mt khc nhau th n s tch cng xa nhau ra V  chnh l  tng ca vic ci tin hm loss Mt khc trong mt s lnh vc, v d trong lnh vc y hc Th kt qu ca mnh khi chng ta phn loi m ra c  chnh xc l 99% Th i khi cc bc s h s khng s dng kt qu ca mnh k c khi mnh chng minh vi h l phng php, m hnh ca mnh c th nhn din c chnh xc cc bnh n 99% m h ch c th s dng h thng ca mnh khi mnh ch ra c nhng khu vc c kh nng l xc nh c  l bnh. Tc l bn cnh vic a ra kt qu u cui l c bnh hay khng bnh, th  y mnh phi thuyt phc ngi s dng rng ti a ra nhn din c ngi ny b bnh khi n c nhng du hiu r rng v nhng du hiu  th n th hin  nhng khu vc nht nh.'), Document(metadata={'start_timestamp': '0:01:08', 'title': '[CS315 - Chng 3] Deep Generative Models (2) - Part 8', 'chunk_id': 1, 'end_timestamp': '0:12:20', 'video_url': 'https://youtube.com/watch?v=nZc5vWo2Rrg', 'filename': 'nZc5vWo2Rrg'}, page_content='V ngc li khi chng ta denoise cng nh th. Nh vy th thi gian chy ca diffusion s l bng t nhn cho thi gian chy ca GAN v VAE. Vy th chng ta s nhc li cng thc to sinh ca m hnh ca mnh. Trong m hnh to sinh ca mnh th cng thc s dng theo cch thc s 2 ca chng ta  l on xem ci nhiu ti mt thi im t so vi li ci nhiu ng l bao nhiu th chng ta s c mi ca qi xt phi x0 l bng cng thc ny v mi ca theta xt t th n s l bng cng thc ny trong cng thc ny th chng ta thy n c tnh cht gi l Markov tc l phi tnh xt c trc ri mi tnh xt tuy nhin c mt bi bo khc  l DDIM tc l denoising diffusion implicit model th  b i ci yu t gi l chui Markov tc l chng ta s khng c yu cu qu xt, xt tr 1 phi l mt chui Markov, tc l phi tnh c xt tr 1 xong ri chng ta mi tnh c ci xt ny th  y chng ta s dng ci s  ny  d hnh dung  l t xt chng ta c th tnh trc tip ln x1 xin li t x0 chng ta c th tnh trc tip ln x1 t x0 chng ta c th tnh trc tip n x2 m khng cn thng qua khng cn thng qua ci bc tnh x1 ny th cng thc ca mnh s l qi ca xt khi chng ta bit trc xt tr 1 x0 th lc ny chng ta s tnh trc tip t x0 m khng cn qua xt tr 1 vy th  trn cng thc ny chng ta thy bn cht ca cc cng thc n ch l mt s tnh ton vi cc h s a, b v b a v b hm mi ca qu xt, xt0, xt0 l bng a, b, axt, b t tng nh vy mi theta ca xt, t l bng axt, b, theta xt Th th chng ta ch cn tm a v b sao cho min l ci xt n tha mn xt l bng cn ca alpha t x0 cng cho 1 tr cn alpha 1 tr... cng cho cn ca 1 tr alpha epsilon th nh vy l  ng c Th ci m hnh DDIM  tng ca n  l thay v chng ta i tng bc ph thuc bc th t chng ta tnh xong th chng ta mi n c bc th T cng 1 th n s dng mt ci cng thc trc tip t x0 cho n ci v tr th T lun v ngc li cng vy th th n s nhy cc, ni mt cch nm na  l n s tnh ton nhy cc ci bc m encoding v decoding v nh vy th ci tc  ca DDIM c th nhanh hn gp 10 hoc thm ch l gp 100 ln so vi li DDPM DDPM y l m hnh probabilistic tc l m hnh c xc sut Cn  y l implicit Tc l mt m hnh m n c th tnh mt cch n nh khng c kiu yu t nhiu trong  khng c yu t nhiu Th th xt v tc  th DDPM n hn Cn xt v  chnh xc th n gn nh tng ng v thm ch l tt hn  mt s tnh hung v d vi s Step 10, FID l 10, DDPM l 13, DDPM l 300 khi thc hin vi 1000 step, DDPM cho  chnh xc cho FID l tt nht DDPM cng gn nh tng ng, 4.0 nhng t 100 tr v trc,  y l 4,0, cn  y l gn 10,4,0, rt tt hn 10 nhiu Vi DDIM, s step ca mnh m nh hn 100,  chnh xc FID ca mnh tt hn hn so vi DDPM. Tng t nh vy cho b CelebA-64, kt qu cng hon ton tng t nh vy. DDIM c th ni l mt trong nhng ci tin t ph trong vic  l ci tin v tc  ca mt m hnh diffusion chuyn t dng probabilistic sang dng deterministic  m mnh c th ly mu nhanh. V mt k thut khc  l progressive distillation khi ni n m hnh hc my th chng ta s c k thut tc l hun luyn mt m hnh teacher c mt s tham s rt l ln v m hnh student c s lng tham s t hn trong trng hp ny th chng ta s hun luyn m hnh teacher v student phi hp vi nhau  sao cho chng ta, thay v chng ta phi i tng bc nh th ny th chng ta c th i nhng ci ng tt m vn c th n c ch progressive distillation  y chng ta s hun luyn teacher trc v sau  chng ta s distill vo knowledge ca student theo ng mu vng ny th student ca mnh l i theo cc ng tt, tc l n b qua cc bc trung gian  y sau , nu l progressive c ngha l g? n ly chnh ci ng tt ny, tc l ci m hnh m i denoise theo ci kiu ng tt ny  lm teacher  lm teacher, l ci ng mu vng ny l teacher th chng ta s i mt ci ng tt hn na,  l student chng ta s b qua ci node ny b qua ci node ca teacher c  to ra mt student mi c bc nhy cc nhanh hn th y chnh l Progressive Length Distillation chng ta tng bc gim s bc ca mnh xung  tng tc  denoise M hnh Guided Distillation  tng cng l dng Distillation nhng m kt hp vi Latent Diffusion y l mt m hnh cho chng ta va t c tc  hun luyn v tc  inference ca mnh. y l m hnh c Condition l Y, cho php chng ta iu hng m hnh ca mnh. V vy,  y l mt m hnh Guided Distillation l giao thoa hoc l kt hp ca Progressive tc l chng ta s i cc ng i tt thay v chng ta i tng bc, tng bc, tng bc th chng ta s i tt hoc thm ch l tt hn, tc l chng ta c th i trc tip t y sang y thng qua ci vic l chng ct tun t sau  chng ta kt hp vi m hnh Latent Diffusion, tc l chng ta ch lm bc encode v decode  trn khng gian latent thi, tc l chng ta khng lm trong khng gian nh m lm trn khng gian latent v kt qu ca Guided Distillation th chng ta thy l rt l p v Cc bc t 2 bc, 4 bc v 8 bc th kt qu gn nh tng ng nhau, khng c s phn bit g nhiu Vi ch 2 bc m kt qu ca chng ta rt l tt So vi ng nhin l 8 bc nhiu bc hn th n s p hn, chi tit hn nhng m 2 bc th kt qu cng rt l tt v khi chng ta denoise m ch c hai bc th r rng tc  mnh nhanh hn rt l nhiu so vi li denoise c t bc th y l ci kt qu vo nm 2023 v chng ta s c ci m hnh consistency model tc l chng ta s kt hp cc ci loss li vi nhau l bng min ca EMA ca XT v T Ri F ca theta x t phi th y l mt ci target network hay cn gi l m hnh ca teacher Cn online network s l m hnh student Tm li l i vi nhng ci gii php m gim ci tc  th chng ta s dng ci m hnh  l teacher v student Kt hp hai ci network ny li  chng ta c th to ra ci m hnh m tt hn, i tt hn v multi-step hn v d nh  y chng ta thy l ci ng ny n l i 1 pht 1 n ch th n  tit gim cho chng ta rt l nhiu cc bc denoise nh vy th chng ta c th l single step generation l mt bc nhy t xt ln v x0 V kt qu ca Latent Consistency Model th cng hon ton tng t nh cc m hnh trc Vi 4 Step Inference, 4 Step Denoise th kt qu ca mnh vn cho cht lng rt tt Ngoi ra th chng ta s c cc k thut lin quan n vn  v Fine-tune li m hnh Fine-tune m hnh diffusion Khi ni v m hnh diffusion th tham s thng rt ln L do  l n phi encode c vn bn Cng vi li encode c thng tin v mt hnh nh Do  s lng tham s ca mnh ca cc m hnh diffusion thng rt l ln c nhng m hnh ln n gn 1 t tham s c nhng m hnh hin i hn th c th ln n 3 t, 4 t tham s  to c nhng k nh cht lng tt v hiu c vn bn, hiu c yu cu u vo ca mnh th s tham s l ln v chng ta mun fine-tune m hnh diffusion ny vi data set ca mnh Th khi  n rt d b hin tng overfitting. Ti v trong cc ci bi trc chng ta  ni ri, hin tng overfitting xy ra khi s lng tham s ln v khi d liu ca mnh t.'), Document(metadata={'title': '[CS114 - Chng 3] M hnh hi quy n bin (Phn 2)', 'playlist': 'PLb62OySGqC9wDaL2dnF_5J8f49e_YNi2f', 'video_url': 'https://www.youtube.com/watch?v=xptu0eq_CXQ', 'start_timestamp': '0:13:29', 'end_timestamp': '0:15:05', 'filename': 'xptu0eq_CXQ', 'chunk_id': 11}, page_content='V mi ln x l xong mt batch, m hnh s cp nht cc tham s mt ln. V d nh chng ta t backside bng 32, ngha l sau khi nhn thy v x l 32 mu d liu, m hnh s thc hin mt ln cp nht tham s. Vic la chn backside ph hp khng ch gip tit kim ti nguyn phn cng m cn nh hng n tc  v hiu qu ca qu trnh hun luyn m hnh. Khi lm vic vi cc tp d liu ln, vic s dng ton b d liu cho mi ln cp nht tham s l iu khng kh thi. Nhiu b d liu hin i c th cha n hng triu mu nu chng ta c gng ti ton b d liu ny v b nh RAM hoc VRAM ca GPU  tnh ton gradient, my tnh s khng  ti nguyn  x l. Chnh v vy m back size ra i  gii quyt vn  v gii hn b nh. Vic chia nh d liu thnh cc BCH nh gip qu trnh hun luyn tr nn kh thi hn ngay c trn nhng my tnh c phn cng hn ch. Ngoi vic gii quyt vn  b nh backsite cn mang li hai li ch quan trng khc. Th nht l hiu qu tnh ton. Khi cp nht tham s sau mi BCH nh, m hnh c sa li lin tc, t  hc nhanh hn. Chng ta khng cn phi i x l ht ton b d liu mi cp nht m c th ci thin m hnh sau tng BCH. Th hai l kh nng tng qut ha. Vic c lng gradient trn mt bch nh s to ra mt cht nhiu gip m hnh khng b kt  cc im cc tiu cc b v c kh nng tm ra nghip tt hn. iu ny gip m hnh hot ng hiu qu hn trn d liu mi cha tng thy trong qu trnh hun luyn.'), Document(metadata={'end_timestamp': '0:11:14', 'chunk_id': 8, 'start_timestamp': '0:09:06', 'title': '[CS114 - Chng 3] M hnh hi quy n bin (Phn 2)', 'filename': 'xptu0eq_CXQ', 'playlist': 'PLb62OySGqC9wDaL2dnF_5J8f49e_YNi2f', 'video_url': 'https://www.youtube.com/watch?v=xptu0eq_CXQ'}, page_content='Learning ray. Learning ray k hiu alpha l mt trong nhng siu tham s quan trng nht. Trong qu trnh hun luyn bng gradient des learning ray cn cn gi l tc  hc v k hiu l alpha. Learning ray quyt nh kch thc bc nhy khi m hnh cp nht cc tham s trong mi vng lp. Ni cch khc, n kim sot mc  thay i ca W v B sau mi ln tnh ton gradient. Nu chn ln rray qu ln, m hnh c th nhy qua im ti u khin hm chi ph dao ng mnh, thm ch l khng hi tc. Ngc li, nu ln ray qu nh, m hnh s cp nht rt chm, qu trnh hun luyn s tn nhiu thi gian v c th kt  cc im cha ti u. V vy, vic la chn learning ray ph hp l cc k quan trng  m bo m hnh hc hiu qu v n nh.  slide ny th chng ta c th quan st trc quan nh hng ca learning ray n qu trnh hun luyn. Hnh pha bn trn th hin trng hp learning ray qu nh, cc bc nhy ngn, m hnh tin chm v im ti u, mt nhiu thi gian  hi t. Ngc li  hnh bn di minh ha cho trng hp learning ray qu ln, cc bc nhy rt di khin hm chi ph dao ng mnh v m hnh khng th hi t v im ti u. Qua hai trng hp ny, chng ta cng thy r tm quan trng ca vic la chn learning ray hp l  qu trnh ti u ha din ra nhanh chng m vn m bo  chnh xc ca m hnh. Vy lm th no  la chn mt gi tr learning ray ph hp? Thng thng th chng ta s th nghim nhiu gi tr khc nhau  quan st tc  hi t ca m hnh. Mt phng php c ph bin l th cc gi tr theo thang logris. V d nh 0.1, 0.01, 0.001 hay l 0.001. Sau  th chng ta s theo di s thay i ca hm chi ph qua cc vng lp. Nu ln ray qu ln, hm chi ph s dao ng hoc thm ch tng ln.'), Document(metadata={'chunk_id': 3, 'video_url': 'https://www.youtube.com/watch?v=73-FbhDr_Po', 'filename': '73-FbhDr_Po', 'start_timestamp': '0:04:11', 'playlist': 'PLb62OySGqC9yGRvUaSe-iWFuXYuM8X6_n', 'end_timestamp': '0:04:41', 'title': '[CS116 - Bui 7] Part 2'}, page_content='y chnh l phng sai ca cc ci m hnh ca mnh khi d on trn nhng ci b d liu khc nhau v trung bnh ca n th n s l ci sai s trn ton b ci d liu thc ca mnh. Th nu variance thp n th hin ci g? Ci variance thp tc l ci sai s ny l thp. Tc l m hnh ca mnh n c ci tnh tng qut cao.'), Document(metadata={'end_timestamp': '0:07:21', 'title': '[CS116 - Bui 14] Part 2_3', 'playlist': 'PLb62OySGqC9yGRvUaSe-iWFuXYuM8X6_n', 'start_timestamp': '0:00:00', 'chunk_id': 0, 'video_url': 'https://www.youtube.com/watch?v=aevGbPj9y6k', 'filename': 'aevGbPj9y6k'}, page_content='v cui cng  chnh l Edge prediction nu nh trc y m hnh tnh ton sn ri m hnh t  trong ci server v m hnh t ring  mt ci con server khc ng khng th by gi m hnh ca mnh s c t trn chnh ci my ca ngi dng cui t trn chnh ci my ca client  th ci Edge ny  N c th c hiu  l ci thit b bin ci tn ting Vit ca mnh  chnh l thit b bin hoc l ci thit b ca ngi dng th lm sao chng ta c th a ci m hnh ca mnh chy c trn cc ci thit b ny th  y chng ta s gi ci trng s ca m hnh chng ta s gi ci trng s ca mnh v ng nhin y l trng s ny l  c hun luyn ci trng s ny l  c hun luyn v chng ta s copy ci m hnh ci trng s ny ln trn cc ci thit b Edge device ri sau  chng ta load ci m hnh ny ln v thc thi ci vic d on trc tip  trn ci my trm client ny th y chnh l ci Edge v vi ci cch lm ny th gn nh khng c  tr tc l chng ta s khi chng ta c ci nhu cu cn phi d on ng khng cn phi gi ci m hnh  d on th n s lp tc n s phn hi ngay lu  l  ci khi nim  tr  y n khng phi l ci tc  ca m hnh n khng phi l ci tc  ca m hnh m ci  tr  y l ci thi gian k t khi chng ta c ci yu cu m hnh thc thi v sau khi m hnh thc thi xong th chng ta s tr ci kt qu v th ci  tr  y l ci thi gian khng lin quan n ci qu trnh m m hnh n d on n ch lin quan n ci thi gian trung chuyn d liu t lc m ngi dng c yu cu a n cho m hnh  m hnh bit l chng ta ang c nhu cu  cn phi thc thi d on ri sau khi c kt qu xong chng ta tr ci kt qu  v cho ngi dng th  l ci khong thi gian  tr n khng lin quan n ci thi gian m m hnh ca mnh n chy bn di ci thut ton hn v vi ci cch lm ny th  tr n rt l thp Edge prediction  tr thp gn nh l tc th v n cng c xut pht t ci nguyn nhn  l chng ta khng cn c ci mng internet ti v khi m hnh ca mnh c t trn chnh ci thit b bin th n s thc thi ngay trn chnh m hnh  n khng cn phi trung chuyn qua internet  nh mt ci bn th ba tnh ton th khng cn phi c Internet v nh vy th n  tit gim c mt ci yu cu mt trong nhng ci yu cu rt l quan trng  l ci tnh kt ni ca ci my trm vi li ci mi trng internet khng phi lc no my trm ca mnh cng c kh nng kt ni c vi Internet v mt ci u im na ca ci phng php Edge prediction ny chnh l bo mt d liu ti v ci my client ca mnh n s khng c chuyn qua ci internet ng  a v mt ci con server th nu nh chng ta a ci d liu a ci d liu qua mng internet th  y n c th b ng khng l b tn cng  ci d liu m chng ta a ln mng internet N s b trong ci qu trnh trung chuyn n s b bn th ba c th khai thc c th l ly cp ci d liu  chng ta khng ang ni v ci li ti server nha Tc l trong ci qu trnh Ci ng truyn n c ci server ny th s c mt ci bn th ba c th ly cp c  th chng ta ang thc hin ci d liu ca mnh gi l trc tip trn chnh ci thit b bin th khng th chng ta b mt ci d liu  c  th d liu n khng a ra khi ci my trm nn chng ta ci kh nng m chng ta mt d liu n s thp hn nhiu v ci khuyt im ca ci phng php ny  chnh l ci ti nguyn tnh ton ca my trm th thng l n s yu hn so vi cc ci con server ng khng Ti v cc ci my trm n c sinh ra l  phc v a chc nng ly v d nh ci in thoi ca mnh ng khng hoc l ci Laptop ca mnh th n c sinh ra l phc v cho a chc nng ch khng phi l thc gi l ti u cho cc ci m hnh my hc n thc hin ci vic l lu tr tnh ton hin th hnh nh tnh ton nhng ci php ton c bn x l nhng ci lu tr ri hin th c bn ch n khng c thc hin cc ci tnh ton s hc trn cc ci m hnh my hc do  th ci vic ti u ca n cho ci m hnh my hc l n khng hiu qu  th yu t u tin  l ci ti nguyn my trm n s c hn  y hiu   l n s khng c ph hp vi cc ci m hnh my hc v cc ci th vin v framework ca my trm th thng khng c  ci tnh nng ti v cc ci my trm ca mnh thng l nhng ci my m phc v a nng nn n s khng c ci sn trc nhng ci phn mm hoc l ci trc nhng ci th vin  cho ci m hnh my hc ca mnh c th thc thi c ri n s kh c th cp nht c m hnh by gi Nu khng c mng internet th lm sao chng ta c th a lm sao chng ta c th a ci m hnh ca mnh v trn ci my trm ny ng khng Th n kh cp nht ri n s kh theo di v debug V d nh khi ngi dng ngi ta s dng v ngi ta bo l  ti ang dng ci tnh nng ny nhng m n b li V by gi chng ta cng khng bit l lm sao  kim sot c ti v chng ta khng c php can thip vo bn trong ci log ca cc ci my tnh my trm V d nu chng ta ang thc hin  trn server ca mnh ng khng Th chng ta hon ton c th can thip v ci log ca ci server ca mnh  m mnh xem coi nguyn nhn  u li ca n l ci g th t  l mnh s bit c ci cch  m debug ci cch  m khc phc  cn  y l khi thc hin trn my trm Chng ta khng c quyn  truy xut v cc ci file trong my ca ngi dng hoc l can thip vo bn trong cc ci ch s hoc l can thip vo bn trong cc ci thng tin lu tr ca ngi dng nn chng ta rt kh trong ci vic theo di v chn on li th  chnh l nhng ci u v khuyt im cho ci phng php tip cn  l Edge prediction hay l d on trn my trm'), Document(metadata={'playlist': 'PLb62OySGqC9xl1_deMF_UXP5tA2Tvt17_', 'filename': 'T2xJmTiRM5o', 'video_url': 'https://www.youtube.com/watch?v=T2xJmTiRM5o', 'title': '[CS431 - Chng 2] Part 3a: M hnh hi quy lun l (Logistic Regression)', 'start_timestamp': '0:01:52', 'chunk_id': 1, 'end_timestamp': '0:03:20'}, page_content='Cn nhng im no nm v pha bn trn, v d nh  y, Th v th s ra gi tr ln hn 0. Cn nhng im nm di nh vy th s l nh hn 0. Nh vy da trn quan st, kin thc ton cp 2, cp 3 m chng ta  hc c th chng ta s thit k hm d on bng dng nh trn.  l f(theta, x1, x2), x l d kin u vo, hai c trng u vo. N s bng 1, tc l ci nhn y ny l bng 1. Nu theta0 cng theta1 x1 cng theta2 x2 ln hn hoc bng 0, tc l n thuc v mt na ci mt phng ny, th n s c gn gi tr l 1. v n s bng 0, ci nhn d on ca mnh s bng 0 nu nh theta 0 cng cho theta 1 x 1 cng theta 2 x 2 n b hn 0, tc l n nm v mt na pha bn ny th nu nh chng ta thit k ci hm d on nh th ny th iu g s xy ra? iu g s xy ra?'), Document(metadata={'title': '[CS431 - Chng 2] Part 4_3: Kin trc Transformer: B Encoder', 'start_timestamp': '0:03:13', 'end_timestamp': '0:04:57', 'video_url': 'https://www.youtube.com/watch?v=7AZr_li6ZtA', 'playlist': 'PLb62OySGqC9xl1_deMF_UXP5tA2Tvt17_', 'filename': '7AZr_li6ZtA', 'chunk_id': 1}, page_content='Tc l PE ca mnh n phi l mt ci hm tng l khng cn thit. u im th 2 l n c th biu din c chui rt di th thay i qua 10.000 th y ca mnh thay i th gi tr ny s tng theo v thm ch cho n khi y chm c n 10.000 v vt qua khong 10.000 th cc gi tr ny ca mnh, vector PE ca mnh cng s khng lp li n khng c trng nhau Ti v  trng th n s phi c thm mt ci i lng l pi na N phi c thm mt ci i lng l pi Cn  y l khng c pi vo nn ci kh nng n trng rt l thp Ri V ng nhin n cng s c mt s khuyt im nh chng ta thy  y V ci vector positional embedding ny l mt ci vector c nh Vi mt ci y c nh th chng ta s c mt ci PE c nh V ci ny n l mt ci hm do chng ta thit k, t hp ca cc hm tun hon N khng phi hc t d liu, n khng hc c t d liu Th y chnh l ci im yu ca ci cch biu din v tr di dng cc hm sin V  y th chng ta s xut hin thm mt ci khi nim na,  l multi-head self-attention. Trc y th l self-attention, cn by gi chng ta s lm multi-head self-attention.'), Document(metadata={'chunk_id': 0, 'video_url': 'https://www.youtube.com/watch?v=_nPettH0cXg', 'title': '[CS114 - Chng 3] Minh ha Feature Engineering (Phn 1)', 'start_timestamp': '0:00:13', 'end_timestamp': '0:01:17', 'playlist': 'PLb62OySGqC9wDaL2dnF_5J8f49e_YNi2f', 'filename': '_nPettH0cXg'}, page_content='Tip theo th chng ta s cng minh ha cho ci  tng ca feature engineering. Th u tin chng ta cng s import th vin NP. V bc u tin  l chng ta s khi to cc ci d liu. Th th gi s nh ci m hnh ca mnh n c to bi cc ci im  c ci mi quan h l mt ci dng ng cong v gi s nh  y chng ta xt l ng cong bc hai th x th chng ta cng s ly l np.range Range t 0  cc hiu t 1 cho n 3 i v bc nhy l 0.2 2 v y th s l bng x cng cho x bnh phng cng cho x bnh cng cho x - 3. V d vy.'), Document(metadata={'video_url': 'https://www.youtube.com/watch?v=m_jt8-LpwLs', 'start_timestamp': '0:03:30', 'playlist': 'PLb62OySGqC9wDaL2dnF_5J8f49e_YNi2f', 'end_timestamp': '0:04:48', 'chunk_id': 3, 'title': '[CS114 - Chng 4] Cu hi tho lun 1', 'filename': 'm_jt8-LpwLs'}, page_content='V ci cch gii thch th hai  l chng ta c th s dng l thuyt v mt thng tin. ri. Th th l thuyt v thng tin  th vai tr ca bias  y l g? R rng trong cc ci m hnh d on, cc ci gi tr u ra th chng ta phi gi nh nhng ci tham s, nhng ci bin s u vo. C th trong trng hp ny  chnh l ci  c trng x u vo. Nhng iu g xy ra nu nh  ci y ng ca mnh tc l ci gi tr d on ca mnh  y n khng c ph thuc vo x m n c th ph thuc vo nhiu yu t khc. Ly v d trong bi ton d on gi nh, chng ta thy l mt ci cn nh th n khng ch n ph thuc vo ci thng tin v mt din tch m n cn c th ph thuc vo ci cc ci thng tin khc m chng ta khng bit c. V d nh l gii trc nh ng khng?'), Document(metadata={'video_url': 'https://youtube.com/watch?v=DSmR6JSwx5I', 'chunk_id': 0, 'start_timestamp': '0:00:14', 'end_timestamp': '0:01:05', 'title': '[CS315 - Chng 2] Vanishing Gradient (Phn 2)', 'filename': 'DSmR6JSwx5I'}, page_content='By gi chng ta s n vi mt ci v d c th  chng ta c th d dng hnh dung hn. Th  y chng ta set mt ci mng Neural Network gm c th  l 10 lp bin i. V cc ci hm kch hot ca mnh  y chng ta s s dng cng mt hm kch hot  l hm sigmoid. Th cng thc ca ci hm sigmoid  l bng mt phn mt cng e m tr x. Th y l ci cng thc ca sigmoid. V khi chng ta hun luyn ci mng Neural Network ny th chng ta s i tnh ci hm loss. y l hm li. V chng ta s dng ci binary cross entropy ti v  y chng ta dng hm kch hot l sigmoid. Nn ci gi tr u ra ca mnh l con s t 0 cho n 1.'), Document(metadata={'end_timestamp': '0:09:29', 'start_timestamp': '0:06:52', 'chunk_id': 5, 'title': '[CS315 - Chng 2] S tin ha ca cc m hnh chui (Phn 1)', 'video_url': 'https://youtube.com/watch?v=-7JWQptLoMQ', 'filename': '-7JWQptLoMQ'}, page_content='Chng ta s i tnh ci gi tr d on.  l y ng t. Y ng t c tnh trc tip t ST. Th cng thc ca mnh cng rt n gin.  l softmax ca V nhn ST. Bn cht ca V ny  l nh x hoc l chuyn t ci khng gian ca ci lp hidden ny v ci khng gian ca ci output. Th  y chng ta s c 3 ci tham s  l U, W v V. Th 3 ci tham s ny chng ta   l n xut hin trn tt c cc ci gi tr thi gian. Tc l 3 ci gi tr U, V, W ny l chia s trng s. V, W l share parameter. Vy l cho d ci vn bn ca chng ta c di nh th no i chng na th n vn dng cng mt ci b tham s U, V, W. Th ci ANN  l mt ci m hnh m n c a tc v cho lnh vc v NLP. Ti sao gi l a tc v? Ti v vi mt ci kin trc ca ANN chng ta c th gii quyt rt nhiu nhng ci bi ton khc nhau trong lnh vc x l ngn ng t nhin. V d, 1 to 1, tc l t mt ci t u vo chng ta s to ra mt ci t u ra. V y c th dng trong ci lnh vc v d nh l dch t, ri 1 to many. V d nh chng ta c cho trc mt ci t ny l ci ch . Ci ch  ca mt ci bi th chng hn v output ca chng ta s l bi th. Many to 1 th mt ci ng dng kh l ph bin v kinh in.  chnh l sentiment analysis, tc l phn loi cm xc vn bn.')]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start= time.time()\n",
    "response = vector_retriever.get_relevant_documents(\"naive bayes l g?\")\n",
    "end = time.time()\n",
    "print(f\"Time taken: {end - start} seconds\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4c7c8a",
   "metadata": {},
   "source": [
    "## Reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e227cd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): XLMRobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from typing import List\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "rerank_model_name = \"BAAI/bge-reranker-base\"\n",
    "tok = AutoTokenizer.from_pretrained(rerank_model_name)\n",
    "reranker = AutoModelForSequenceClassification.from_pretrained(rerank_model_name)\n",
    "# reranker.to(device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "reranker.to(device=\"cpu\")\n",
    "reranker.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03d3db9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "# def batch_crossencoder_scores(q: str, texts: List[str], batch_size: int = 64, max_len: int = 512) -> List[float]:\n",
    "#     scores = []\n",
    "#     for i in range(0, len(texts), batch_size):\n",
    "#         batch = texts[i : i + batch_size]\n",
    "#         inputs = tok([q]*len(batch), batch, padding=True, truncation=True, max_length=max_len, return_tensors=\"pt\")\n",
    "#         inputs = {k: v.to(device=\"cuda\" if torch.cuda.is_available() else \"cpu\") for k, v in inputs.items()} # chuyn ln gpu\n",
    "#         logits = reranker(**inputs).logits.squeeze(-1)\n",
    "#         scores.extend(logits.tolist())\n",
    "#     return scores\n",
    "\n",
    "@torch.no_grad()\n",
    "def batch_crossencoder_scores(q: str, texts: List[str], batch_size: int = 64, max_len: int = 512) -> List[float]:\n",
    "    scores = []\n",
    "    # FIX: Thit lp device cng l CPU, KHNG dng logic kim tra CUDA c\n",
    "    device = \"cpu\" \n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i : i + batch_size]\n",
    "        inputs = tok([q]*len(batch), batch, padding=True, truncation=True, max_length=max_len, return_tensors=\"pt\")\n",
    "        \n",
    "        # FIX: Buc input tensors chuyn sang CPU\n",
    "        inputs = {k: v.to(device=device) for k, v in inputs.items()} \n",
    "        \n",
    "        logits = reranker(**inputs).logits.squeeze(-1)\n",
    "        scores.extend(logits.tolist())\n",
    "    return scores\n",
    "\n",
    "def crossencoder_rerank(docs, query: str, top_k: int = 10):\n",
    "    texts = [d.page_content for d in docs]\n",
    "    scores = batch_crossencoder_scores(query, texts, batch_size=16, max_len=512)\n",
    "    ranked = sorted(zip(docs, scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    BAD_HINTS = (\"Cm n cc bn  xem\", \"ng k knh\", \"subscribe\", \"like v share\")\n",
    "    final_docs = []\n",
    "    for d, s in ranked:\n",
    "        if all(h.lower() not in d.page_content.lower() for h in BAD_HINTS):\n",
    "            final_docs.append(d)\n",
    "        if len(final_docs) >= top_k:\n",
    "            break\n",
    "    return final_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5d9c44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranking Time taken: 9.172336101531982 seconds\n",
      "[0]  | [CS315 - Chng 3] Deep Generative Models (2) - Part 1 | https://youtube.com/watch?v=SCNZncN1Hvk\n",
      "    0:00:14  0:01:11\n",
      "   Chng ta s cng n vi cc m hnh to sinh hc sau Deep Generated Model phn 2, m hnh Diffusion. Cc m hnh to sinh hnh nh u c gc gc s dng m hnh pht tn, m hnh Diffusion Model. y c th ni l mt trong nhng m hnh c tnh ng dng rt cao do to ra nhng nh c  phn gii...\n",
      "--------------------------------------------------------------------------------\n",
      "[1]  | [CS315 - Chng 3] Deep Generative Models (2) - Part 4 | https://youtube.com/watch?v=NJVpvCzceRk\n",
      "    0:06:19  0:08:34\n",
      "   y l mt ci thao tc khng tnh o hm c. Dn n l khi chng ta s dng ci k thut tnh Gradient Ascent, chng ta s khng th hun luyn c ci m hnh Diffusion Model ny. Do  chng ta s vit li x di dng l mt ci hm s khc. V thay v chng ta ly mu trn x, th chng ta s...\n",
      "--------------------------------------------------------------------------------\n",
      "[2]  | [CS315 - Chng 0] Gii thiu mn hc (Phn 1) | https://youtube.com/watch?v=RU8d6QAuX0k\n",
      "    0:04:07  0:05:48\n",
      "    chnh l m hnh da trn xc sut v c th ca mt m hnh da trn xc sut  chnh l m hnh khuch tn l Diffusion Model. Sau  sang tun th 11 th chng ta s cng tm hiu v nhng m hnh hc su nhng m c s tham gia ca ngn ng v th gic hay cn gi l Vision Language Model. ...\n",
      "--------------------------------------------------------------------------------\n",
      "[3]  | [CS315 - Chng 3] Deep Generative Models (2) - Part 8 | https://youtube.com/watch?v=nZc5vWo2Rrg\n",
      "    0:00:14  0:01:10\n",
      "   Tip theo chng ta s bn v tc  ca m hnh Diffusion i vi m hnh Diffusion th vn  ln nht l n phi sampling rt nhiu bc trung gian  c th encode v decode Nh vy th lm sao  c th sinh ra nh vi tc  nhanh hn Nguyn nhn l trong qu trnh thm nhiu vo, nhiu sau s ...\n",
      "--------------------------------------------------------------------------------\n",
      "[4]  | [CS315 - Chng 3] Deep Generative Models (2) - Part 4 | https://youtube.com/watch?v=NJVpvCzceRk\n",
      "    0:13:08  0:14:21\n",
      "   Nh vy th lm sao chng ta c th kh nhiu c? V da trn ci cng thc ca ci ELBO m chng ta  c  nhng slide trc. Qua mt s ci php bin i, th  y l do s lng php bin i qu nhiu. Nn chng ta ch ghi ci kt qu cui cng  y thi. Th n s c ba ci thnh phn s h...\n",
      "--------------------------------------------------------------------------------\n",
      "[5]  | [CS315 - Chng 3] Deep Generative Models (2) - Tng kt | https://youtube.com/watch?v=--6FInuIyys\n",
      "    0:02:26  0:04:16\n",
      "   Th y l ba ci cch. V sau  th chng ta  tm hiu v cch  iu hng vi hai k thut  l classifier guidance. Vi mi mt ci condition mi, th mt ci condition chng ta s ra mt ci classifier. Nh vy th n s khng c linh ng trong ci vic l update hoc l thay ci conditio...\n",
      "--------------------------------------------------------------------------------\n",
      "[6]  | [CS315 - Chng 3] Deep Generative Models (2) - Part 4 | https://youtube.com/watch?v=NJVpvCzceRk\n",
      "    0:16:35  0:17:31\n",
      "   y chnh l ci s c th ring ca ci diffusion model. Nh vy th lm sao  c th hun luyn c ci hm P ny. Sao cho n khp vi li ci q. Th  trong ci hnh ny, n minh ha mt ci trc quan.  l ci qu trnh, ci mu tm  y, tng ng l ci mu hng  y. L ci phn b ca ...\n",
      "--------------------------------------------------------------------------------\n",
      "[7]  | [CS431 - Chng 10] Part 7: Mt s ng dng ca kin trc mng Transformer | https://www.youtube.com/watch?v=iMfkIHkU6NM\n",
      "    0:16:28  0:18:56\n",
      "   Ri, v cui cng  chnh l chng ta c mt v d  l trn multimodal. Tc l va c s kt hp ca c nh v text. Th trong ci model l Stable Diffusion, chng ta thy l c s tham gia ca text l ng vai tr l conditioning  can thip vo khng gian latent  cho chng ta c th chnh s...\n",
      "--------------------------------------------------------------------------------\n",
      "[8]  | [CS315 - Chng 3] Deep Generative Models (2) - Part 8 | https://youtube.com/watch?v=nZc5vWo2Rrg\n",
      "    0:01:08  0:12:20\n",
      "   V ngc li khi chng ta denoise cng nh th. Nh vy th thi gian chy ca diffusion s l bng t nhn cho thi gian chy ca GAN v VAE. Vy th chng ta s nhc li cng thc to sinh ca m hnh ca mnh. Trong m hnh to sinh ca mnh th cng thc s dng theo cch thc s 2 ca chng ta ...\n",
      "--------------------------------------------------------------------------------\n",
      "[9]  | [CS315 - Chng 3] Deep Generative Models (2) - Part 3 | https://youtube.com/watch?v=qCEs0PIGwek\n",
      "    0:00:14  0:00:40\n",
      "   Chng ta s cng tm hiu v m hnh khuch tn diffusion model v s khc bit gia diffusion model so vi m hnh variational autoencoder ra sao, qu trnh khuch tn c thc hin nh th no. Chng ta s nhc li cng thc ca m hnh xc sut ng trc,  l log P ca x s l bng tng ca h...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "## test reranker\n",
    "start= time.time()\n",
    "query = \"diffusion l g\"\n",
    "docs = vector_retriever.get_relevant_documents(query)\n",
    "reranked_docs = crossencoder_rerank(docs, query, top_k=10)\n",
    "end = time.time()\n",
    "print(f\"Reranking Time taken: {end - start} seconds\")\n",
    "\n",
    "for i, d in enumerate(reranked_docs):\n",
    "    m = d.metadata\n",
    "    print(f\"[{i}]  | {m.get('title', '')} | {m.get('video_url', '')}\")\n",
    "    print(f\"    {m.get('start_timestamp', '?')}  {m.get('end_timestamp', '?')}\")\n",
    "    text = d.page_content.replace(\"\\n\", \" \").strip()\n",
    "    print(\"   \" + (text[:300] + (\"...\" if len(text) > 300 else \"\")))\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "218bd48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allocated: 0.0 GB\n"
     ]
    }
   ],
   "source": [
    "print(\"allocated:\", torch.cuda.memory_allocated(0) / 1e9, \"GB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4592cfd",
   "metadata": {},
   "source": [
    "## bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97bd28c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "# ===== 1. Load docs t Chroma =====\n",
    "raw = vector_db_semantic.get(include=[\"documents\", \"metadatas\"])\n",
    "docs = []\n",
    "\n",
    "for content, metadata in zip(raw[\"documents\"], raw[\"metadatas\"]):\n",
    "    docs.append(Document(\n",
    "        page_content=content,\n",
    "        metadata={\n",
    "            \"filename\": metadata.get(\"filename\", \"\"),\n",
    "            \"video_url\": metadata.get(\"video_url\", \"\"),\n",
    "            \"start_timestamp\": metadata.get(\"start_timestamp\", \"\")\n",
    "        }\n",
    "    ))\n",
    "\n",
    "# ===== 2. BM25 retriever t LangChain =====\n",
    "if docs:\n",
    "    bm25_retriever = BM25Retriever.from_documents(docs)\n",
    "    bm25_retriever.k = 30     # s lng tr v\n",
    "else:\n",
    "    bm25_retriever = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b04b0e",
   "metadata": {},
   "source": [
    "## Hybrid : semantic search + keyword search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bf61a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== 3. Hybrid retriever =====\n",
    "if bm25_retriever is None:\n",
    "    hybrid_retriever = EnsembleRetriever(\n",
    "        retrievers=[vector_retriever],\n",
    "        weights=[1]\n",
    "    )\n",
    "else:\n",
    "    hybrid_retriever = EnsembleRetriever(\n",
    "        retrievers=[bm25_retriever, vector_retriever],\n",
    "        weights=[0.5, 0.5]   # chnh theo  mun\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b7c0314",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_31336\\254254511.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = hybrid_retriever.get_relevant_documents(\"diffusion l g\") if bm25_retriever else []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'filename': '--6FInuIyys', 'video_url': 'https://youtube.com/watch?v=--6FInuIyys', 'start_timestamp': '0:02:26'}, page_content='Th y l ba ci cch. V sau  th chng ta  tm hiu v cch  iu hng vi hai k thut  l classifier guidance. Vi mi mt ci condition mi, th mt ci condition chng ta s ra mt ci classifier. Nh vy th n s khng c linh ng trong ci vic l update hoc l thay ci condition. Chng ta s c k thut khc ci tin  chnh l classifier free guidance. Tc l chng ta s b lun ci classifier ny m chng ta ch i fine-tune li ci m hnh diffusion. Ch fine-tune li diffusion, khng c dng thm ci classifier no  cho n c th l train c t u, fine-tune t u n cui. Sau  chng ta  ni qua nhng ci vn  v  phn gii khi chng ta lm vic vi latent, xin li khi lm vic vi diffusion. V ci k thut m cascade diffusion th n rt l cng knh. V n phi s dng n hai ba ci m hnh ni tip nhau v c lp nhau. N khng c end to end, tc l kt ni t u n cui. Do  th chng ta c ci m hnh latent diffusion v m ra mt ci hng n gi l end to end diffusion. Th latent diffusion c th ni l mt trong nhng ci m hnh m cho ci impact rt l ln trong cng ng nghin cu. L v n  gip cho chng ta tnh ton nhanh, ri ci m hnh ca mnh t c ci  phn gii rt l cao, cht lng rt l tt.'), Document(metadata={'filename': '79WZow7G8fE', 'video_url': 'https://youtube.com/watch?v=79WZow7G8fE', 'start_timestamp': '0:02:32'}, page_content='V n s d gy ra ci hin tng  l lan truyn li. V d iu g xy ra nu nh ci nh 64 x 64 ny n c nhng ci artifact, tc l nhng ci du hiu  m khng c c p v c nhng ci li trong hnh nh. V vy th n s lan truyn ci li  n nhng ci nh sau m khng c ci c ch, n khng c c ch  sa li. Th th ci m hnh ny cascade diffusion ny th n s khng c ph hp  m c th ng dng c. L do  l v th nht l n s lan truyn li.'), Document(metadata={'filename': 'nZc5vWo2Rrg', 'video_url': 'https://youtube.com/watch?v=nZc5vWo2Rrg', 'start_timestamp': '0:01:08'}, page_content='V ngc li khi chng ta denoise cng nh th. Nh vy th thi gian chy ca diffusion s l bng t nhn cho thi gian chy ca GAN v VAE. Vy th chng ta s nhc li cng thc to sinh ca m hnh ca mnh. Trong m hnh to sinh ca mnh th cng thc s dng theo cch thc s 2 ca chng ta  l on xem ci nhiu ti mt thi im t so vi li ci nhiu ng l bao nhiu th chng ta s c mi ca qi xt phi x0 l bng cng thc ny v mi ca theta xt t th n s l bng cng thc ny trong cng thc ny th chng ta thy n c tnh cht gi l Markov tc l phi tnh xt c trc ri mi tnh xt tuy nhin c mt bi bo khc  l DDIM tc l denoising diffusion implicit model th  b i ci yu t gi l chui Markov tc l chng ta s khng c yu cu qu xt, xt tr 1 phi l mt chui Markov, tc l phi tnh c xt tr 1 xong ri chng ta mi tnh c ci xt ny th  y chng ta s dng ci s  ny  d hnh dung  l t xt chng ta c th tnh trc tip ln x1 xin li t x0 chng ta c th tnh trc tip ln x1 t x0 chng ta c th tnh trc tip n x2 m khng cn thng qua khng cn thng qua ci bc tnh x1 ny th cng thc ca mnh s l qi ca xt khi chng ta bit trc xt tr 1 x0 th lc ny chng ta s tnh trc tip t x0 m khng cn qua xt tr 1 vy th  trn cng thc ny chng ta thy bn cht ca cc cng thc n ch l mt s tnh ton vi cc h s a, b v b a v b hm mi ca qu xt, xt0, xt0 l bng a, b, axt, b t tng nh vy mi theta ca xt, t l bng axt, b, theta xt Th th chng ta ch cn tm a v b sao cho min l ci xt n tha mn xt l bng cn ca alpha t x0 cng cho 1 tr cn alpha 1 tr... cng cho cn ca 1 tr alpha epsilon th nh vy l  ng c Th ci m hnh DDIM  tng ca n  l thay v chng ta i tng bc ph thuc bc th t chng ta tnh xong th chng ta mi n c bc th T cng 1 th n s dng mt ci cng thc trc tip t x0 cho n ci v tr th T lun v ngc li cng vy th th n s nhy cc, ni mt cch nm na  l n s tnh ton nhy cc ci bc m encoding v decoding v nh vy th ci tc  ca DDIM c th nhanh hn gp 10 hoc thm ch l gp 100 ln so vi li DDPM DDPM y l m hnh probabilistic tc l m hnh c xc sut Cn  y l implicit Tc l mt m hnh m n c th tnh mt cch n nh khng c kiu yu t nhiu trong  khng c yu t nhiu Th th xt v tc  th DDPM n hn Cn xt v  chnh xc th n gn nh tng ng v thm ch l tt hn  mt s tnh hung v d vi s Step 10, FID l 10, DDPM l 13, DDPM l 300 khi thc hin vi 1000 step, DDPM cho  chnh xc cho FID l tt nht DDPM cng gn nh tng ng, 4.0 nhng t 100 tr v trc,  y l 4,0, cn  y l gn 10,4,0, rt tt hn 10 nhiu Vi DDIM, s step ca mnh m nh hn 100,  chnh xc FID ca mnh tt hn hn so vi DDPM. Tng t nh vy cho b CelebA-64, kt qu cng hon ton tng t nh vy. DDIM c th ni l mt trong nhng ci tin t ph trong vic  l ci tin v tc  ca mt m hnh diffusion chuyn t dng probabilistic sang dng deterministic  m mnh c th ly mu nhanh. V mt k thut khc  l progressive distillation khi ni n m hnh hc my th chng ta s c k thut tc l hun luyn mt m hnh teacher c mt s tham s rt l ln v m hnh student c s lng tham s t hn trong trng hp ny th chng ta s hun luyn m hnh teacher v student phi hp vi nhau  sao cho chng ta, thay v chng ta phi i tng bc nh th ny th chng ta c th i nhng ci ng tt m vn c th n c ch progressive distillation  y chng ta s hun luyn teacher trc v sau  chng ta s distill vo knowledge ca student theo ng mu vng ny th student ca mnh l i theo cc ng tt, tc l n b qua cc bc trung gian  y sau , nu l progressive c ngha l g? n ly chnh ci ng tt ny, tc l ci m hnh m i denoise theo ci kiu ng tt ny  lm teacher  lm teacher, l ci ng mu vng ny l teacher th chng ta s i mt ci ng tt hn na,  l student chng ta s b qua ci node ny b qua ci node ca teacher c  to ra mt student mi c bc nhy cc nhanh hn th y chnh l Progressive Length Distillation chng ta tng bc gim s bc ca mnh xung  tng tc  denoise M hnh Guided Distillation  tng cng l dng Distillation nhng m kt hp vi Latent Diffusion y l mt m hnh cho chng ta va t c tc  hun luyn v tc  inference ca mnh. y l m hnh c Condition l Y, cho php chng ta iu hng m hnh ca mnh. V vy,  y l mt m hnh Guided Distillation l giao thoa hoc l kt hp ca Progressive tc l chng ta s i cc ng i tt thay v chng ta i tng bc, tng bc, tng bc th chng ta s i tt hoc thm ch l tt hn, tc l chng ta c th i trc tip t y sang y thng qua ci vic l chng ct tun t sau  chng ta kt hp vi m hnh Latent Diffusion, tc l chng ta ch lm bc encode v decode  trn khng gian latent thi, tc l chng ta khng lm trong khng gian nh m lm trn khng gian latent v kt qu ca Guided Distillation th chng ta thy l rt l p v Cc bc t 2 bc, 4 bc v 8 bc th kt qu gn nh tng ng nhau, khng c s phn bit g nhiu Vi ch 2 bc m kt qu ca chng ta rt l tt So vi ng nhin l 8 bc nhiu bc hn th n s p hn, chi tit hn nhng m 2 bc th kt qu cng rt l tt v khi chng ta denoise m ch c hai bc th r rng tc  mnh nhanh hn rt l nhiu so vi li denoise c t bc th y l ci kt qu vo nm 2023 v chng ta s c ci m hnh consistency model tc l chng ta s kt hp cc ci loss li vi nhau l bng min ca EMA ca XT v T Ri F ca theta x t phi th y l mt ci target network hay cn gi l m hnh ca teacher Cn online network s l m hnh student Tm li l i vi nhng ci gii php m gim ci tc  th chng ta s dng ci m hnh  l teacher v student Kt hp hai ci network ny li  chng ta c th to ra ci m hnh m tt hn, i tt hn v multi-step hn v d nh  y chng ta thy l ci ng ny n l i 1 pht 1 n ch th n  tit gim cho chng ta rt l nhiu cc bc denoise nh vy th chng ta c th l single step generation l mt bc nhy t xt ln v x0 V kt qu ca Latent Consistency Model th cng hon ton tng t nh cc m hnh trc Vi 4 Step Inference, 4 Step Denoise th kt qu ca mnh vn cho cht lng rt tt Ngoi ra th chng ta s c cc k thut lin quan n vn  v Fine-tune li m hnh Fine-tune m hnh diffusion Khi ni v m hnh diffusion th tham s thng rt ln L do  l n phi encode c vn bn Cng vi li encode c thng tin v mt hnh nh Do  s lng tham s ca mnh ca cc m hnh diffusion thng rt l ln c nhng m hnh ln n gn 1 t tham s c nhng m hnh hin i hn th c th ln n 3 t, 4 t tham s  to c nhng k nh cht lng tt v hiu c vn bn, hiu c yu cu u vo ca mnh th s tham s l ln v chng ta mun fine-tune m hnh diffusion ny vi data set ca mnh Th khi  n rt d b hin tng overfitting. Ti v trong cc ci bi trc chng ta  ni ri, hin tng overfitting xy ra khi s lng tham s ln v khi d liu ca mnh t.'), Document(metadata={'filename': 'NJVpvCzceRk', 'video_url': 'https://youtube.com/watch?v=NJVpvCzceRk', 'start_timestamp': '0:13:08'}, page_content='Nh vy th lm sao chng ta c th kh nhiu c? V da trn ci cng thc ca ci ELBO m chng ta  c  nhng slide trc. Qua mt s ci php bin i, th  y l do s lng php bin i qu nhiu. Nn chng ta ch ghi ci kt qu cui cng  y thi. Th n s c ba ci thnh phn s hng. S hng u tin  l ci k vng ca phn b xc sut ca x1 cho trc x0. X0 ca mnh chnh l ci nh gc ban u. N sau  thm mt t nhiu  to ra thnh x1. Th chng ta s ly k vng trn ton b ci phn b ca x1. V log ca Ptheta x0 cho trc x1. Th ci  ngha ca ci cng thc ny  l g?  ngha ca ci cng thc ny  l t x1 cho trc x1. Chng ta khi phc c tr li x0. V phn b xc sut ca Ptheta x0 ny l phi cc i. Ti v trong cng thc ca diffusion model l chng ta cc i ci k vng ny.'), Document(metadata={'filename': 'NJVpvCzceRk', 'video_url': 'https://youtube.com/watch?v=NJVpvCzceRk', 'start_timestamp': '0:16:35'}, page_content='y chnh l ci s c th ring ca ci diffusion model. Nh vy th lm sao  c th hun luyn c ci hm P ny. Sao cho n khp vi li ci q. Th  trong ci hnh ny, n minh ha mt ci trc quan.  l ci qu trnh, ci mu tm  y, tng ng l ci mu hng  y. L ci phn b ca ci XT. Phn b ca XT khi chng ta c encode t XT-1, c encode t XT-1. Tc l chng ta phun nhiu v thm nhiu t XT-1. Th ci phn b ny n phi khp vi li ci phn b ca ci P, tc l ci mu xanh ca XT, cho trc XT-1. Tc l chng ta kh nhiu t XT-1  v ci XT.'), Document(metadata={'filename': '79WZow7G8fE', 'video_url': 'https://youtube.com/watch?v=79WZow7G8fE', 'start_timestamp': '0:07:03'}, page_content='V hun luyn n cng s n nh hn. Th  chnh l ci iu khin cho latent diffusion model l mt trong nhng ci m hnh to sinh hnh nh m c rt nhiu ci trch dn v c rt nhiu cc ci bi bo cng nh l cc ci nghin cu gn y h s dng  pht trin.'), Document(metadata={'filename': 'SCNZncN1Hvk', 'video_url': 'https://youtube.com/watch?v=SCNZncN1Hvk', 'start_timestamp': '0:00:14'}, page_content='Chng ta s cng n vi cc m hnh to sinh hc sau Deep Generated Model phn 2, m hnh Diffusion. Cc m hnh to sinh hnh nh u c gc gc s dng m hnh pht tn, m hnh Diffusion Model. y c th ni l mt trong nhng m hnh c tnh ng dng rt cao do to ra nhng nh c  phn gii cao, ng thi c th cho chng ta can thip v iu hng ni dung ca tm nh. Vy th  tng ca Diffusion l g v cch thc hun luyn ra sao, chng ta s cng tm hiu trong bi ngy hm nay. Cc vn  chnh khi chng ta tm hiu mt m hnh Diffusion Model, m hnh pht tn,  l chng ta s tm hiu v m hnh to sinh tng qut. M hnh to sinh tng qut ny s da trn l thuyt v xc sut thng k.'), Document(metadata={'filename': '79WZow7G8fE', 'video_url': 'https://youtube.com/watch?v=79WZow7G8fE', 'start_timestamp': '0:00:52'}, page_content='V ci ny n s c thc hin i, thc hin li l T, 1 bc. V khi sang ci m hnh cascade diffusion mode th chng ta khng ch text-to-image diffusion, tc l y l ci m hnh gc ban u n. N s c kt hp vi cc m hnh  thc hin vic super resolution, tc l tng kch  phn gii ln. V  trong hnh bn di chng ta thy  l ban u ci nh ca mnh n s c kch thc l 64 x 64. V y l ci m hnh diffusion gc. Sau khi chng ta kt thc text-to-image diffusion, n s to ra tm hnh ging nh th ny. Th chng ta s train mt ci m hnh super resolution th 2  tng kch thc ca tm nh ln. V n  tng ln 256 x 256. Ri sau  chng ta li tip tc chy qua mt ci m hnh super resolution diffusion mode  tng ln l 1024 x 1024. Nh vy th vi ci m hnh cascade diffusion ny chng ta thy,  l ci qu trnh hun luyn ny l n c lp nhau. Text-to-image v super resolution diffusion 1 v 2 th khng c, ni chung l hun luyn c lp vi nhau. V n khng c end to end, tc l khng c hun luyn t u n cui.'), Document(metadata={'filename': 'qCEs0PIGwek', 'video_url': 'https://youtube.com/watch?v=qCEs0PIGwek', 'start_timestamp': '0:00:14'}, page_content='Chng ta s cng tm hiu v m hnh khuch tn diffusion model v s khc bit gia diffusion model so vi m hnh variational autoencoder ra sao, qu trnh khuch tn c thc hin nh th no. Chng ta s nhc li cng thc ca m hnh xc sut ng trc,  l log P ca x s l bng tng ca hai k vng ny.'), Document(metadata={'start_timestamp': '0:00:14', 'chunk_id': 0, 'end_timestamp': '0:01:08', 'video_url': 'https://youtube.com/watch?v=NJVpvCzceRk', 'filename': 'NJVpvCzceRk', 'title': '[CS315 - Chng 3] Deep Generative Models (2) - Part 4'}, page_content='Ri trong nhng phn trc th chng ta  cng tm hiu v s khc nhau gia VAE, Variational Autoencoder v Diffusion C hai m hnh VAE v Diffusion u da trn l thuyt  l chng ta s cc i ha log ca PX ny, tc l lm sao cho k nh X ca mnh ging tht nht. Thay v chng ta cc i ha log PX ny, chng ta s cc i ha chn di, tc l evidence lower bound ELBO ca k vng ny. Nu nh trong cng thc ca VAE, th ci Z ny l mt vector n, th  y chng ta s c nhiu vector n, ti v m hnh Diffusion ca mnh s thc hin nhiu bc  encoding. Nguyn l ca n  l chia thnh nhng bc nh, th n s gip chng ta n gin ha bi ton ca mnh.'), Document(metadata={'filename': '79WZow7G8fE', 'video_url': 'https://youtube.com/watch?v=79WZow7G8fE', 'start_timestamp': '0:00:14'}, page_content='Vn  tip theo th chng ta s bn v  phn gii. Do sao th cc m hnh to sinh nh nu m mun c ng dng c th n phi c th to ra c nhng ci nh m c kch thc ln. Vy th vi m hnh cascade diffusion th chng ta s denoise, chng ta thm nhiu ri sau  chng ta s kh nhiu  trn cng mt  phn gii khc nhau. V d nh  y chng ta thy l y l m hnh diffusion gc, th kch thc ca noise ca mnh ng bng kch thc ca nh m chng ta s decode. V ci qu trnh m chng ta hun luyn m hnh th y l mt ci m hnh  m to ra mt ci nh vi iu kin cho trc l ci Y.'), Document(metadata={'filename': '79WZow7G8fE', 'video_url': 'https://youtube.com/watch?v=79WZow7G8fE', 'start_timestamp': '0:03:18'}, page_content='Ci th hai  l ci s cng knh. Mnh mong mun khi setup th n s ch c duy nht mt m hnh thi, cn  y n c n 3 ci m hnh thc hin cng mt lc. Nh vy th chng ta s sang mt ci phin bn tip theo  c th gii quyt c ci m hnh, ci im yu ca m hnh cascade diffusion ny.  chnh l ci m hnh latent diffusion. Th latent diffusion l chng ta s thc hin ci diffusion, chng ta thc hin ci bc l denoise v add noise  trn ci khng gian latent. Th u tin chng ta train mt ci m hnh VAE  nh x t ci nh c  phn gii cao v d nh l 1024 v ci khng gian latent z ca mnh, v d nh l 64 x 64. Ri, sau  vi ci  phn gii thp ny, ci nh  phn gii thp ny chng ta s decode ra  to ra ci nh gc. V chng ta s c mt ci reconstruction loss, tc l ci loss  kim tra xem ci nh chng ta ti to c ging vi nh ban u hay khng. Ri sau  chng ta cng s c ci phn regularization loss  cho ci latent z ny n tun theo mt ci phn b l, tun theo mt ci prior distribution mong mun, v d nh l phn b Gauss. Ngoi ra th cn c thm ci adversarial loss ca gan  gip cho chng ta c th to ra nhng ci tm nh c cht lng cao vi  sc nt chi tit. V chng ta s s dng ci m hnh VAE ny  l ci bc u tin  nn, chng ta s nn ci nh x ny qua VAE encoder. Chng ta s to ra ci vector latent z, sau  chng ta s p dng ci m hnh diffusion trn chnh ci khng gian latent ny, thay v trn khng gian gc chng ta s to ra d, y l d, d1 hoc l d0 i ha, d2, ri cho n dt, th y l ci qu trnh encode. Sau  chng ta s tin hnh l decode l t dt, denoise ra dt tr 1 v.v. v d0 m, v vi d0 m ny sau  chng ta p dng ci decoder ca VAE, th n  to ra mt ci tm hnh, ging nh  y, th y l ci cch thc  chng ta hun luyn mt ci m hnh latent diffusion. Ci  tng ln nht ca ci latent diffusion ny, th nht  l mt ci end-to-end model. V ci th hai,  l thay v chng ta diffusion, chng ta encode v decode hoc l chng ta add noise hoc denoise ha, encode v decode. Nhng chng ta khng lm trn khng gian nh m chng ta lm trn khng gian latent.'), Document(metadata={'end_timestamp': '0:02:11', 'start_timestamp': '0:01:28', 'video_url': 'https://youtube.com/watch?v=NJVpvCzceRk', 'filename': 'NJVpvCzceRk', 'title': '[CS315 - Chng 3] Deep Generative Models (2) - Part 4', 'chunk_id': 2}, page_content='X0 s l nh u vo c sampling theo phn b ca data X. Vy th cng thc  trn s c a v v bi ton m hnh Diffusion model s a v vic cc i ha k vng ca x1 cho n XT cho trc X0. Th y chnh l latent ca mnh. V xT s l gm x0 cho n XT, n m, trn li vi nhau. Cn cng thc  y th n em qua t y.'), Document(metadata={'filename': '--6FInuIyys', 'video_url': 'https://youtube.com/watch?v=--6FInuIyys', 'start_timestamp': '0:00:58'}, page_content='y ci ELBO ny ln, maximum ELBO ny ln. V khi chng ta maximum ELBO ny ln th chng ta s c hai ci m hnh,  l VAE v m hnh diffusion. V i vi ci m hnh diffusion th chng ta s c ci bc gi l khuch tn thun. V trong ci khuch tn thun ny th chng ta s thm nhiu vo ci nh ca mnh. V  y l chng ta khng c tham s  hc, khng c tham s hun luyn. Ci iu ny n gip cho chng ta n gin ha ci vic hun luyn ca ci m hnh diffusion m ch dnh ci d a  hun luyn cho ci phn denoising, phn kh nhiu. Chng ta ch hc kh nhiu v hc bng c ba cch. Cch u tin  l chng ta s ti u  sao cho ci x m theta xp x vi li x0. Cch th hai  l chng ta ti u ci epsilon theta sao cho xp x vi li ci epsilon. V cch s ba  l chng ta s ti u  cho ci x m theta xp x vi li ci gradient ca log p theta. Th y ging nh l ci hng  kh nhiu ca mnh.'), Document(metadata={'video_url': 'https://youtube.com/watch?v=nZc5vWo2Rrg', 'title': '[CS315 - Chng 3] Deep Generative Models (2) - Part 8', 'chunk_id': 0, 'end_timestamp': '0:01:10', 'filename': 'nZc5vWo2Rrg', 'start_timestamp': '0:00:14'}, page_content='Tip theo chng ta s bn v tc  ca m hnh Diffusion i vi m hnh Diffusion th vn  ln nht l n phi sampling rt nhiu bc trung gian  c th encode v decode Nh vy th lm sao  c th sinh ra nh vi tc  nhanh hn Nguyn nhn l trong qu trnh thm nhiu vo, nhiu sau s ph thuc vo nhiu trc Tc l  denoise c xt-2 th phi c xt-1 M mun tnh c xt-1 th phi c xt Chnh s tun t ny s khin chng ta chm Nguyn nhn ca tun t ny l n gi nh theo chui Markov, tc l phi c x th t tr 1 xong chng ta mi c th tnh c xt.  chnh l nguyn nhn.'), Document(metadata={'end_timestamp': '0:05:48', 'chunk_id': 3, 'title': '[CS315 - Chng 0] Gii thiu mn hc (Phn 1)', 'video_url': 'https://youtube.com/watch?v=RU8d6QAuX0k', 'filename': 'RU8d6QAuX0k', 'start_timestamp': '0:04:07'}, page_content=' chnh l m hnh da trn xc sut v c th ca mt m hnh da trn xc sut  chnh l m hnh khuch tn l Diffusion Model. Sau  sang tun th 11 th chng ta s cng tm hiu v nhng m hnh hc su nhng m c s tham gia ca ngn ng v th gic hay cn gi l Vision Language Model. i vi ting Anh th chng ta  l Vision Language Model nhng m khi chng ta dch sang ting Vit th n s o li,  l ngn ng th gic. V 3 m hnh u tin chng ta s cng tm hiu trong tun th 11  chnh l m hnh clip, m hnh clip v m hnh clip. Sau  th chng ta s tm hiu v nhng m hnh ngn ng th gic m  cp  c s tng tc v ng ngha cao hn,  l m hnh Visual Programming v GPT for Vision. Ri cui cng trong m hnh ngn ng th gic th chng ta c cc m hnh s dng m hnh ngn ng th gic  gii quyt bi ton t kinh in cho n hin i ca th gic my tnh. V d nh l Grounding Dino  phc v cho bi ton pht hin vt th hoc l phn on ng ngha gic. u tin l  pht hin, sau  l kt hp vi thut ton SAM  phn on ng ngha i tng.'), Document(metadata={'filename': 'iQqNUKgIZpc', 'video_url': 'https://youtube.com/watch?v=iQqNUKgIZpc', 'start_timestamp': '0:13:11'}, page_content='V  c l hn 200.000 v gn xp x 300.000 citation, l 300.000 ci trch dn. Th cch y l hn mt nm th mi ch khong l 210.000 nhng m sau mt nm l n nhy ln 90.000. Th th th chng ta thy  l ci tc  tng citation rt l nhanh v cha thy c mt ci du hiu g l dng li. Th iu  chng t l ci k thut m Skip Connection ny rt l hiu qu v c rt nhiu nhng ci nghin cu h s dng gn y. V vi ci kt ni tt ny th khng ch ResNet m nhng ci kin trc khc v d nh l DenseNet cng s c cc ci kt ni tt. y l cc kt ni tt. Ri Transformer cng vy. Chng ta thy l Transformer l Attention Is All You Need. Tc l l tt c nhng g bn cn.'), Document(metadata={'end_timestamp': '0:08:49', 'filename': 'Hrmm1B6sR8g', 'title': '[CS315 - Chng 3] Deep Generative Models (2) - Part 2', 'chunk_id': 8, 'start_timestamp': '0:08:10', 'video_url': 'https://youtube.com/watch?v=Hrmm1B6sR8g'}, page_content='Khi a v min chng ta o th t cho nhau. V chng ta  a n v ci cng thc ca KL diversion. Th y l mt ci cng thc rt l ni ting. Ri, ci  ngha ca ci cng thc ny  l g?  l chng ta s tm cch  cho ci P theta ny tin v vi P data. Hay l ci phn b mu cam ny n.'), Document(metadata={'filename': 'peYaH97QeEw', 'video_url': 'https://youtube.com/watch?v=peYaH97QeEw', 'start_timestamp': '0:00:14'}, page_content='Chc hi trc th chng ta  cng tm hiu v kin trc autoencoder By gi th chng ta s cng tm hiu v mt bin th rt l quan trng,  chnh l Variational Autoencoder Trc ht th chng ta s nhc li autoencoder l g v chng ta s xem c nhng im g cn phi ci tin trong kin trc ny u tin  l autoencoder th s bao gm hai thnh phn,  l mt encoder v mt decoder Trong , encoder, nhim v ca n l chng ta s nn d liu v biu din d liu  s chiu cao v mt vector biu din thp chiu hn Nu ch nh vy th khng c, chng ta s phi ti to li c so vi d liu gc ban u l x, chng ta s phi c mt decoder Vi decoder ny th n s gip chng ta lin kt v mt  ngha gia vector z v d liu gc ban u x Chng ta tng tng l trong mt khng gian latent, ging nh  y th nh ca mnh s c map vo mt khng gian v  y s l vector z Vector z ny qua decoder s khi phc ngc li v nh gc ban u Cu hi t ra  l by gi chng ta s dng autoencoder ny  lm g? R rng cc m hnh to sinh c s dng  sinh hnh nh, do  chng ta s tin hnh sinh hnh nh V d chng ta c mt vector  y v chng ta s qua hm decoder, vit tt ch D, th n s to ra thnh mt tm hnh Vi kin trc encoder th n khng c g m bo rng nh sau khi chng ta ti to li c th l mt nh c  ngha  l  th nht.'), Document(metadata={'end_timestamp': '0:05:30', 'video_url': 'https://youtube.com/watch?v=NEK5lIyST0M', 'chunk_id': 3, 'start_timestamp': '0:03:19', 'title': '[CS315 - Chng 1] M hnh hc my da trn Gradient (Phn 10)', 'filename': 'NEK5lIyST0M'}, page_content='Mo s khc ch ch khng th no m mo nh hn ch hoc l mo ln hn ch. Th  l ci cch  chng ta c th bit  l bi ton hi quy hay bi ton tuyn tnh. Th i vi ci bi ton hi quy th chng ta s c ci m hnh l hi quy tuyn tnh hay cn gi l linear regression. V i vi ci bi ton phn loi th chng ta s c hai tnh hung. Tnh hung u tin  l phn loi nh phn, tc l ci s phn lp ca ca mnh l c hai phn lp. V chng ta s c ci m hnh  l hi quy logistic hay l logistic regression. i vi trng hp m ca ln hn 2 th  s l chng ta s c ci m hnh  l hi quy softmax hay cn gi l softmax regression. Cn trong ci trng hp m ci m hnh ca mnh phi tuyn tnh th chng ta s c rt nhiu nhng ci m hnh hin i tp trung vo gii quyt ci bi ton m y ca mnh ph thuc mt cch phi tuyn tnh vi l x u vo. V mt trong nhng ci m hnh u tin m gii quyt ci bi ton m c tnh cht phi tuyn tnh  l m hnh Neural Network. Neural Network hay cn gi l mng Neural Nhn to, ANN. Th y c th ni l mt trong nhng ci m hnh u tin  t nn mng cho hc su. V cc ci m hnh v sau th chng ta thy n c ci ch A, c ci ch NN, v d nh l CNN. Th ci ch NN  y n cng chnh l Neural Network. V cn ANN th n cng c ci ch NN l Neural Network. V thm ch l Transformer th rt nhiu nhng ci, k c Transformer th rt nhiu nhng ci module  trong Transformer n cng da trn ci kin trc ca Neural Network. Do  th chng ta mi gi Neural Network l mt trong nhng ci m hnh nn tng u tin v hc su. V chng ta s n vi ci m hnh u tin.'), Document(metadata={'filename': 'qCEs0PIGwek', 'video_url': 'https://youtube.com/watch?v=qCEs0PIGwek', 'start_timestamp': '0:11:23'}, page_content='Ci v th hai  l ci thnh phn chnh quy ha l ci nhiu ny, th n s tun theo ci phn b 0.1. Cn i vi ci m hnh diffusion  di y th thay v mt bc, Th nht, ci s khc bit th nht  l thay v mt bc th  y chng ta s c nhiu bc encoding, nhiu bc nh encoding. V cui cng chng ta cng n c ci random noise nh th ny theo ci phn b normal distribution. Nhng ci s khc bit th hai  l trong m hnh VAE th n s c tham s, c ci tham s phi. Cn  y l khng c tham s, cc encoding ny l khng c tham s. Th  chnh l ci s khc bit ln nht m chng ta thy c gia hai ci m hnh VAE v AE. VAE th s c tham s v ch c mt bc, mt bc nhy l n c ci random noise. Th th chng ta thy l ci vic m chng ta nh x trc tip t nh th gii thc sang ci random noise ny m ch qua mt bc, th y l mt ci bi ton kh. V cha k khi chng ta decode ngc tr li t ci random noise ny th y cng l mt ci bi ton kh. Tuy nhin khi thay v chng ta gii mt ci bi ton kh vi mt ci encoder th chng ta s chia nh n ra thnh nhiu bc. Th nhng ci bc encoding ny n s l mt ci m hnh d hn, d hn rt l nhiu. Chng ta phun mt t nhiu ln trn ci X0  c ci X1, ri sau  phun mt t nhiu ln  thnh X2.'), Document(metadata={'chunk_id': 11, 'title': '[CS315 - Chng 3] Deep Generative Models (2) - Part 2', 'filename': 'Hrmm1B6sR8g', 'video_url': 'https://youtube.com/watch?v=Hrmm1B6sR8g', 'end_timestamp': '0:17:51', 'start_timestamp': '0:12:36'}, page_content='Tc l lm sao chng ta c th bit c ci P ca z khi cho trc x. Th  lm c ci chuyn  th chng ta s s dng mt ci hm,  l encoder. Tc l trong cng thc ny l cho trc x, cho trc x, lm sao chng ta xc nh c ci P ca z cho trc x th y l mt ci hm phn b. Vy lm sao bit c ci P ny? Th chng ta s thm v mt ci module l encoder  t ci d liu x m chng ta sampling trong th gii tht P data. Qua ci hm encoder ny th chng ta s xc nh c ci Quy zx, tc l phn b ca z khi bit trc x. Tc l cho trc mu d liu u vo v chng ta xc nh ci phn b ca z, ca ci vector trong khng gian tm n. Th th chng ta c ci cng thc  l P ca x l bng log ca Px. Th nhn vi li ci tch phn ca Quy z cho trc x nhn vi dz th ci cng thc ny n s c ci gi tr l bng mt. Ti v khi chng ta cho z da trn ton b ci khng gian xc sut ca n th Quy ca z cho trc x th tng xc sut ny l ci tch phn xc sut ny l lun l bng mt. Ti v dz n  chy, ci dz ny n chy trn ht trong ci khng gian xc sut ca n. Vy th chng ta s trin khai ci cng thc ny, em ci tch phn ra ngoi. Th s c l Quy ca zx cho trc x nhn vi li log ca Px dz. Chng ta a ci tch phn ra ngoi. Th ci cng thc ny n s tng ng vi ci vic l chng ta tnh ci k vng ca z, ly mu trong ci z cho trc x. Ri, nh vy th chng ta s ly ht ci phn b ny, sau  chng ta s ly ci xc sut , chng ta nhn vi li log ca Px. Th ci cng thc ny n s tng ng vi li ci k vng  y. V chng ta s cng nhn s dng ci cng thc Bayes th Px, hi ny chng ta  ghi ci cng thc ny ri. Px l bng Px v z chia cho Pzx da trn ci lut Bayes. V khi chng ta p dng ci cng thc ny vo th chng ta cng nhn cho t v mu l Quy ca z cho trc x. Ri, sau  chng ta o th t li, chng ta em ci Quy qua v em ci P qua y. Th khi  chng ta s c l Px, nhn cho Quy ca zx. Ri, v t ci cng thc  trn th chng ta s c l log ca tch,  y chng ta c ci php l php nhn. Chng ta c ci php nhn, th log ca tch s l bng tng 2 log. Ri, th l Px chia cho Quy ca zx, cn  y s l Quy ca zx chia cho Px. V chng ta s thy y chnh l ci cng thc  m chng ta c th c lng c ci Px ny. V lm sao cho ci Px ny n tin v ci P ca data.x th chng ta s da trn ci cng thc ny  chng ta xy dng ci m hnh. V  trong ci cng thc ny th k vng ca Quy zx, ca ci cng thc l log ca Quy zx chia cho P ca zx, th y chnh l ci cng thc ca KL diversion. y chnh l ci cng thc ca KL diversion.  trn y l Quy zx, th n s l KL diversion ca Quy zx v Pzx, tc l ci khong cch gia 2 ci phn b ny. M khong cch ca 2 ci phn b ny th  l con s ln hn khng. Tuy nhin lm sao chng ta c c ci ny, lm sao chng ta c c ci P ca zx th ci chuyn  l rt l kh. Rt kh  chng ta c th xc nh c ci phn b thc t ca z cho trc x.'), Document(metadata={'filename': 't5t5G61ZtAg', 'video_url': 'https://youtube.com/watch?v=t5t5G61ZtAg', 'start_timestamp': '0:04:27'}, page_content='th cch m chng ta s thc nghim  chnh l chng ta s lm ci li t tr 5 cho n 10 v t tr 10 cho n 5 ri, th chng ta s th ha chng ta s v ci li ny ri, tr 5 l  y ri chng ta s ly ci li chp ci mn hnh ny th tr 5 s l  y ri 10 s l  y tr 5 cho n 10 tr 5 cho n 10 th 10 s l  y ri v trc tung th l s t tr 10 cho n 5 tr 10 cho n 5 l  y tr 10 cho n 5 l  y ri, nh vy ci li m d nh chng ta s v l  khu vc ny trc honh l t tr 5 cho n 10 v trc tung l t tr 10 cho n 5 nh vy th chng ta s c mt ci khung vung ri, sau  chin thut ca chng ta l g? chng ta s chia li n ra v d nh trong trng hp ny chng ta s chia ra lm 12 khong cch u nhau ri, sau  chng ta cng s chia li theo chiu dc nh vy ri, th vi mi mt ci im trn ci mt li ny ly v d nh ci im  y chng ta s dng mt im en v d nh mt ci im trn ci mt li ny th n s l mt ci vector z m chng ta ly ra, chm ln trn ci li v chng ta s qua ci hm decoder  xem n ra mt ci tm nh g n nh th no sau  chng ta ly ci nh ny chng ta s v ln trn thnh mt ci ma trn vi ci nh ny chng ta s v ra mt nh vi mt ci im z  y chng ta s decode ra v v nh ln vi ci im ny, im ny chng ta decode ra v v nh ln th chng ta s ra mt ci ma trn cc im nh v chng ta s quan st xem n c ci tnh cht g c bit phi khng Ri, th  chnh l ci  tng ca ci hm Plot Reconstructed chng ta s chia ra thnh cc latent space vi n  y l bng 12, chng ta s chia ra lm 12 khong ri ly ci x v ci y ny chng ta s c c ci latent z l ci im mu en m chng ta  v ri qua ci hm decoder chng ta s ra c x hat tc l ci nh c to sinh ra v nh ny s c reset v ci kch thc l 28 x 28 v sau  v ln ci ma trn nh ri, th chng ta s chy ci on code ny  th vi ci v d ny chng ta c th thy  l  nhng ci khu vc pha trn  s ra mt ci hnh th g y v chng ta khng cm nhn c  l mt ci con s khu vc  gia  y cng vy n s c ln ln rt nhiu nhng ci hnh nh  trong  c th c cha nhiu con s dn n l mnh nhn mnh khng cm nhn c  l s g khu vc ny cng vy th th chiu ln trn ci hnh nh ca ci khng gian ca mnh th nhng nh  gc pha trn bn y l  khu vc tr 5 cho n 5 tr 5 cho n 5 tc l n nm  ci khu vc mu trng v ci khu vc mu trng ny khi chng ta decode ra th n s to ra mt ci nh khng c  ngha khng ging ci con s no ht  th y chnh l ci im yu ca m hnh auto encoder'), Document(metadata={'video_url': 'https://youtube.com/watch?v=ZMtZ2jeujIU', 'end_timestamp': '0:12:26', 'filename': 'ZMtZ2jeujIU', 'chunk_id': 0, 'title': '[CS315 - Chng 3] Deep Generative Models (1) - Part 3 (Phn 2)', 'start_timestamp': '0:00:14'}, page_content='Chng ta s la chn mt phn b xc sut prior tc l tin nghim, l Normal Gaussian Tc l chng ta c rt nhiu nhng dng phn b khc nhau, tuy nhin mt trong nhng phn b rt ph bin  l phn b chun l Normal Gaussian Chng ta mong mun phn b khng gian n ca mnh s l mt phn b ging vi phn b Gauss V c th lun l Normal Gaussian, tc l vi mu l bng 0 v sigma bnh phng l bng 1, th y l phn b n tin nghim V mnh s hun luyn m hnh  cho Q ca z cho trc x vi tham s phi l tun theo phn b Gauss V vy, phn b ng u s xoay xung quanh tm ca khng gian n, v d nh chng ta c mt khng gian n th mnh s tm cch a n v cng mt tm vi nhau V vy, phn b ca mnh s xoay xung quanh tm khng gian n, tc l mu bng 0, khuyn khch cho c trng phn b ng u xoay xung quanh tm khng gian n V vy, phn b u s xoay xung quanh tm khng gian n, tc l nu nh  trong m hnh autoencoder khng c hnh thng thng, th mnh s tm cch a n v cng mt tm V vy, phn b ca mnh s xoay xung quanh tm khng gian n, tc l nu nh  trong m hnh autoencoder khng c hnh thng thng, th mnh s tm cch a n v cng mt tm V vy, phn b ca mnh s xoay xung quanh tm khng gian n, tc l mu bng 0, khuyn khch cho c trng phn b ng u xoay xung quanh tm khng gian n V vy, phn b ca mnh s tm cch a n v cng mt tm Ci cng thc khong cch  li gia qi v p th n c tnh nh th no? N s c tnh da trn cng thc KL divergence gia hai phn phi V khi chng ta trin khai vi p l bng phn b Normal Gauss l mu bng 0 v sigma bnh bng 1, th chng ta s c cng thc  l bng mt phn tng ca g chy t 0 cho n k tr 1 ca sigma z cng cho mu z bnh phng tr 1 Tr cho log ca sigma z, trong  k chnh l s chiu ca vector ca mnh K chnh l s chiu ca khng gian n V khi  n cng chnh l s chiu ca mu, n cng chnh l s chiu ca sigma lun Ri, khi chng ta hun luyn mt m hnh VAE, thnh phn chnh quy ha ny n khuyn khch ci chuyn g?  l khi chng ta cho ci loss ny cng tin v 0, tc l cng gim R rng l vi cng thc ny chng ta s thy sigma z s c xu hng tin v 0 Ngc li,  y chng ta thy c ci du tr log ca sigma z, th n li khuyn khch ci sigma ny l khng qu nh N s khuyn khch Ci sigma z khng qu nh Cn ci mu tin v 0, tc l ci phn b ca mnh, n s ko t mt ci khu vc rt l xa, n s ko v tin v ci gc ta  00 ny y l mt ci mu ban u, n s ko ci mu ny v gc ta  Ri, ng thi sigma z nu nh ci phn b ca mnh n qu ln, th n s ko cho ci sigma ny tin v  nh Nhng nh c ci log ca sigma z ny th n s khin cho ci sigma ca mnh khng qu nh Ch cn nu m n nh qu th c phi l thay v chng ta a v mt phn b th cui cng n s a v mt im khng? Phn b ca mnh n s tin v mt im, nh vy l n tng t nh autoencoder ri Nh vy th ci sigma n s ko v, ng c qu ln nhng m cng ng c qu nh  hy vng rng l ci phn b ca mnh n thc s l mt ci phn b c yu t ngu nhin Ch cn nu m sigma m tin v bng 0, tc l n s co v mt im, tc l n s a v mt ci m hnh deterministic, tc l mt ci m hnh tt nh Ch khng c yu t xc sut nh trong ci m hnh VAE Th vi ci cng thc ny n s khuyn khch hai ci chuyn y, mt  l ci phn b Q ny s tin v 0, tin v ci gc ta  Ci th hai  l mu z, n s tin v mt ci phn b m c ci  lch va , ch n khng c qu nh nhng n cng khng qu to Th y l ci cng thc chnh quy ha V chng ta c nhng ci tnh cht g t ci vic chnh quy ha ny, n s c nhng tnh cht g u tin  l ci tnh lin tc, tc l nhng ci im gn nhau trong khng gian th ni dung hon ton tng t nhau khi gii m Chng ta ang ni n ci  ny Th  bn tri l mt ci m hnh khng c c chnh quy, tc l chng ta ch c ci sai s gia x tr cho x m thi Sai s ti to thi, ch c sai s ti to Th nu khng c thnh phn chnh quy ha th n s khng m bo c Th nht  l hai im gn nhau trong khng gian n, l ci im mu xanh l m v mu   y th n gn nhau trong khng gian tin n Nhng khi m gii m th n khng c tng t nhau, v d ci im mu xanh l ny, xanh l m ny th n s ra hnh vung Trong khi ci im mu  th li to ra mt ci hnh ging hnh tam gic, th hai ci hnh ny n khng c tng t nhau, mc d hai ci im ny n gn nhau Ci th hai  l i vi ci vic m khng chnh quy ha, n s c th khin cho ci im ca ci khng gian n c gii m nhng m khng c  ngha V d nh  y chng ta ch c hnh tam gic, hnh trn, hnh vung, nhng m c mt ci im  y l ci im m n khng qu gn ba ci im ny th khi chng ta gii m n ra mt ci hnh g y m n khng c  ngha V d nh trong ci ch s vit tay th khi chng ta decode ra l ra n phi ra l s, ch s th 0 cho n 9 nhng cui cng n s ra mt ci g y, n khng phi l con s Tc l mt ci d liu khng c  ngha, th nu nh khng c chnh quy ha n s khin cho chng ta b hai ci vn  ny Ngoi ra th nh c chnh quy ha n s gip cho chng ta gii quyt c ci vn  ,  l ci tnh lin tc ca d liu ca ci im biu din trong khng gian n Th hai ci vector z v z phi nm trong khng gian n m ging nhau, gn nhau th khi decode ra n cng phi ging nhau Tnh cht th hai,  l tnh y  l ly mu t khng gian n th ci ni dung ca mnh n s phi c  ngha, th y l mt ci v d ny khng c  ngha Cn nu nh chng ta s dng mt ci m hnh chnh quy ha, tc l bn cnh ci sai s ti to n c thm ci thnh phn chnh quy ha l c biu din bi ci cng thc l d ca kl,  l KL divergence ca qi v p Ci ny l vit tt nha, th cc ci im gn nhau th c gii m tng t v c  ngha, v d chng ta thy ci im mu cam v ci im mu tm th hai ci hnh ny khi chng ta gii m th chng ta thy ci dng dp n cng ging nhau Mc d ci im mu tm th n s hi bo  y mt cht, hi bo trn, nhng nu xt v hnh th th n cng gn ging vi hnh tam gic, do  th hai ci im ny khi chng ta dy n s c ci tnh tng t nhau v n hon ton l c  ngha ca n, n c ci l do ca n Ri, th y chnh l ci s khc bit ca vic c chnh quy ha v khng c chnh quy ha khi chng ta hun luyn vi ci m hnh VAE Th th mt ci biu din khc l sau khi chng ta  hun luyn xong m hnh VAE, th ci phn b chun tin nghim s m bo c ci yu t v tnh lin tc v tnh y  Ci tnh lin tc n th hin  ch  l nhng ci im no m gn nhau th khi decode n s ging nhau v ci tnh y   l mi im ca mnh Trong ci khng gian th khi chng ta decode ra n u c ci  ngha ca n ch khng phi l mt ci ni dung v ngha Th sau y chng ta s ni c mt ci v d r hn v ci chuyn ny Chng ta thy  y c 3 ci phn b mu  mu xanh v mu vng Th  y l ci tm cm mu  th khi chng ta decode ra n s ra ci hnh tam gic Cn y l tm cm ca b mu xanh decode ra l ra hnh trn Th th mt ci im  lng chng ngay chnh gia trn v tam gic th chng ta thy ci hnh ny n u c ci  ngha kh l ph hp ng khng? l ci hnh ny n s c ci bo trn ging nh ci hnh trn Nhng ng thi n s c ci nt thng, 3 ci nt thng Ging nh tam gic , th ci im trung im ny n s ging ging, n s gip chng ta to ra ci tnh gi l ci tnh lin tc V ng thi n cng c  ngha, n cng c  ngha ch khng phi l khng Nu m ci  gia ny m n ra mt ci im no  m chng ta khng th gii thch c th  l khng c  ngha Ri khi chng ta tin cng gn hn v ci tm th chng ta thy l ci tam gic n bt bo trn i ng khng?'), Document(metadata={'filename': 'Ds8mbsbarxs', 'video_url': 'https://youtube.com/watch?v=Ds8mbsbarxs', 'start_timestamp': '0:06:49'}, page_content='V input ca n chnh l ci hidden  pha trc. Ri, by gi chng ta s ng gi c ci ny vo trong ci bin l model. V chng ta s tr v cho cell.model.  y th chng ta s khng cn phi return ci g ra bn ngoi. Ri, tng t nh vy  y chng ta s c optimizer s l bng tf.keras.optimizer.stochastic gradient descent Vi learning rate l bng 0.1  train cho n nhanh. V  y chng ta s c s dng momentum'), Document(metadata={'start_timestamp': '0:15:35', 'chunk_id': 15, 'title': '[CS315 - Chng 3] Deep Generative Models (2) - Part 4', 'end_timestamp': '0:16:16', 'filename': 'NJVpvCzceRk', 'video_url': 'https://youtube.com/watch?v=NJVpvCzceRk'}, page_content='Th y chnh l ci thnh phn regularization. Ri, v thnh phn cui cng,  chnh l ci k vng ny. Ri, chy t chy t 1 cho n T ln. Th ci  ngha ca ci tng k vng ny  l ci s consistency. L ci consistency, tc l ci s nht qun gia ci k vng ca ci hm chng ta denoise, gii m, chng ta kh nhiu. Vi li ci phn b ca q XT, XT t 1.'), Document(metadata={'filename': 'DSmR6JSwx5I', 'video_url': 'https://youtube.com/watch?v=DSmR6JSwx5I', 'start_timestamp': '0:06:26'}, page_content='Vy th vi ci o hm ny m bng 0.25 th iu g xy ra? Vi ci cng thc o hm ca G theo theta y, n c n s xut hin ca o hm sigmoid n 10 ln. Tc l ngoi cc thnh phn kia th chng ta s thy l thnh phn o hm sigmoid s b hn hoc bng 0.25. Vy l 0.25 l m 10. Ri xong  nhn vi ci thnh phn o hm cn li. Vy th by gi chng ta s xem xt ci 0.25 m 10 ny nu chng ta ly my tnh bm th n s xp x l bng 0. N l 1 con s rt l b.'), Document(metadata={'filename': 'CtOfKuiy_uc', 'title': '[CS315 - Chng 1] M hnh hc my da trn Gradient (Phn 3)', 'end_timestamp': '0:04:33', 'start_timestamp': '0:04:00', 'chunk_id': 4, 'video_url': 'https://youtube.com/watch?v=CtOfKuiy_uc'}, page_content='Mt mu random. Ci bin th tip theo  chnh l mini-batch gradient descent hay vit tt l MGD. Th chng ta thay v truyn vo mt mu, th chng ta s truyn vo mt khi hay batch. Ci mu hun luyn. V ci batch size  y, ci kch thc ca ci mu, kch thc ca ci khi l vit tt ca ch batch size. y l kch thc ca khi.'), Document(metadata={'filename': 'peYaH97QeEw', 'video_url': 'https://youtube.com/watch?v=peYaH97QeEw', 'start_timestamp': '0:02:23'}, page_content=' th hai l mt iu rt quan trng, mt vector z phi nm  gn z trong khng gian latent space Khi chng ta decoder ra th liu c g m bo rng nh m chng ta qua decoder phi c tnh cht g  ging vi vector z  y khng? Ti v hai vector biu din z v z phi  trong khng gian ca mnh nm gn nhau, chng ta k vng ci s gii m ra c l ging nh s 3 Ch khng th no nu vector z phi gn z, nhng nu chng ta decode m n ra s 7 chng hn Th y l iu m chng ta khng mong mun. Chng ta mong mun l z phi gn z, th khi decode n phi ra con s ging vi con s z ny Th  mi ng l mt ci khng gian latent. Vi autoencoder n khng c m bo c ci chuyn  Nu nh vector z sau khi ti  encode, th khi ti decode n s ra li ng nh ban u N thiu i mt tnh cht chn v tnh lin quan trong khng gian ca mnh.  l nhng im gn nhau s c cng mt  ngha ging nhau V  chnh l im yu ca autoencoder v variational autoencoder s tm cch gii quyt ci vn  ny  l thay v vi mi mt ci nh khi chng ta encode th cng c mt ci module l encode  l trong khng gian latent. Tuy nhin thay v chng ta nh x sang mt im c nh ging nh trong autoencoder Th  y ci m chng ta s nh x sang  chnh l mt distribution, mt ci phn b Th th ti sao li l phn b m khng phi l mt im c nh? Ti v nu chng ta nh x sang mt im c nh Th n s d khin ci m hnh ca mnh l hc thuc ci v tr, tc l c nh  th v tr , nh  th v tr  M n khng c ci tnh cht tng qut.'), Document(metadata={'end_timestamp': '0:06:52', 'title': '[CS315 - Chng 1] Gradient based model - Phn 10 - Part 3 (New)', 'filename': 'm19884tczqs', 'video_url': 'https://youtube.com/watch?v=m19884tczqs', 'start_timestamp': '0:06:27', 'chunk_id': 6}, page_content='Do  n s chia ci khng gian ca mnh ra. Chia ci khng gian ca mnh ra. V d vy thnh 4 phn v vi mi mt ci im th n s thuc vo mt phn ch n khng c thuc vo hai ci phn. Gy ra ci s nhp nhng ging nh trong ci m hnh logistic regression.'), Document(metadata={'filename': 'yPzXzbEhUW0', 'video_url': 'https://youtube.com/watch?v=yPzXzbEhUW0', 'start_timestamp': '0:03:53'}, page_content='Sau  th chng ta s cu hnh. V d nh  y chng ta s chn ci ng dn nh n ci th mc hin ti. Th ci th mc hin ti l, chng ta xem ci th mc g ha? Th l Content. Do  ci DataDir chng ta s  l Content. Ri,  hin gi th cha c hnh. Chng ta s ti cc ci hnh ny v. Th  y ti c chun b sn 3 ci tm hnh. V d y l cho bn ha.'), Document(metadata={'video_url': 'https://youtube.com/watch?v=HWWlm40wQ-s', 'end_timestamp': '0:08:43', 'chunk_id': 6, 'filename': 'HWWlm40wQ-s', 'title': '[CS315 - Chng 1] M hnh hc my da trn Gradient (Phn 4)', 'start_timestamp': '0:07:53'}, page_content='Nhng tuy nhin mc d l n hi t chm nhng m b li l n s u tin hi t v nhng im cc tiu tt hay gi l generalization minimum do yu t ngu nhin. Ti sao li nh vy? Th chng ta tham kho mt ci bi bo v On-Large Batch Training for Deep Learning.  y s xut hin hai khi nim  l flat minimum v sharp minimum. Flat minimum l chng ta thy l y l mt im cc tiu. Tuy nhin n s rng. Ci khu vc ny chng ta thy l n s rt rng.'), Document(metadata={'filename': 'iQqNUKgIZpc', 'video_url': 'https://youtube.com/watch?v=iQqNUKgIZpc', 'start_timestamp': '0:04:33'}, page_content='Th y l ci thao tc bin i mt cch tun t. V chng ta k hiu n l hx. Th nu nh chng ta dng mt ci kin trc mng bnh thng nh th ny, m khng c ci kt ni tt, kt ni tt l g th chng ta s ni trong slide tip theo. Nhng m vi ci kin trc thng l ny, th khi tc gi ca ci bi bo l Deep Residual Learning for Image Recognition, bi ny l vit tt ca ci kin trc mng l ResNet, l tc gi Kaming Hair, th khi chng ta tng s layer ln t 20 ln 32 ln 46 ln 56, th ci gi tr loss ca mnh n li cng lc cng cao. Khi m tng layer ln th n li i hi t chm.'), Document(metadata={'chunk_id': 6, 'end_timestamp': '0:10:19', 'filename': 'HKbzvh4rDw0', 'start_timestamp': '0:08:55', 'title': '[CS315 - Chng 2] Xu hng chung ca CNN', 'video_url': 'https://youtube.com/watch?v=HKbzvh4rDw0'}, page_content='Vy th CNN th sao? Vi mi mt ci lt ct  y, vi nh d liu u vo, chng ta thy  y s c 3 chiu. Trong  chiu ngang v chiu dc chnh l chiu khng gian l width v height. y l hai chiu khng gian. Cn chiu ny s l chiu  su d. y chnh l chiu ca c trng. Ri, tc l s lng c trng ca mnh. V d trong ci feature map  y, th mi mt ci lt ct  y n s l mt ci c trng ca ci input u vo. Trn hnh chng ta thy l mt ci vng mu en, th y s l mt ci feature. V feature ny l ca mt ci lt ct u tin. Chng ta s c rt nhiu nhng ci lt ct. V vi mi ci lt ct ny, n s l mt ci feature, mt ci c trng. Th nhiu ci c trng chng ta tng hp li, th n s gip cho chng ta c ci gc nhn a chiu v i tng ca mnh.'), Document(metadata={'filename': '--6FInuIyys', 'video_url': 'https://youtube.com/watch?v=--6FInuIyys', 'start_timestamp': '0:05:27'}, page_content='Th chng ta s i tt nh th ny. i tt n n m khng qua cc ci bc trung gian. V ci  chnh xc, ci cht lng ca hnh nh vn rt l tt, tng ng vi nhng trng thi ban u. V tng t nh vy cho ci m hnh consistency l c kt hp vi c Latent Diffusion.  m cho ci cht lng va tt m tc  va nhanh, th trn y  l chng ta  tng kt nhng ci g  hc trong phn cc m hnh to sinh hc su. Tm bit.'), Document(metadata={'video_url': 'https://youtube.com/watch?v=N6F7elExenE', 'filename': 'N6F7elExenE', 'end_timestamp': '0:09:55', 'chunk_id': 7, 'title': '[CS315 - Chng 3] Deep Generative Models (1) - Part 5 (Phn 2)', 'start_timestamp': '0:08:47'}, page_content='y l phn phi d liu mc tiu. V khi chng ta sampling mt ci im khc  pha di y, th qua ci hm G chng ta c hnh mt ci con chim nh th ny. V n nm  y. Th th khi chng ta di chuyn t ci im  trn xung di ci im  di, c ln lt vi mi im chng ta ly mu, th chng ta qua ci hm G th chng ta cng s c cc ci mu d liu. V khi chng ta v cc ci mu d liu ny ln th chng ta thy l c mt ci s dch chuyn mt m t ci nh con ngng mu en sang ci con chim mu cam ny. Th chng ta t tri sang phi th cng ging nh l chng ta ly mu t trn xung di vi mi im trong ci khng gian latent, chng ta qua generator, chng ta to ra mt tm nh. Th chng ta thy l dn dn ci con ngng mu en ny, ci u ca mnh n hng v pha bn y, th n dn dn l ci u n s khng r hng, ri sau  qua y s l hng v bn tay tri.'), Document(metadata={'filename': 'Qj6HkeNtIuI', 'video_url': 'https://youtube.com/watch?v=Qj6HkeNtIuI', 'start_timestamp': '0:00:14'}, page_content='Chng ta s cng n vi vn  u tin m chng ta cn phi gii quyt,  chnh l vn  v overfitting. Th overfitting khng phi l mt vn  ring ca lnh vc hc su m  l mt vn  chung ca mi m hnh my hc. Th th overfitting l g, nguyn l ca n ra sao, nguyn nhn l g v gii php l g th chng ta s cng tm hiu trong phn ny. u tin khi ni v hin tng overfitting th chng ta s phi nhc n ci vn   l ci m hnh ca mnh. N d on rt l tt trn tp Train nhng n li rt l t trn tp Test. Th ci ny c mt s biu hin mang tnh cht nh lng, v d nh l trn tp Train chng ta hun luyn xong chng ta dng chnh tp Train  chng ta nh gi, th ci  chnh xc ca mnh n c th ln n 80% v d vy. Nhng khi chng ta Test trn tp D liu Test th  chnh xc ca mnh n rt xung rt l ng k. V d nu m n khong 75% th ok l ci m hnh ca mnh tng i tt v n s khng c qu b hin tng Overfitting. Tuy nhin nu ci  chnh xc trn tp Test ca mnh m ch cn c khong 60% th n  c mt s gim ng k t 80% xung 60%. V vy ci tnh hung ny  l hin tng Overfitting. Th y l mt ci v d mang tnh cht nh lng  gip chng ta hnh dung v ci hin tng ny. Th th nu xt v gii thch th chng ta c rt nhiu nhng ci cch thc  gii thch cho ci hin tng Overfitting. Th y l mt ci m hnh n rt l phc tp v d liu khng  nhiu. Th y l mt ci cch gii thch cho ci nguyn nhn ca hin tng Overfitting m cc bn thy ph bin nht khi chng ta c cc ti liu trn cc bi bo khoa hc hoc l trn ngun internet. Hoc l mt ci cch gii thch khc  l hin tng Overfitting l ci hin tng m m hnh ca mnh n s tm cch  m hc thuc cc mu d liu Train thay v l chng ta tng qut ha ln.  sao cho sau ny khi c mt ci d liu mi th nh c tnh cht tng qut ha ny n c th d dng x l c trn nhng ci d liu mi.'), Document(metadata={'chunk_id': 4, 'title': '[CS315 - Chng 3] Deep Generative Models (1) - Part 4', 'filename': '-2bJ_8EO9ZE', 'video_url': 'https://youtube.com/watch?v=-2bJ_8EO9ZE', 'end_timestamp': '0:06:35', 'start_timestamp': '0:04:31'}, page_content='Ri , tc l chng ta s tch tng phn t. Th ti sao chng ta li dng element y? Ti v mi v sigma  l nhng ci vector, v d nh l vector d chiu. Sigma cng l mt ci vector d chiu. Th epsilon ca mnh n cng s thuc mt ci vector d chiu.  l mt ci vector nhiu d chiu. Trong  tng ci chiu ca sigma, xe gi tng ci chiu ca epsilon, th s l mt ci vector, l mt ci gi tr c sampling theo phn b chun 0,1. Th khi chng ta dng ci cng thc ny l z bng mi cng cho sigma nhn tch tng phn t vi epsilon, th khi  expectation ca z ca chng ta n ng l bng mi lun. V variance ca z cng ng l bng sigma. Th y chnh l ci tnh cht m ti tham s ha, tc l thay v chng ta s dng mt ci lp sampling layer l ly mu z theo ci bin, theo ci phn b Gaussian mi sigma bnh, th chng ta i ly mu, i sampling ci ny. Chng ta s i sampling epsilon. Cn cc gi tr mi v sigma ny l c nh, l tt nh, c tnh ton t encoder. Th khi  l chng ta s khng c b ci hin tng gi l lan truyn ngc, n khng c i c.'), Document(metadata={'filename': 'FMhXMbROI-o', 'video_url': 'https://youtube.com/watch?v=FMhXMbROI-o', 'start_timestamp': '0:00:14'}, page_content='Chng ta s cng n vi vn  th 2 khi hun luyn vi mt m hnh hc su  chnh l Vanishing-Gradient. Nu nh ci vn  v overfitting hay l qu khp vi d liu th n rt tng qut cho cc m hnh my hc. Mi m hnh my hc u s gp nhng vn  v overfitting. Cn vn  v Vanishing-Gradient th thng ch dnh cho cc m hnh hc su. Vy th c ch ca ci hin tng Vanishing-Gradient l g v lm sao  khc phc c vn  ny? Chng ta s cng n trong nhng phn tip theo.'), Document(metadata={'start_timestamp': '0:16:42', 'chunk_id': 10, 'end_timestamp': '0:17:20', 'filename': 'NEK5lIyST0M', 'video_url': 'https://youtube.com/watch?v=NEK5lIyST0M', 'title': '[CS315 - Chng 1] M hnh hc my da trn Gradient (Phn 10)'}, page_content='Ci ng nh th ny n s tch ra lm 4 phn th n s khng c tnh trng 1 im th n s khng thuc v ci phn no. V d nh vi 1 im  y th chng ta da trn ci ng phn bin ny chng ta s bit n s thuc v ci lp xanh l. Ri ci im  y th n s thuc v ci lp mu vng. Th  chnh l hi quy softmax.'), Document(metadata={'filename': '5Wpw2EsSz40', 'video_url': 'https://youtube.com/watch?v=5Wpw2EsSz40', 'start_timestamp': '0:12:16'}, page_content='y l mt k thut rt l ni ting v n n gin. N rt l n gin. Ti v n d thc hin. Nhng m ci g n gin th n s c ci mt hn ch ca n,  l ci chi ph cao. Ci chi ph n cao. Nu chng ta thu thp bng tay th c th chng ta s phi tn ci chi ph  thu ngi gn nhn. Trong hai ci lnh vc x l hnh nh v vn bn, chng ta c hai ci k thut tng cng d liu. Mt  l i vi hnh nh th chng ta c th s dng cc php bin i. V d nh l thay i ci texture, gim bt ci texture ca i tng i, loi b i ci yu t mu sc  ra ci nh mc xm. Ri chng ta tng cng ci bin cnh ln.'), Document(metadata={'chunk_id': 9, 'video_url': 'https://youtube.com/watch?v=fiDM76zR6UY', 'title': '[CS315 - Chng 3] Tutorial - GAN', 'end_timestamp': '0:09:38', 'filename': 'fiDM76zR6UY', 'start_timestamp': '0:08:13'}, page_content='Label real th s c nhn l 1 v label fake th s c nhn l 0. Sau  th chng ta s fix ci noise ca mnh. L ci random noise l t... l 64 v kch thc  l 100. Epoch l 10. Th  y chng ta s ln lt hun luyn. Step s 1 l chng ta s i ti u Discriminator trc. Tc l hun luyn cho b phn loi ny c kh nng phn loi c nh tht v nh gi trc. Sau  chng ta mi sang Step s 2  i hun luyn cho Generator. Ri, th  y chng ta s ly ra ci Xreel v truyn vo GPU. Ri sau  chng ta s khi to ci optimizer D. V chng ta s truyn ci Xreel ny vo ci Discriminator. Th y chnh l ci xc sut. y chnh l ci xc sut thuc v lp Reel. V lossD ca Reel tc l ci gi tr loss cho ci Discriminator. i vi ci phn d liu Reel l d liu tht th chng ta s truyn vo ci gi tr d on v ci nhn ca mnh l label Reel. Th mc tiu l lm sao cho ci gi tr ny l nh nht.'), Document(metadata={'filename': '-2bJ_8EO9ZE', 'video_url': 'https://youtube.com/watch?v=-2bJ_8EO9ZE', 'start_timestamp': '0:08:07'}, page_content='Nn n s khng nh hng g n ci qu trnh hun luyn ca mnh. Ci qu trnh hun luyn ca mnh  l khi chng ta tnh c ci loss  pha trn, chng ta lan truyn xung, v n y th chng ta gp ci z. V z ny th hon ton l mt ci node deterministic, tc l mt ci node tt nh, tc l khng c yu t ngu nhin. N s c tnh t mi v sigma, c tnh ton t phi v x. Qua ci bc encode, chng ta s c c mt ci cp mi v sigma c nh. Cn epsilon  y l mt ci gi tr chng ta truyn vo z. Th c ci gi tr ny, chng ta nhn vi mi, chng ta nhn vi sigma, v sau  cng vi mi th n s ra mt node tng ng. Vi ci vic l z ca mnh tun theo mt ci phn b l Gaussian.'), Document(metadata={'video_url': 'https://youtube.com/watch?v=_HLKpylxwMw', 'end_timestamp': '0:12:25', 'title': '[CS315 - Chng 0] Gii thiu mn hc (Phn 2)', 'filename': '_HLKpylxwMw', 'chunk_id': 12, 'start_timestamp': '0:11:09'}, page_content='Chuyn khng gian. V d nh chng ta c mt ci khng gian l nh th ny. V mt ci im trong ci khng gian th khi chng ta chiu xung di mt ci mt phng no , v d vy. Ri, th khi chng ta chiu xung,  i din cho ci mt phng ny, i din cho ci mt phng ny, mt phng P i, th n s c ci tham s v tham s  chnh l ci ma trn A ca mnh. V khi chiu, khi chiu xung ci khng gian ca A th chng ta s chuyn t mt ci vector l 3 chiu, V d vy, thuc R3, chuyn xung mt ci khng gian 2 chiu th lc  l chng ta ch cn l mt ci im kch si, nhng m nm trong ci khng gian ch c 2 chiu, ch khng gian mt phng.  y l mt ci php chiu t mt ci khng gian ln chiu l 3 chiu xung mt ci khng gian mt phng l 2 chiu. V ngc li, chng ta cng s c ci php chiu t khng gian thp chiu ln khng gian cao chiu.'), Document(metadata={'filename': 'iQqNUKgIZpc', 'video_url': 'https://youtube.com/watch?v=iQqNUKgIZpc', 'start_timestamp': '0:01:39'}, page_content='Hoc l c th lc n s l s rt b nhng m cng c th l s ln, n s phi dao ng xung quanh con s mt. Cn vi hm sigmoid th cho d l hm kch hot c o hm nh, cho d l hm ca mnh n c kin trc g i chng na, th sigmoid ca x lun lun l con s b hn mt. Trong khi  chng ta khng c dng ci hm ny, khng dng hm sigmoid na, m chng ta dng hm relu. Th o hm ca hm relu ny th n s l bng 0. Nu z b hn 0 v bng 1 nu z ln hn 0, th ci vic ny n s gip chng ta cn bng. V chng ta lu   l khng phi lc no z khi chng ta gi hm activation function, th ci gi tr chng ta truyn v l u b hn 0, n s c lc b hn 0, c lc ln hn 0, do  n to ra s hi ha v s cn bng cho mnh.  l ci biu hin ca tnh cn bng, l th hin cho .'), Document(metadata={'chunk_id': 4, 'video_url': 'https://youtube.com/watch?v=NqnUZDkYvM0', 'title': '[CS315 - Chng 1] M hnh hc my da trn Gradient (Phn 11)', 'filename': 'NqnUZDkYvM0', 'start_timestamp': '0:04:17', 'end_timestamp': '0:04:59'}, page_content='Lm 2 phn.  l ci vng mu tam gic v hnh trn. Th y chnh l ci  tng ti sao mt ci mng Neural Network c th gii quyt c mt ci bi ton phi tuyn tnh. L nh cc ci c trng, cc ci b phn lp yu  cc lp u tin t hp li vi nhau  to ra cc ci c trng cp gia, tc l c trng cp va.'), Document(metadata={'filename': 'FMhXMbROI-o', 'video_url': 'https://youtube.com/watch?v=FMhXMbROI-o', 'start_timestamp': '0:09:35'}, page_content='Do  th cc ci tham s cng xa th n cng d b tiu bin. V th th nu m ci o hm ca G theo thetaG m n tiu bin, tc l n s tin v 0, th vn  g xy ra? Chng ta phi quay tr li ci cng thc cp nht tham s ca thut ton Gradient Descent,  l thetaG, th s l bng thetaG tr cho alpha nhn cho o hm ca G theo thetaG. V ci i lng m o hm  y xp x 0 nn alpha nhn vi n s xp x 0, alpha l mt con s cn nh hn 1 na, n c th l 0.001 na, v cng nh hn. Th th ci con s ny s cng tin v 0, th th thetaI bng thetaI tr 0, tc l xp x vi li con s thetaI hay ni ci khc thetaI khng cp nht, tc l gn nh khng cp nht. Th n gii thch cho ci hin tng  l hi t chm, ti v n khng c cp nht tham s th ly u m n hi t?'), Document(metadata={'chunk_id': 1, 'end_timestamp': '0:17:32', 'title': '[CS315 - Chng 1] Gradient based model - Phn 1 (New)', 'start_timestamp': '0:07:45', 'filename': 'QZrUqMbEY8Q', 'video_url': 'https://youtube.com/watch?v=QZrUqMbEY8Q'}, page_content='Th li m nh nht l ci d on cng chnh xc Tip theo th chng ta s cng so snh vi cc ci m hnh khc, th mt s m hnh m khng c da trn Gradient, v d nh chng ta c K-Nearest Neighbor Mc d y l mt ci thut ton my hc nhng m n khng thc s l hun luyn v bn cht ca n ch l truy vn  tm ra k ci lng ging gn nht V sau  s da trn nhn ca k ci lng ging   t  n dng ci c ch  gi l voting  m ly ra nhng ci tp nhn m c xut hin nhiu nht  t  gn ci nhn nhiu nht  vo cho ci c trng ca mnh Th y chnh l ci  tng ca K-Nearest Neighbor. Hng tip cn th 2  chnh l Naive Bayes, th y l da trn cc ci m hnh xc sut m c th  l chng ta da trn cng thc xc sut c iu kin nh l cng thc Bayes Th c lng ci phng php ny th n s c lng cc ci tham s mt cch tng minh Cch tip cn th 3  chnh l Decision Tree vi cc thut ton v d nh l CART, ID3, C4.5 th n da trn lut  phn chia thnh cc ci nhnh quyt nh V d nh  y chng ta s c mt ci node, n s chia ra lm 2, 2 nhnh v d vy ri sau  chng ta li tip tc c nhng ci lut, n s c nhng ci lut li tip tc chia xung V d nh  trn y, ci lut ca mnh s l tri c my hay khng, th nu c th n s tip tc hi l ci  m ca mnh l cao hay thp Nu m  m cao th n s kt lun l ma, v d vy, th y l mt ci m hnh kh l hiu qu v d hiu V m rng cho ci m hnh Decision Tree  chnh l Random Forest th nh ci tn gi ca mnh, Random Forest n s kt hp nhiu ci cy thnh phn V d nh  y chng ta c mt cy th Random Forest c th kt hp thm nhiu ci cy khc  c th to ra thnh mt ci khu rng V Random Forest l mt trong nhng thut ton, mt ci m hnh m c th chng c ci Overfitting v c ci tnh tng qut kh l cao  chng ta chn c ci tham s ph hp Th th c 4 ci m hnh ny u l nm trong ci nhm  l hc c gim st V thut ton khng gim st th chng ta s c cc thut ton lin quan n ci Clustering V d nh l c K-Means, DBscan, Hierarchical Clustering, th  tng ca cc thut ton ny cng l nhng thut ton lp vic cp nht tm cm Tc l chng ta s lp i lp li vic cp nht tm cm V khc bit so vi cc m hnh da trn Gradient  l chng ta khng tnh ci Vector o hm, khng da trn Gradient V trong ci bng sau th chng ta s so snh cc m hnh trn cc kha cnh khc nhau Kha cnh u tin  l ci c ch  ti u ha m hnh ca mnh Th cc thut ton da trn Gradient th u da trn thut ton Gradient Ascent V cc bin th ca n, v d nh Stochastic Gradient Ascent, Adam, Root Mean Square Propagation th y u l nhng ci thut ton ti u ha V cc m hnh da trn Gradient th u da trn cc thut ton ny Trong khi  cc m hnh khng da trn Gradient, th c ch  ti u ha da trn mt cng thc tng minh hoc da trn cc chin thut tham lam, heuristic, v d nh l Naive Bayes, Decision Tree, K-Nearest Neighbor Xt trn kha cnh v kh nng din gii m hnh th cc m hnh da trn Gradient th thng c tnh din gii kh l thp hay mt ci cch gi khc  l thng c dng Black Box, hp en th kh nng din gii ca mnh l s thp Tuy nhin cc nghin cu gn y th h cng  tm cch trc quan ha m hnh da trn Gradient n vn hnh nh th no, ri gii thch c ch ca n  lm sao cho m hnh c th ti u ha c vic m d on th cc nghin cu  gn y cng c ch tm rt nhiu Trong khi  th m hnh khng da trn Gradient th n c tnh gii thch d dng hn v c bit l nhng m hnh nh l Decision Tree, Random Forest chng ta nhn v ci cu trc cy thi l chng ta c th hiu c m hnh vn hnh nh th no Xt trn ci hiu qu ca cc tc v phc tp th thut ton cc m hnh da trn Gradient th n s cho kt qu rt tt trn nhng lnh vc nh l th gic my tnh hoc l x l ngn ng t nhin trong  l trn nhng d liu l Unstructured Data v d nh l d liu hnh nh, d liu vn bn, ri d liu m thanh v th y l nhng d liu m hnh da trn Gradient lm vic rt tt trong khi  m hnh khng da trn Gradient th thng tt trn d liu bng v c quy m nh v d nh l d liu bng th n bao gm cc ct ABC v tng ci ct ny th n s c kiu d liu c nh v  ngha ca n l c nh cc m hnh khng da trn Gradient th lm vic rt tt trn d liu ny  l nhng d liu Structured Data v cui cng  l xt trn kha cnh chi ph hun luyn cc m hnh da trn Gradient th thng c chi ph hun luyn rt cao do n cn rt nhiu ti nguyn tnh ton, b nh, GPU, TPU do cc m hnh da trn Gradient c s lng tham s rt ln ngc li th chi ph hun luyn ca cc m hnh khng da trn Gradient th t tn km hn nh vy chng ta  lt qua nhng kha cnh v chng ta thy m hnh da trn Gradient n c nhng im yu c hu v d nh l m hnh ca mnh kh nng din gii s thp hn so vi nhng m hnh nh l Decision Tree v chi ph hun luyn ca n s cao hn tuy nhin gn y th ti sao m hnh da trn Gradient li cng tr nn ph bin n c nhiu l do, l do u tin  l di s pht trin ca cc mng x hi th cc d liu ca mnh s ngy cng phong ph hn v c lu tr cng khai th  giai on u, v d nh l vo nhng nm 2010, th ci quy m d liu ca chng ta u  ch khong l 1-2 triu nh nhng m sau  n vo nhng nm 2020, c th  l cng ty OpenAI c u t th h xy dng nhng m hnh v d nh m hnh clip c hun luyn trn tp d liu rt ln ln n hng trm triu mu d liu v gn y hn na th vo nhng nm 2020, th c tp d liu LAION ln n 5 t nh th c th ni l  hun luyn c trn nhng quy m d liu ln hng t nh th ch c th c tp on cng ngh ln h mi c th lm c m thi v mt trong nhng l do na  khin m hnh da trn Gradient cng tr nn ph bin  l ti nguyn ca mnh ti nguyn c th l ti nguyn tnh ton, n ngy cng mnh v ng thi n s ngy cng r th ni v phn cng th n s cng cng r v nh c ti nguyn tnh ton sp sau ny, n s gip chng ta hun luyn cc m hnh nhanh chng hn cui cng  l s hon thin ca cc m hnh chng ta thy  l trc y th chng ta c ci mng Neural Network th n khng c hiu qu trong vic hun luyn vi cc d liu ln v cc bi ton phc tp nhng m gn y th chng ta thy l c ci kin trc nh l CNN, RNN, Convolutional Neural Network, Recurrent Neural Network v gn y nht chnh l Transformer,  l nhng ci kin trc  hon thin hn gip chng ta c th hp th c lng d liu tt hn v c th khai thc c hiu qu ti nguyn ca GPU do  th cc m hnh da trn Gradient ang ngy cng tr nn ph bin v khng ch nh vy m cc thnh tu mi nht ca tr tu nhn to gn y v d nh l ChatGPT, Gemini, chng ta thy  l u c kin trc da trn Transformer v ci kin trc da trn Transformer ny,  l da trn,  u c hun luyn da trn thut ton,  l Gradient Descent th y chnh l mt ci v d minh chng cho ci thnh tu ca cc m hnh da trn Gradient Cm n cc bn  xem video hp dn'), Document(metadata={'filename': '2NThga7SQ-I', 'video_url': 'https://youtube.com/watch?v=2NThga7SQ-I', 'start_timestamp': '0:05:36'}, page_content='V tt c cc phn t cn li s  l s 0. V tng t nh vy cho s 2 i, th n s bt ln l 0,  y l 0,  y l 0 v n s bt ln  y. V tt c cc phn t cn li s  l s 0. Th y l ci dng One Hot Encoding. Ri bc tip theo,  l chng ta s tin hnh ci t ci thut ton hun luyn hay c th  l ci t ci m hnh. Th ci mng CNN,  y chng ta s c cc phng thc nh l Build, Train, Constructor, Load, Get Weights.  y c cc phng thc Get Weights l chng ta s cha ci t, chng ta s ci t  a ln Train song hnh cng vi li hm Train  ko chng ta qun. Xin li, chng ta s a ln Train ngang vi li phng thc l Build  khng mt cht na chng ta s qun. Ci qu trnh Train ca mng CNN rt l lu, nu m chng ta qun thc hin ci g y v chng ta thc hin li th n s tn thi gian rt l nhiu. Th  y chng ta s phi cho ci model n bit  l Input Dimension. Ri, ng thi l cc cu hnh, v d nh s lng filter l 6, s lng filter l 16, ri s cc output ca cc lp Fully Connected l 120, 84. Th chng ta s phi tham s ha 4 ci b s ny.'), Document(metadata={'start_timestamp': '0:00:14', 'end_timestamp': '0:01:01', 'chunk_id': 0, 'title': '[CS315 - Chng 2] Xu hng chung ca CNN', 'video_url': 'https://youtube.com/watch?v=HKbzvh4rDw0', 'filename': 'HKbzvh4rDw0'}, page_content='Chng ta s cng vn dng nhng l thuyt v balancing gradient v overfitting  c tm hiu  nhng phn trc  l gii cho s tin ha ca cc mng CNN. Cc mng CNN  y s c kho st t giai on mi bt u c  tng ca mng CNN cho n nhng mng CNN hin i hn. u tin  chnh l m hnh Logistic Regression hay l mt ci Perceptron n gin.  y chng ta thy mng ca chng ta ch c duy nht mt node, duy nht mt neuron. V  ngha ca m hnh ny l n s phn chia khng gian c trng ra, lm thnh mt mt phng.'), Document(metadata={'filename': 'HWWlm40wQ-s', 'video_url': 'https://youtube.com/watch?v=HWWlm40wQ-s', 'start_timestamp': '0:01:33'}, page_content='Th nhng ci chng ngi  l g v ti sao nhng ci im  n li gy ra ci vic hun luyn kh khn, th chng ta s cng ly mt s v d. Ci chng ngi u tin  l nhng ci im cc tiu cc b hay cn gi l local minimum. V vy, gi s nh chng ta bt u ti ci im  y, th trong ci qu trnh di chuyn, nu nh hon ho, th chng ta s t c ci im ny,  l ci im global minimum. Nhng m thc t th khng phi vy. N hon ton c kh nng l trong qu trnh di chuyn, n c th rt vo mt ci im  ci im  y, tc l tng ng  y. V y chnh l mt ci im local minimum. V khi chng ta rt vo ci im  y, th n s b bt kt v n s khng thot ra c,  m c th n c ci im ti u ton cc. Ci tnh hung th hai  l ci im yn nga. Th im yn nga l nhng ci im c bit. Ly v d  y. im yn nga th n s c ci o hm bng khng ti ci v tr , v n s o hm bng khng ti nhiu hng. V d nh l theo ci hng ny, chng ta thy l n i xung ri i ln, th ti ci v tr ny l o hm bng khng.'), Document(metadata={'filename': 'NJVpvCzceRk', 'chunk_id': 10, 'title': '[CS315 - Chng 3] Deep Generative Models (2) - Part 4', 'end_timestamp': '0:12:37', 'video_url': 'https://youtube.com/watch?v=NJVpvCzceRk', 'start_timestamp': '0:11:16'}, page_content='Hay chng ta bit gi l trin khai.  l bng epsilon ca cn ca ci v bn tay tri l alpha 2 tr cho alpha 1 alpha 2. Ri cng cho 1 tr cho alpha 2. Th y l mt ci cng thc m kh l kinh in ca ci vic m chng ta cng 2 ci bin ngu nhin theo phn b chun. Th th tr alpha 2 cng alpha 2 l mt do  th chng ta s cn l 1 tr alpha 1 alpha 2 epsilon. V mt cch tng t th ci xt bt k n s c tnh di t ci x0 v mt ci bin epsilon theo phn b chun. V cng thc ca n s l nh y. Th th alpha  y s l alpha gch ngang trn u.  cng thc ca ci alpha t gch ngang trn u. Nu m vit trin khai ra th alpha gch ngang t s bng alpha 1 alpha 2... cho n alpha t. V epsilon  y th vn l mt ci bin ngu nhin theo phn b chun. Th ci cng thc ny chng ta thy kh l gn.'), Document(metadata={'start_timestamp': '0:14:40', 'title': '[CS315 - Chng 3] Deep Generative Models (1) - Part 1', 'video_url': 'https://youtube.com/watch?v=hrxNKadDpw4', 'filename': 'hrxNKadDpw4', 'chunk_id': 15, 'end_timestamp': '0:15:14'}, page_content='Th  y chng ta s dn nhp, gii thch ci  ny. Cc ci m hnh ca mnh khi c hun luyn th ly d liu  trong thc t m d liu chng ta sampling trong thc t th 95% Chng ta ly mt ci v d  l d liu m li xe trn ng. 95% d liu m chng ta li xe, tc l n nm  trong ci khu vc ny. L trong ci khu vc ny.'), Document(metadata={'start_timestamp': '0:14:38', 'end_timestamp': '0:15:06', 'filename': 'HWWlm40wQ-s', 'chunk_id': 10, 'video_url': 'https://youtube.com/watch?v=HWWlm40wQ-s', 'title': '[CS315 - Chng 1] M hnh hc my da trn Gradient (Phn 4)'}, page_content='Th  y  chnh l ci hin tng c ci  dc bt thng.  y chng ta thy l c ci  dc i xung n, nhng ngay lp tc n li i ln. Ngay lp tc n li i ln th  chnh l ci s bt thng. Th nhng ci, y chnh l nhng ci vng m c ci s thay i ln v  dc theo cc ci chiu, theo cc ci chiu.'), Document(metadata={'chunk_id': 17, 'video_url': 'https://youtube.com/watch?v=-7JWQptLoMQ', 'start_timestamp': '0:19:31', 'title': '[CS315 - Chng 2] S tin ha ca cc m hnh chui (Phn 1)', 'end_timestamp': '0:20:56', 'filename': '-7JWQptLoMQ'}, page_content='Cn cha c nhiu ti liu ni l khi chng ta dng thm nhiu hn na, v d nh l hng chc hoc hng trm lp. Thng l t 2 cho n 4 lp. Ring trong Transformer th c th l vi d liu phc tp hn, bi ton thch thc hn, th c th l s lp ca mnh s cao hn. Th th chng ta  hc v Bi-directional v DeepStack, do  chng ta cng s c mt hn hp ca hai bin th ny.  l va Bi-directional, tc l i theo chiu t tri sang phi, nhng ng thi cng s c chiu i t phi sang tri, thng qua du mi tn nt t ny. V n s stack ln nhiu tng, th y s l layer 1, y l layer 2 v y l layer 3. N s kt hp va 2 chiu v va DeepStack  tn dng c th mnh ca tng ci bin th ca mnh.  l th nht, c c nhiu chiu, ci th 2, c trng ca mnh s phn cp tt hn, c nhiu thng tin hn. Hy subscribe cho knh Ghin M G  khng b l nhng video hp dn.'), Document(metadata={'end_timestamp': '0:17:35', 'chunk_id': 1, 'start_timestamp': '0:07:45', 'video_url': 'https://youtube.com/watch?v=0PqzYo2Z-20', 'filename': '0PqzYo2Z-20', 'title': '[CS315 - Chng 1] M hnh hc my da trn Gradient (Phn 8)'}, page_content='Chng ta s cn li l dfn-dx, tc l o hm ca f theo x Th y l mt ci quy tc  nh thi  l dfn-1, sau  l n-1, n-2, n-2, n-3, ri v.v.v cho n f2 theo f1 v f1 theo x Th x s l ci bin s ca mnh, n s nm  cui cng  y Th chng ta s xt mt ci v d cho n gin v trc quan V d nh fx, iz l bng x cng i, tt c nhn vi z Th  y gi s nh chng ta xem xt l, chng ta ti mt thi im th chng ta ch xt vi mt bin x Tc l tt c nhng ci hm  trn y s c a v ci hm ch c mt bin thi Th t ci cng vic u tin chng ta phi tnh ton,  l ci vic tnh x cng i y l ci thao tc u tin chng ta tnh, th y s l biu din bi hm f1 Sau khi chng ta tnh ci f1 l x cng i xong, th chng ta s li nhn vi z, th y s l hm f2 Nhng  y chng ta s xt trn mt bin x trc, th f1x s l bng x cng i Sau  chng ta li ly f1 nhn vi z  ra f2 Nh vy cng thc ca f2 m theo ci bin x th n s l bng f1 nhn vi z Nhng m trong trng hp ny, f1 ca chng ta chnh l ci bin s ca mnh Th khi , fx ca mnh, ci cng thc fx ban u ca mnh s l bng f2 ca f1x Khi chng ta th vo, th f2 chnh l z nhn x Do , f2 ca f1x s l bng z nhn cho xx, trong trng hp ny chnh l f1 F1 chng ta s th vo bng cng thc ny,  l x cng i Ri, khi  th o hm ca f1 theo x, lu  l  y chng ta ch ang xt vi mt bin x thi Chng ta s lm ci vic tng t, ci vic ny tng t cho bin i, chng ta s lm sao o hm ca f1 theo x, th o hm ca f1 theo x chnh l trong cng mc ca x, th i chnh l hng s Do  o hm ca f1 theo x chnh l 1 Ri, o hm ca f2 theo f1 l bao nhiu? o hm ca f2 theo f1, tc l chng ta s tnh o hm ca ci ny theo x Chng ta s tnh o hm ca ci ny theo x, th trong bin x, th z chnh l hng s do  o hm ca ci ny s l bng z o hm ca f2 theo f1 chnh l z Ri, nh vy th chng ta s s dng, p dng ci cng thc chain rule l d ca f theo x s l bng df2 theo f1 Sau  df1 theo x, th df2 theo f1 chnh l z, nguyn ci cp ny s l z V df1 theo x chnh l 1 Nh vy z nhn 1 chnh l bng z, nh vy o hm ca f theo x s l bng z Hon ton tng t cho i v z, chng ta s lm ci cng vic ny cho o hm ca f theo i v o hm ca f theo z Th i vi bin i V chng ta c nhiu bin nn ti mt thi im chng ta ch xem xt mt bin thi Th cng vic u tin chng ta s tnh ton,  l php cng  y Th f1 ca ta, by gi n khng phi l bin x na m s l bin theo i, th n vn s l bng x cng i V f2 ca mnh theo bin i th n cng s l bng gi tr f1 nhn vi z V f1 theo nhn vi z nh vy s l z nhn vi i Ti v trong trng hp ny f1 ca mnh s l bin s, f1 ca mnh s l bin s Nh vy th f2 i l bng z i V khi  th cng thc f ca i s l bng f2 ca f1 ca i Th x cng i l x cng i Ri, f2 ca f1 l z nhn vi i Thay l z nhn vi li ci f1 ny M f1 ca mnh l x cng i Tc l khi chng ta trin khai  y th f1 i chnh l chng ta xem n nh l mt ci bin Ri chng ta trin khai v th n s l z nhn vi li ci bin Tc l z nhn vi f1, m f1 th n li l bng x cng i Ri, khi  chng ta s tnh o hm o hm l d ca f1 theo i D ca f1 theo i th n s l bng 1 Ti trong c mt ca i th x l bng hng s D ca f2 theo f1 Tc l o hm ca cng thc ny V o hm ca cng thc ny l bng z Ri, nh vy th chng ta s c o hm ca f theo bin i Chnh l bng o hm ca f2 theo f1 Nhn cho o hm ca f1 theo i V f2 theo f1 chnh l bng z V df1 theo i chnh l bng 1, khng bng z Tng t nh vy chng ta s tnh cho o hm ca f theo z Th chng ta thy l ci cch lm ny, Chain Rule ny th n s rt l bi bng v c th tng qut ha c V by gi chng ta s tm cch biu din ci cng thc ca ci fx, iz ny di dng l biu ,  th tnh ton Nh sau, u vo chng ta s c x, y v z Bc u tin chng ta s thc hin l ly x, y, y l ton t cng V u ra ca mnh s l hm f1 Sau  chng ta ly ci z ny em nhn vi ci f1  ra ci f2, th y chnh l ci hm f ca mnh Ri, th y l ci cch biu din di dng  th tnh ton Trong  mi mt ci node tnh ton s l mt ton t v u vo n s nhn cc ci bin s Th th chng ta s n vi mt trong nhng thut ton u tin,  chnh l thut ton Feed Forward Tc l trc khi thc hin Backpropagation, Backpropagation l lan truyn nghch Th chng ta s phi lm ci thut ton lan truyn thun, tc l chng ta s i tnh ci gi tr ca hm f trc Da trn ci  th tnh ton, th gi s  y chng ta vn s dng cc ci hm nh  nu  trn Th x, x n s l bng f2 ca f1, x th u tin ta s xy dng ci  th tnh ton Ri sau  chng ta s tnh gi tr ti cc ci node, bit rng l chng ta s chn ra mt ci b gi tr x, y, z khi to ban u y chnh l ci gi tr khi to V chng ta s i tnh o hm ti ci gi tr x bng 3, y bng tr 4 v z bng 5 u tin  l chng ta s xy dng ci  th tnh ton, ging nh  trong slide trc, th y chnh l  th tnh ton V chng ta s c cc ci node l node cng, ri node nhn Sau  chng ta s ln lt thay cc ci gi tr ny vo cc ci node, th x l bng 3, y l bng tr 4 v z l bng 5 Sau  chng ta c ln lt lan truyn thun ln, lan truyn thun v pha trc u tin  l thc hin php cng, th f1 bc ny n s l bng 3 cng cho tr 4, th n s l bng tr 1 Sau khi chng ta  tnh f1 xong, th chng ta s thc hin ci node php nhn Th f2 n s l bng f1 nhn vi tr 5, tc l f1 nhn vi 5, tc l bng tr 1 nhn vi 5 l bng tr 5 Nh vy th ci thut ton lan truyn thun  l mt ci thut ton quan trng  gip chng ta xy dng ci  th tnh ton Ci bc quan trng u tin  l xy dng c ci  th tnh ton L mt ci bc tin  quan trng trc khi chng ta c th tnh c ci o hm ca hm f theo cc ci bin x ny, cc ci bin x, x, y, z ny'), Document(metadata={'chunk_id': 3, 'filename': 'hrxNKadDpw4', 'end_timestamp': '0:06:22', 'start_timestamp': '0:03:12', 'video_url': 'https://youtube.com/watch?v=hrxNKadDpw4', 'title': '[CS315 - Chng 3] Deep Generative Models (1) - Part 1'}, page_content='Chng ta c th dng trong lnh vc v phn loi mt ci i tng no , bi ton hi quy, d on mt ci gi tr c tnh th t no . Ri pht hin i tng, phn on ng ngha i tng v.v. th hc c gim st n  t c nhng thnh tu hin nay v c th ng dng c rt l rng ri. Th th cn mt ci mng na  chnh l hc khng c gim st. Th hc khng c gim st  l d liu u vo chng ta s khng c y m chng ta ch c duy nht mt bin x u vo. Chng ta khng c nhn, th y chnh l s khc bit ln nht gia hc khng gim st v hc c gim st. Mc tiu ca hc khng gim st  l chng ta s hc t ci cu trc n ca d liu, hay l chng ta s i hc ci phn b ca d liu. Phn b ca d liu. Ri, th mnh c th ly mt ci v d nh sau  chng ta hiu th no l chng ta i hc mt ci cu trc n v hc mt ci phn b d liu. Bng cch  l chng ta s tr li cho ci cu hi sau. Mt bn hc sinh c im trung bnh l v d nh l 8,8 im. Th theo cc bn  l bn ny s c ci hc lc l gii, kh xut sc hay l di trung bnh. Th a s  l chng ta s khng bit c ci im ny l cao hay thp khi chng ta khng t n  trong ci phn b ca nhng ci bn cn li trong lp. Th nu nh ci im ca lp mnh m c ci phn b nh sau, im 8,8 th nm  ci khu vc ny. V d nh im 8,8 l nm  khu vc ny. Th bn ny l mt bn c hc lc gii ti v nhn trong ci phn b ny bn nm  ci top m nhng ngi c im cao. Nhng ngc li nu trong mt ci phn b khc, im 8,8 ca bn n li nm  y. 8,8 th khi  l vi ci phn b ny th im ca bn l c hc lc di trung bnh. Nh vy  kt lun c tnh cht ca d liu x th chng ta phi hc c ci phn b. V vy, trong ci phn b chng ta s xc nh c ci phn b ca d liu v t  chng ta hnh thnh c ci cu trc n ca d liu. V d chng ta chia ci khng gian ca mnh ra lm 3 phn. V d vy th y l nhng ci bn m c hc lc km. y l nhng bn c hc lc trung bnh v y l nhng bn c hc lc gii. V d vy th y l chng ta ang cu trc ha ci khng gian n ca mnh. V nhng ci bi ton m kinh in lin quan n ci hc khng gim st  chnh l bi ton phn cm, bi ton gim chiu d liu. Th  l chng ta  cng n li mt vi ci khi nim v hc c gim st v hc khng c gim st.'), Document(metadata={'end_timestamp': '0:13:56', 'filename': '5Wpw2EsSz40', 'video_url': 'https://youtube.com/watch?v=5Wpw2EsSz40', 'title': '[CS315 - Chng 2] Overfitting (Phn 2)', 'chunk_id': 9, 'start_timestamp': '0:12:59'}, page_content='Hoc l chng ta ly ci salient, tc l nhng ci bin cnh m ni bt nht. Hoc l chng ta lm cc ci thao tc l transformation. Tc l ci thao tc bin i v mt hnh hc, nh flip, quay, t l, tnh tin, v.v. T , t mt nh mc xm, th t mt nh chng ta s to ra N nh v ci N nh ny th N nh phin bn khc nhau. Cn i vi lnh vc v x l ngn ng t nhin, th chng ta cng c mt s k thut. Trong  n gin v d hiu nht  chnh l k thut Back Translation. Tc l vi ci vn bn gc, th chng ta chuyn n dch n sang ci ngn ng khc. Th d nh l ting Anh, sau  chng ta dch ngc tr li, sang tr li ting Anh. Th t ting Anh sang ting Php, xong ri t ting Php dch ngc li ting Anh, th chng ta  c mt ci phin bn mi.'), Document(metadata={'video_url': 'https://youtube.com/watch?v=NJVpvCzceRk', 'end_timestamp': '0:06:23', 'start_timestamp': '0:05:49', 'filename': 'NJVpvCzceRk', 'chunk_id': 5, 'title': '[CS315 - Chng 3] Deep Generative Models (2) - Part 4'}, page_content='Ri thm v mt ci thnh phn nhiu l 1 tr alphaT. Th y chnh l ci cng thc ca khuch tn thun. Th th chng ta s n vi mt ci k thut.  l k thut Reparameterization hay gi l ti tham s ha. Th ci ny cng tng tng tng t nh l ci VAE. Nu nh ci thao tc x m chng ta sampling, ci k hiu ny l sampling. Th ci thao tc sampling ny l mt ci thao tc khng tnh o hm c.'), Document(metadata={'end_timestamp': '0:04:18', 'filename': 'RVj2LTBd7IU', 'start_timestamp': '0:00:14', 'video_url': 'https://youtube.com/watch?v=RVj2LTBd7IU', 'chunk_id': 0, 'title': '[CS315 - Chng 3] Deep Generative Models (1) - Part 5 (Phn 3)'}, page_content='Chng ta s cng tm hiu v mt s bin th ca mng GAN v ng dng ca n. GAN s bao gm hai generator v discriminator. Tuy nhin, khi chng ta sinh nh vi  phn gii rt cao, c th l  phn gii HD, th n s gp mt s vn  thch thc, v d nh tc  hun luyn, kh hi t, hoc b overfitting. Th th, ci gii php ca chng ta  l thay v chng ta s dng mt ci kin trc phc tp t  phn gii thp ln  phn gii cao, tc l mt ci random noise, t  phn gii thp ln  phn gii cao, sau  t cao xung thp, chng ta ch hun luyn vi mt ci mng nh th ny, th chng ta s hun luyn t t. Th ci qu trnh training process chng ta thy l t tri sang phi, l chng ta ang i t  phn gii thp, i tin n ci  phn gii cao. Vi ci  phn gii thp, th chng ta s hc v nhng ci concept chung ca tm hnh. V d nh  y chng ta c ci vector latent, c random sampling theo nhiu normal 01, th chng ta s bin i n thnh mt ci tm nh c  phn gii,  l 4x4. Ci module ny th gip chng ta to ra tm nh c  phn gii l 4x4. V kt hp vi li ci nh tht, th chng ta s qua ci discriminator, v dnh cho ci nh c kch thc l 4x4. Th chng ta thy l vi ci m hnh to sinh v phn bit, phn loi, nh tht, nh gi, m vi  phn gii thp, th ci s lng tham s n s rt l t, do  ci hi t, tc  hi t n s nhanh hn, n d hi t hn. Khi chng ta ln ci  phn gii cao hn, chng ta s chng thm cc lp bin i  t nh c  phn gii 4x4 ln 8x8. V vi nh ny th chng ta thy n  mt hn mt cht, n  mt hn, so vi li nh  pha trc l 4x4. Tng t nh vy, kt hp vi nh tht, th chng ta s i qua mt b phn loi, nh tht, nh gi, t 8x8 v li 4x4. V c nh vy, th chng ta nng dn ci  phn gii ca nh ln, t 4x4 ln 1024 x 1024, th to ra mt nh c  phn gii rt l cao.  phn gii cao. V t ci  phn gii cao ny, chng ta a qua ci m hnh phn loi, th chng ta s ra c ci m hnh c kh nng phn bit c nh hay l nh tht, hay nh gi, th  bn tay phi, chng ta thy  l ci kt qu l nh c  phn gii rt l cao. V khi chng ta to sinh hnh nh, th chng ta s s dng ci m hnh G ny, chng ta s s dng ci m hnh G c ci  phn gii cao ny. V ng dng ca n th chng ta bit rng l  trong ci StyleGAN, StyleGAN 2, th c cng b mt ci trang web  l This Person Does Not Exist, th mc tiu  l n to ra ngu nhin mt ci nh ngi nhng m khng c tht. V chng ta c th s dng ci nh ny  phc v cho ci vic l lm nhng ci v d nng cao m khng vi phm cc ci vn  v quyn ring t. Mt ci bin th khc cng rt l ni ting ca GAN,  chnh l Conditional GAN hay l GAN c iu kin. Trc y th chng ta t mt ci vector nhiu Z, chng ta to ra mt ci tm nh, nhng m ci nh ny l chng ta khng th on trc c, hoc l chng ta khng th kim sot c, khng th kim sot c ci u ra ca mnh,  l ci nh nh th no.'), Document(metadata={'chunk_id': 10, 'start_timestamp': '0:14:16', 'video_url': 'https://youtube.com/watch?v=iQqNUKgIZpc', 'end_timestamp': '0:15:28', 'title': '[CS315 - Chng 2] Vanishing Gradient (Phn 3)', 'filename': 'iQqNUKgIZpc'}, page_content='Nhng m cc bn nhn v y th chng ta thy ci kt ni tt mi chnh l nhng ci thao tc m nhiu nht. y l mt ci ni tt. Mt kt ni tt. Ri li tip tc kt ni. Kt ni tt.  th khng bit l Attention Is All You Need hay l Skip Connection Is All You Need. Ci ny l mt ci ni vui. V tng t nh vy th cng s c Deep Supervision l mt ci kin trc mng m c cc ci kt ni tt. Th ci kt ni tt ny n khng c theo kiu ca DenseNet m l n s tt ra thnh tng nhnh. V vi mi nhnh th chng ta thy nu i theo ng ci ng ban u l ci ng kin trc  gia th s bin i rt l nhiu. Nhng m nh c ci nhnh n tt ra, tt ra, tt ra, tt ra  y. Th chng ta s tnh cc ci loss  nhng ci lp m c t bin i hn. Th nhng ci loss  cc lp t bin i ny th khi chng ta lan truyn v th chng ta s gip cp nht c trng s ca nhng lp u tin d dng hn. Ti v khong cch t lp u tin ny cho n nhng ci...'), Document(metadata={'chunk_id': 7, 'title': '[CS315 - Chng 1] M hnh hc my da trn Gradient (Phn 7)', 'filename': '3TT7y2Nz-vc', 'start_timestamp': '0:08:35', 'video_url': 'https://youtube.com/watch?v=3TT7y2Nz-vc', 'end_timestamp': '0:10:14'}, page_content='N b sai lch so vi li ci o hm ti ci thi im . V trong ci s  ny th chng ta s c ci trc quan ha  cho thy ci tc  hi t ca tng thut ton. Th  y AdaDelta,  chnh l ci Adam ca mnh.  l ci ng mu vng.  l ci ng mu vng ny. Ri, v chng ta thy l ci ng mu vng th n s rt xung rt l nhanh, n s hi t rt l nhanh. Khi n ci khu vc m gi l Saddle Point v ng thi l c ci valley, l ci thung lng chng ta thy l c hai ci thnh, gim  dc, i ngang, xong ri li i ln,  gi l valley th ci Adam ca chng ta rt xung nhanh nht, n rt xung rt l nhanh. Cn ci thut ton m Root Mean Square Propagation l ci ng mu en th chng ta thy l n s rt chm hn. Cn Stochastic Gradient Descent th i vi Stochastic Gradient Descent l ci chm mu  n l chng ta thy n b dao ng qua li v n ng yn lun, n khng thot ra c ci ch ny lun. Momentum th kh hn mt cht xu l ci ng, ci im mu xanh l. Chng ta thy l khi Momentum n rt xung n cng s chao o qua li. Nhng m v c mt s kiu ti u nn n s dn dn dn dn n thot ra c v n n c ci rnh ny n di chuyn. Trong khi cc ci phng php ci tin khc th n cng b ci hin tng l dao ng qua li rt l nhiu.'), Document(metadata={'filename': 'zbR5lDFTKTM', 'chunk_id': 2, 'start_timestamp': '0:03:47', 'end_timestamp': '0:21:54', 'video_url': 'https://youtube.com/watch?v=zbR5lDFTKTM', 'title': '[CS315 - Chng 4] Vision - Language Model (1): Part 6'}, page_content=' m t  l n... V d y, n tm ra c ci Magna nm  y chng hn Th n s tr li l 6  la V sau  n cn lp lun v thc hin ci thao tc m L trong ci y c hai chai bia, do  n s ly 6 nhn cho 2 l bng 12 Nh vy th  y chng ta thy ci m hnh ny n cn c ci s gi l reasoning Tc l ci s suy lun Ch n khng ch n gin l information extraction, tc l rt trch thng tin ra t tm nh M n c ci s reasoning  y Th  t c ci reasoning ny th n s phi nh n ci kt qu hoc l nhng thnh tu ca GPT L ci m hnh m pre-train dnh cho c decoder  phc v cho vic l x l ci vn bn Hoc l generate to sinh ra vn bn Vy th GPT-4V l mt ci m hnh cho php x l a dng cc d liu u vo hay cn gi l multimodality l a th thc V n c th x l d liu u vo l dng vn bn thng thng N c th gm mt hoc l nhiu nh V d nh trong ci v d ny ta thy l c th ln n vi nh, ba nh Ri vn bn trong nh, tc l trong tm nh n li c vn bn Bnh thng l mnh s c vn bn ring v nh ring By gi trong nh n li c vn bn , th y l mt ci v d trong nh l c vn bn L trong tm hnh menu n s c cc ci tn ca cc loi  ung v gi tin Ri visual pointer tc l mt ci dng thc  cho chng ta tng tc i vi l mt ci dng prompt, n l mt ci dng prompt mi Bnh thng mnh c prompt l dng text v nh By gi ci prompt ca mnh c th l du mi tn ging nh chng ta ang v  y Ci mi tn ny n cng c gi l mt ci prompt Nu nh ci m hnh ny gi s nh n gii khng c th chng ta c th ch v y Gi ca ci beer Magna n l nm  y, mnh ch v M hnh ca mnh s hiu c ci visual pointer ny nh l mt ci loi prompt Vy th GPT-4V n c mt vi c trng chnh,  l g y l mt ci bi ton c th c thc hin vi GPT-4V y l nhng ci bi ton m GPT thc hin c bao gm nhng task rt l n gin V d nh l m t hnh nh, image description, image captioning, ri nhn dng nh, recognition on different domains Ri kt hp kin thc a th thc, multimodal knowledge Trong ci v d  trn chng ta thy l n c s dng ci knowledge ca vn bn l text ng thi n cng c s dng ci knowledge ca tm nh Ri n c s dng ci text trong nh Th  l multimodality V c th tng tc vi cc kin thc tng qut V d nh n c th hiu v nhng ngi ni ting nh l David Beckham Ngi ni ting ny Ri cc ci a danh nh l Paris, H Ni v.v. a danh ni ting th  l nhng ci kin thc tng qut Ri v ng thi n c kh nng quan trng l hiu v suy lun hay gi l reasoning trn ci vn bn n thun hoc l vn bn trong nh syntax understanding hoc document reasoning Th y chnh l nhng ci kh nng ni tri ca GPT-4V so vi nhng m hnh ngn ng th gic m chng ta  tm hiu  pha trc Tip theo th chng ta s cng tm hiu v khi nim visual pointer  bn tay phi l mt hnh nh v d v visual pointer Bn cnh cu m t l display the pointed region in the image V chng ta s c mt tm nh Trong tm nh ny, n s c mt ng mu  y chnh l mt v d ca visual pointer Vi visual pointer s hng dn cho m hnh tp trung vo nhng phn quan trng ca tm nh Thay v chng ta nhn v, tm nh ny s c c rng ch v s Vi ng khoanh mu  ny, m hnh ca mnh bit l s tp trung vo y  phn tch s liu ca mnh Vi ng mu  ny, m hnh GPT-4V  nu c V chng ta  a ra cc phn tch tng ng ca tm nh V chng ta  a ra cc phn tch tng ng ca tm nh Vy th ngoi ng khoanh mu , n s cn nhng dng visual pointer no V d nh chng ta c th a vo ta  dng s, hoc l coordinate Hoc chng ta c th a vo blackbox, trong  chng ta loi b ht tt c nhng phn nh khng lin quan V ch cha ci vng nh c lin quan n vic suy lun hoc l ci vic tr li cu hi ca chng ta Hoc l n c th  dng l mt ci mi tn, ch vo nhng i tng m chng ta ang mun quan tm Th y c th l mt trong nhng dng kh l th v v gn vi cch thc ngi tng tc khi m trao i vi nhau trn hnh nh Ri ci dng na  l chng ta c th dng mt ci box, mt ci khung km ci nh gc th n s c thm mt ci ng mu   khoanh vng ci i tng chng ta quan tm V c nhng ci dng m freestyle hn, v d nh l hnh oval, hoc l hand drawing, tc l mt ci ng nt t do Vi ci visual pointer, n  gip cho ci vic tng tc gia ngi v my tnh tr nn thun tin hn V y c l l mt trong nhng ci th thc quan trng c bit m GPT-4V n khc bit so vi li nhng ci m hnh vision language, ci m hnh th gic ngn ng trc y Vy th mt vi ci v d na  cho chng ta thy ci tnh hiu qu ca GPT-4V lin quan n ci vic l reasoning Nu nh chng ta a vo mt ci cu prompt  l count number of apples in the image th n s m sai l c 12 qu to Nng cp hn mt cht xu th mnh s ch dn cho n,  l thm mt ci cu vit ng sau  l suy ngh step by step Th n s a ra l c 4 step, ri step 1 l tnh nh th no, step 2 l lm g, step 3 l lm th no, step 4 thm ch  kim tra li Nhng cui cng n vn ra sai v ch n khi chng ta a ra mt ci ch dn y  v cc ci bc  n gin Th n mi c th lm ng v d, cu u ging nh n khen You are an expert in counting things in the image Ri, hy m nhng s lng apple trong tm nh ny row by row v m bo rng l n ra c ci kt qu chnh xc Th th n s xt trong tm hnh ny th n s c 4 dng v vi mi dng n s ln lt lit k ra, n s a ra ci con s m V d nh l 4 apple, dng s 2 l c 4 apple, dng s 3 l c 3 apple v cui cng n s ra c con s ng l 11 apple Ri, th nh vy, GPT-4V  y l mt ci v d cho chng ta thy l n c th a ra, chng ta c th a vo cc ci ch dn cng vi ci tm nh V ci ch dn ny th bit n ging nh l mt ci cu prompt m chng ta tr chuyn vi chatbot, ch dn cho n bit l phi lm nh th no  m suy lun Th y chnh l mt ci v d khi s dng GPT-4V ging nh l chng ta s dng vi ci m hnh GPT-4o hoc GPT-4 ca nn tng ChatGPT Ri, ci In-context Few-Shot Learning th  y l mt ci v d Zero-Shot i a s mi ngi khi m lm vic th u hay s dng Zero-Shot, ti v th nht l h ngh rng ci m hnh ca mnh l tt, ci m hnh ca mnh l xn Gi n y l ci g cng bit, ci g cng bit Ci th hai l bn thn mnh l ci ngi s dng th mnh cng li, mnh li hng dn cho n nhiu Th  l hai ci yu t khin cho Zero-Shot l mt trong nhng ci k thut c s dng rt l ph bin V d trong v d ny l chng ta a vo ci prompt l In which year had the highest average gas price  trong thng 6 Th  y l m hnh tr li sai l 3,3  Nu m chng ta dng l Zero-Shot nhng m chng ta ku n l think step by step th kt qu ca mnh cng sai Ch khi chng ta a vo ci In-context Few-Shot, c th  y l hai shot Th ci In-context Few-Shot ny c ngha l g? Chng ta s cho n mt ci cp cu hi V v d, cu hi v d, ci p n th n s bm theo ci cp suy lun   m n tr li cho nhng cu hi mi V d nh  y l chng ta hi,  y chng ta s a cho n l ch dn thm l ci  th ny Plot the National Gas Price, tc l plot gi gas  trong nc l t 2016 cho n 2019 Ri n m t ra chi tit l mu  l g, mu xanh l g, mu xanh l l g, v.v. Ri sau  th n s a ra tnh ton l nm m c ci High Gas Price l vo thng 6 nm 2018 Th  y l n a ra nhng ci Few-Shot, tc l ci kt qu Vy th GPT n  da trn ci lp lun tng t  pha trn l vi hai shot, y l shot s 1 y l shot s 2  pha bn di, n s cn mt ci cu na V d th khi chng ta a vo mt s liu mi,  trn l chng ta cho v d 2019, 2018 V vi s liu mi ny l 2023 th n s t ng lp lun y chang nh th ny  tm ra c gi gas m cao nht l bao nhiu Th n bt chc hai ci shot  pha trn cho mt ci loi d liu mi V ci kt qu n ra c  l thng 6 nm 2020, th  chnh l ci hng dn cho ci m hnh, ci cch thc  m n lp lun V vi Few-Shot hay cn gi l In-context learning Nh vy tng kt li chng ta  cng tm hiu qua cc ci m hnh, m hnh ban u nh l CLIP V cho n by gi th vn c dng nhiu, CLIP th dng nhiu cho bi ton l Zero-Shot Image Classification Sau  chng ta c phin bn l GLIP, vi ci s cng l Zero-Shot nhng m cho bi ton Detection Ri nng ln l c m hnh CLIP, sau  l s c Visual Programming Ri ci m hnh m chng ta va mi tm hiu  chnh l GPT-4V Vy th ci vic m chng ta s c ci nhn nh g khi chng ta  tm hiu qua cc ci m hnh ny  l ci vic m chng ta hun luyn mt ci m hnh t u cho ci m hnh th gic th n cn rt nhiu ti nguyn tnh ton Cng nh l ci d liu ca chng ta rt l ln Ni vui  l nhiu khi ci d liu ca mnh n ln n ni m chng ta khng  dung lng  cha ch ng ni n ci chuyn l chng ta hun luyn m hnh Ti v quy m n ln n Internet Scale Internet Scale Dataset V do  th thng thng chng ta s s dng ci m hnh  hun luyn sn Nhng m quan trng l chng ta s phi bit c ci cng nng ca tng m hnh, ca tng phn trong m hnh l g V d nh khi chng ta nhn vo ci m hnh CLIP th chng ta bit ci m hnh no l m hnh chng ta s s dng  cho ci cng vic gi l Unimodal encoding V khi no th chng ta s s dng ci m hnh, m cross-modal hay l image-text, image-text l text matching V khi no th chng ta s s dng ci language model  pha sau  cho ci tc v l text generation Th chng ta bit c ci cng nng ca tng m hnh v dng m hnh no l ph hp cho ci bi ton ca chng ta Ci th hai  l phi hp cc ci thnh phn hun luyn sn  cho ci bi ton ca mnh V d nh chng ta khai thc ci module  m ha hnh nh hoc module m ha vn bn Ti v ci vic m chng ta cho hnh nh v vn bn tng tc vi nhau  hc ra c encoding th n s gip cho chng ta c ci tnh tng qut, c ci tnh tng tc v phn bit c ng ngha mt cch r rng hn so vi vic chng ta ch hc da trn vn bn khng hoc ch hc da trn hnh nh khng V s dng cc k thut Prompt Engineering mt cch hiu qu V d nh chng ta s dng ci In-context learning vi k thut Few-Shot Prompting Chng ta s cho n khong hai, ba v d v ci instruction v ci instruction v ci kt qu ca mnh Th kt qu, ci Result th n s bt chc ci instruction v ci Result ny Khi chng ta c mt ci new instruction th n s gip cho chng ta d on ra c ci kt qu N s a ra mt ci kt qu d on Th  l  tng ca In-context learning v y l mt trong nhng k thut dng cng rt l ph bin Ri hng dn m hnh suy lun mt cch c h thng, chng ta s cho n suy ngh theo kiu step by step Ri c th ch dn cho n chi tit hn l chng ta s chia n ra thnh bc 1, bc 2, bc 3 nh th no Bc 1 chi tit l sao? Cng n gin th m hnh s d thc hin theo Ri hng dn cho n cch suy lun V cui cng  l s dng Visual Pointer th y l mt k thut  gip cho chng ta c th h tr cho ngi dng To ra mt ci prompt mt cch n gin v t nhin Chng ta c th to ra mt ci visual pointer l dng mi tn, n c th l mt ci box hoc l mt ci scribble nh th ny Mt ci ng m zigzag Vy th trn y  l mt vi ci m hnh u tin khi ni v m hnh ngn ng th gic Trong nhng phn tip theo th chng ta s ni v nhng ci m hnh hin i hn, c train trn nhng d liu ln hn V phc v cho cc ci bi ton m chng ta   cp trc y, v d nh bi ton segmentation V bi ton sinh ngn ng text generation C th  l ci m hnh l LLaVA Cn i vi ci segmentation th chng ta c th s dng hai ci m hnh,  l SAM Grounding DINO y l hai ci m hnh Zero-Shot Segmentation V m hnh SEEM l mt ci m hnh tng tc a th thc Trong nhng phn tip theo chng ta s tm hiu v cc ci m hnh ny')]\n"
     ]
    }
   ],
   "source": [
    "result = hybrid_retriever.get_relevant_documents(\"diffusion l g\") if bm25_retriever else []\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925223f5",
   "metadata": {},
   "source": [
    "## generate text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82af4a97",
   "metadata": {},
   "source": [
    "### Chn m hnh (qwen 0.5b hoc api gemini)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8aa5a1",
   "metadata": {},
   "source": [
    "## Generation vi Qwen 0.5B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7569d84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_3340\\3289444550.py:32: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm_qwen = HuggingFacePipeline(pipeline=model_pipeline)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float32,  # CPU thng dng float32\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "\n",
    "MODEL_NAME = \"Qwen/Qwen2-0.5B\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True, trust_remote_code=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "model_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=128,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    temperature=0.1,\n",
    "    device=0  \n",
    ")\n",
    "# HuggingFacePipeline LangChain\n",
    "llm_qwen = HuggingFacePipeline(pipeline=model_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86b29605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allocated: 1.97685248 GB\n"
     ]
    }
   ],
   "source": [
    "print(\"allocated:\", torch.cuda.memory_allocated(0) / 1e9, \"GB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3257647e",
   "metadata": {},
   "source": [
    "## generation ( ch dng cho qwen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52c89ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DAI_HOC\\CS431\\DoAn\\Rag_QABot\\venv310\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3579: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables import RunnableMap,RunnableLambda\n",
    "\n",
    "\n",
    "class VideoAnswer(BaseModel):\n",
    "    text: str = Field(description=\"Cu tr li tm tt trong 3 cu\")\n",
    "    filename: str = Field(description=\"Tn file transcript gc\")\n",
    "    video_url: str = Field(description=\"URL ca video gc\")\n",
    "    start_timestamp: str = Field(description=\"Thi im bt u (format: HH:MM:SS)\")\n",
    "    end_timestamp: str = Field(description=\"Thi im kt thc (format: HH:MM:SS)\")\n",
    "    confidence: str = Field(description=\" tin cy: zero/low/medium/high\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=VideoAnswer)\n",
    "\n",
    "# ===== Prompt =====\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Transcript:\n",
    "{context}\n",
    "\n",
    "Cu hi: {question}\n",
    "\n",
    "Tr li bng JSON vi cc yu cu:\n",
    "- \"text\": tm tt **ch 3 cu ngn gn**.\n",
    "- \"filename\", \"video_url\", \"start_timestamp\", \"end_timestamp\": gi nguyn thng tin.\n",
    "- \"confidence\": chn mt trong cc gi tr \"zero\", \"low\", \"medium\", \"high\" da trn  chc chn ca cu tr li.\n",
    "\n",
    "Cu trc JSON:\n",
    "{{\n",
    "  \"text\": \"<tm tt trong 3 cu ngn gn>\",\n",
    "  \"filename\": \"<tn file transcript>\",\n",
    "  \"video_url\": \"<URL video>\",\n",
    "  \"start_timestamp\": \"<HH:MM:SS>\",\n",
    "  \"end_timestamp\": \"<HH:MM:SS>\",\n",
    "  \"confidence\": \"<zero/low/medium/high>\"\n",
    "}}\n",
    "\n",
    "Answer:\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "def extract_json_from_output(output: str) -> str:\n",
    "    return output.split('Answer:')[1].strip()\n",
    "\n",
    "\n",
    "def format_doc(docs):\n",
    "    formatted = []\n",
    "    for doc in docs:\n",
    "        url = doc.metadata.get(\"video_url\", \"\")\n",
    "        filename = doc.metadata.get(\"filename\", \"\")\n",
    "        start = doc.metadata.get(\"start_timestamp\", \"\")\n",
    "        end = doc.metadata.get(\"end_timestamp\", \"\")\n",
    "        content = doc.page_content\n",
    "        formatted.append(f\"\"\"[Video URL]: {url}\n",
    "[Filename]: {filename}\n",
    "[Start]: {start}\n",
    "[End]: {end}\n",
    "[Content]: {content}\"\"\")\n",
    "    return \"\\n\\n\".join(formatted)\n",
    "\n",
    "def rerank_with_query(docs_and_query) -> List:\n",
    "    docs, query = docs_and_query\n",
    "    return crossencoder_rerank(docs, query, top_k=3)\n",
    "\n",
    "def get_context(query: str):\n",
    "    docs = vector_retriever.get_relevant_documents(query)\n",
    "    reranked = crossencoder_rerank(docs, query, top_k=3)\n",
    "    return format_doc(reranked)\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"context\": RunnableLambda(get_context),\n",
    "    }\n",
    "    #| prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "    | prompt.partial()\n",
    "    | llm\n",
    "   #| RunnableLambda(lambda x: extract_json_from_output(x))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b0cd3ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vector_retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mrag_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m tng ca m hnh xc xut trong to sinh nh\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# 3 thnh phn loss ca diffusion \u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#vae loss c bao nhiu thnh phn\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#diffusion b g  c latent diffusion\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# tng ca m hnh xc xut trong vic to sinh hnh nh\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m##  tng naive bayes trong to sinh\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[1;32md:\\DAI_HOC\\CS431\\DoAn\\Rag_QABot\\venv310\\lib\\site-packages\\langchain_core\\runnables\\base.py:3244\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3242\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m   3243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 3244\u001b[0m         input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3245\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3246\u001b[0m         input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config)\n",
      "File \u001b[1;32md:\\DAI_HOC\\CS431\\DoAn\\Rag_QABot\\venv310\\lib\\site-packages\\langchain_core\\runnables\\base.py:4001\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3996\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m   3997\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3998\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[0;32m   3999\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   4000\u001b[0m         ]\n\u001b[1;32m-> 4001\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: future\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[0;32m   4002\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   4003\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\DAI_HOC\\CS431\\DoAn\\Rag_QABot\\venv310\\lib\\site-packages\\langchain_core\\runnables\\base.py:4001\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   3996\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m   3997\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3998\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[0;32m   3999\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   4000\u001b[0m         ]\n\u001b[1;32m-> 4001\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[0;32m   4002\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   4003\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\concurrent\\futures\\_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32md:\\DAI_HOC\\CS431\\DoAn\\Rag_QABot\\venv310\\lib\\site-packages\\langchain_core\\runnables\\base.py:3985\u001b[0m, in \u001b[0;36mRunnableParallel.invoke.<locals>._invoke_step\u001b[1;34m(step, input_, config, key)\u001b[0m\n\u001b[0;32m   3979\u001b[0m child_config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m   3980\u001b[0m     config,\n\u001b[0;32m   3981\u001b[0m     \u001b[38;5;66;03m# mark each step as a child run\u001b[39;00m\n\u001b[0;32m   3982\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap:key:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   3983\u001b[0m )\n\u001b[0;32m   3984\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m-> 3985\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3986\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3987\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3988\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchild_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3989\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\DAI_HOC\\CS431\\DoAn\\Rag_QABot\\venv310\\lib\\site-packages\\langchain_core\\runnables\\base.py:5025\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5010\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke this ``Runnable`` synchronously.\u001b[39;00m\n\u001b[0;32m   5011\u001b[0m \n\u001b[0;32m   5012\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5022\u001b[0m \n\u001b[0;32m   5023\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 5025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m   5026\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invoke,\n\u001b[0;32m   5027\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   5028\u001b[0m         ensure_config(config),\n\u001b[0;32m   5029\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   5030\u001b[0m     )\n\u001b[0;32m   5031\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot invoke a coroutine function synchronously.Use `ainvoke` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5032\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "File \u001b[1;32md:\\DAI_HOC\\CS431\\DoAn\\Rag_QABot\\venv310\\lib\\site-packages\\langchain_core\\runnables\\base.py:2092\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[0;32m   2088\u001b[0m     child_config \u001b[38;5;241m=\u001b[39m patch_config(config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child())\n\u001b[0;32m   2089\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m   2090\u001b[0m         output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   2091\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m-> 2092\u001b[0m             context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   2093\u001b[0m                 call_func_with_variable_args,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   2094\u001b[0m                 func,\n\u001b[0;32m   2095\u001b[0m                 input_,\n\u001b[0;32m   2096\u001b[0m                 config,\n\u001b[0;32m   2097\u001b[0m                 run_manager,\n\u001b[0;32m   2098\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2099\u001b[0m             ),\n\u001b[0;32m   2100\u001b[0m         )\n\u001b[0;32m   2101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   2102\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32md:\\DAI_HOC\\CS431\\DoAn\\Rag_QABot\\venv310\\lib\\site-packages\\langchain_core\\runnables\\config.py:430\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    429\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\DAI_HOC\\CS431\\DoAn\\Rag_QABot\\venv310\\lib\\site-packages\\langchain_core\\runnables\\base.py:4882\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[1;34m(self, input_, run_manager, config, **kwargs)\u001b[0m\n\u001b[0;32m   4880\u001b[0m                 output \u001b[38;5;241m=\u001b[39m chunk\n\u001b[0;32m   4881\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4882\u001b[0m     output \u001b[38;5;241m=\u001b[39m call_func_with_variable_args(\n\u001b[0;32m   4883\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, input_, config, run_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   4884\u001b[0m     )\n\u001b[0;32m   4885\u001b[0m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[0;32m   4886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "File \u001b[1;32md:\\DAI_HOC\\CS431\\DoAn\\Rag_QABot\\venv310\\lib\\site-packages\\langchain_core\\runnables\\config.py:430\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    429\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[16], line 68\u001b[0m, in \u001b[0;36mget_context\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_context\u001b[39m(query: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m---> 68\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[43mvector_retriever\u001b[49m\u001b[38;5;241m.\u001b[39mget_relevant_documents(query)\n\u001b[0;32m     69\u001b[0m     reranked \u001b[38;5;241m=\u001b[39m crossencoder_rerank(docs, query, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m format_doc(reranked)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vector_retriever' is not defined"
     ]
    }
   ],
   "source": [
    "result = rag_chain.invoke(\" tng ca m hnh xc xut trong to sinh nh\")\n",
    "# 3 thnh phn loss ca diffusion \n",
    "#vae loss c bao nhiu thnh phn\n",
    "#diffusion b g  c latent diffusion\n",
    "#VAE b g  c diffusion\n",
    "#diffuion b g  c laten diffusion\n",
    "#Auto encoder b g  to ra VAE\n",
    "#Ti sao to sinh cn encode xong li decode ra\n",
    "# tng ca m hnh xc xut trong vic to sinh hnh nh\n",
    "##  tng naive bayes trong to sinh\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d44befaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vram  dng 4.24905216 GB\n"
     ]
    }
   ],
   "source": [
    "print(\"vram  dng\", torch.cuda.memory_allocated(0) / 1e9, \"GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4208c76",
   "metadata": {},
   "source": [
    "## gemini "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf300fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm_gemini = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",   # hoc gemini-1.5-pro, gemini-2.0-flash\n",
    "    temperature=0.0,\n",
    "    google_api_key=googleAPIKey,  #  thm dng ny,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d81bfbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vram  dng 1.97685248 GB\n"
     ]
    }
   ],
   "source": [
    "print(\"vram  dng\", torch.cuda.memory_allocated(0) / 1e9, \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ea8d389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables import RunnableMap,RunnableLambda\n",
    "\n",
    "\n",
    "class VideoAnswer(BaseModel):\n",
    "    text: str = Field(description=\"Cu tr li tm tt trong 3 cu\")\n",
    "    filename: List[str] = Field(description=\"Tn file transcript gc\")\n",
    "    video_url: List[str] = Field(description=\"URL ca video gc\")\n",
    "    start_timestamp: List[str] = Field(description=\"Thi im bt u (format: HH:MM:SS)\")\n",
    "    end_timestamp: List[str] = Field(description=\"Thi im kt thc (format: HH:MM:SS)\")\n",
    "    #confidence: List[str] = Field(description=\" tin cy: zero/low/medium/high\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=VideoAnswer)\n",
    "\n",
    "# ===== Prompt =====\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Da vo transcript sau, tr li cu hi ca ngi dng bng ting Vit.Phn tm tt ni dung th nn tm tt trong 3 cu, \n",
    "da vo cc on transcript c cung cp v ch ra on video cha thng tin  v cc on video lin quan khc (nu c) (nhng vn chung 1 text tm tt) (video url, thi im bt u v kt thc).\n",
    "ng thi lm mt li ni dung tm tt \n",
    "Khi trch dn thng tin, **lun s dng ng [Video URL] v [Start] t doc cha ni dung **.\n",
    "Nu khng bit cu tr li th c tr li l ti khng bit v  tin cy l zero\n",
    "Nu cu hi khng lin quan n ni dung video th tr li ti ch c hun luyn tr li cc cu hi lin quan n ni dung video v  tin cy l zero\n",
    "Khng ba ra thng tin khng c cn c, khng tr li sai format\n",
    "Nu bn cc k chc chn v cu tr li, hy t  tin cy l high. Nu bn kh chc chn, hy t  tin cy l medium. Nu bn khng chc chn v cu tr li, hy t  tin cy l low.\n",
    "nh dng u ra phi tun theo JSON schema sau:\n",
    "{format_instructions}\n",
    "Transcript:\n",
    "{context}\n",
    "\n",
    "Cu hi: {question}\n",
    "\\nAnswer:                                          \n",
    "\"\"\")\n",
    "\n",
    "def format_doc(docs):\n",
    "    formatted = []\n",
    "    for doc in docs:\n",
    "        url = doc.metadata.get(\"video_url\", \"\")\n",
    "        filename = doc.metadata.get(\"filename\", \"\")\n",
    "        start = doc.metadata.get(\"start_timestamp\", \"\")\n",
    "        end = doc.metadata.get(\"end_timestamp\", \"\")\n",
    "        content = doc.page_content\n",
    "        formatted.append(f\"\"\"[Video URL]: {url}\n",
    "[Filename]: {filename}\n",
    "[Start]: {start}\n",
    "[End]: {end}\n",
    "[Content]: {content}\"\"\")\n",
    "    return \"\\n\\n\".join(formatted)\n",
    "\n",
    "def extract_json_from_output(output: str) -> str:\n",
    "    return output.split('Answer')[1].strip()\n",
    "    \n",
    "    # Hm rerank ly docs v query\n",
    "def rerank_with_query(docs_and_query) -> List:\n",
    "    docs, query = docs_and_query\n",
    "    reranked = crossencoder_rerank(docs, query, top_k=10)\n",
    "    return reranked\n",
    "\n",
    "# Hm ly context  a vo prompt \n",
    "def get_context(query: str):\n",
    "    import time\n",
    "    start= time.time()\n",
    "    docs = vector_retriever.get_relevant_documents(query)\n",
    "    reranked = crossencoder_rerank(docs, query, top_k=10)\n",
    "    end = time.time()\n",
    "    print(f\"Reranking Time taken: {end - start} seconds\")\n",
    "    return format_doc(reranked)\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"context\": RunnableLambda(get_context),\n",
    "    }\n",
    "    | prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "    | llm_gemini\n",
    "\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c60c898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranking Time taken: 8.009997367858887 seconds\n",
      "```json\n",
      "{\n",
      " \"text\": \"Vic t hun luyn m hnh CLIP t u l khng kh thi v n i hi mt lng d liu cc k ln, cng vi ti nguyn tnh ton v kh nng x l song song ng k. Ngoi ra, chi ph cho cc GPU cn thit  hun luyn cng rt t , khin vic s dng cc m hnh CLIP  c tin hun luyn tr thnh la chn kh thi duy nht  gii quyt cc tc v hin c.\",\n",
      " \"filename\": [\n",
      "  \"yPzXzbEhUW0\"\n",
      " ],\n",
      " \"video_url\": [\n",
      "  \"https://youtube.com/watch?v=yPzXzbEhUW0\"\n",
      " ],\n",
      " \"start_timestamp\": [\n",
      "  \"00:00:14\"\n",
      " ],\n",
      " \"end_timestamp\": [\n",
      "  \"00:01:03\"\n",
      " ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "result = rag_chain.invoke(\" ti sao hun luyn clip t u l kh khn\")\n",
    "# 3 thnh phn loss ca diffusion \n",
    "#vae loss c bao nhiu thnh phn\n",
    "#diffusion b g  c latent diffusion\n",
    "#VAE b g  c diffusion\n",
    "#diffuion b g  c laten diffusion\n",
    "#Auto encoder b g  to ra VAE\n",
    "#Ti sao to sinh cn encode xong li decode ra\n",
    "# tng ca m hnh xc xut trong vic to sinh hnh nh\n",
    "##  tng naive bayes trong to sinh\n",
    "print(result.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfd8b0c",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12d89cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DAI_HOC\\CS431\\DoAn\\Rag_QABot\\venv310\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3579: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "import torch\n",
    "from typing import Union, List, Dict, Any\n",
    "\n",
    "# Cc imports cn thit\n",
    "from langchain.schema import Document\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy, context_precision, context_recall\n",
    "from langchain_community.vectorstores import Chroma \n",
    "from langchain_huggingface import HuggingFaceEmbeddings \n",
    "\n",
    "# p dng nest_asyncio  chy async trong notebook\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# --- Gi nh cc bin global  c nh ngha ---\n",
    "# Cn m bo cc bin ny  c khi to trong cc cell trc:\n",
    "# vector_db_recursive, vector_db_semantic, embedding, llm_qwen, llm_gemini\n",
    "# reranker, tok, crossencoder_rerank, batch_crossencoder_scores ( nh ngha)\n",
    "\n",
    "\n",
    "# --- 1. Pydantic Model cho Output ---\n",
    "class VideoAnswer(BaseModel):\n",
    "    text: str = Field(description=\"Cu tr li tm tt trong 3 cu\")\n",
    "    filename: List[str] = Field(description=\"Tn file transcript gc\")\n",
    "    video_url: List[str] = Field(description=\"URL ca video gc\")\n",
    "    start_timestamp: List[str] = Field(description=\"Thi im bt u (format: HH:MM:SS)\")\n",
    "    end_timestamp: List[str] = Field(description=\"Thi im kt thc (format: HH:MM:SS)\")\n",
    "\n",
    "# --- 2. Hm nh dng Context ---\n",
    "def format_doc(docs: List[Document]) -> str:\n",
    "    formatted = []\n",
    "    for doc in docs:\n",
    "        url = doc.metadata.get(\"video_url\", \"\")\n",
    "        filename = doc.metadata.get(\"filename\", \"\")\n",
    "        start = doc.metadata.get(\"start_timestamp\", \"\")\n",
    "        end = doc.metadata.get(\"end_timestamp\", \"\")\n",
    "        content = doc.page_content\n",
    "        formatted.append(f\"\"\"[Video URL]: {url}\n",
    "[Filename]: {filename}\n",
    "[Start]: {start}\n",
    "[End]: {end}\n",
    "[Content]: {content}\"\"\")\n",
    "    return \"\\n\\n\".join(formatted)\n",
    "\n",
    "# --- 3. Hm To Retriever cho Config ---\n",
    "def get_retriever_for_config(db: Chroma, retriever_type: str) -> Union[EnsembleRetriever, Any]:\n",
    "    \n",
    "    # 1. Semantic (MMR) Retriever \n",
    "    vector_retriever = db.as_retriever(\n",
    "        search_type=\"mmr\", \n",
    "        search_kwargs={\"k\": 40, \"fetch_k\": 80, \"lambda_mult\": 0.3}\n",
    "    )\n",
    "    \n",
    "    # 2. BM25 Retriever\n",
    "    raw = db.get(include=[\"documents\", \"metadatas\"])\n",
    "    all_docs = [\n",
    "        Document(page_content=content, metadata=metadata)\n",
    "        for content, metadata in zip(raw[\"documents\"], raw[\"metadatas\"])\n",
    "    ]\n",
    "    bm25_retriever = BM25Retriever.from_documents(all_docs)\n",
    "    bm25_retriever.k = 30\n",
    "    \n",
    "    if retriever_type == \"semantic\":\n",
    "        return vector_retriever\n",
    "    elif retriever_type == \"bm25\":\n",
    "        return bm25_retriever\n",
    "    elif retriever_type == \"hybrid\":\n",
    "        return EnsembleRetriever(\n",
    "            retrievers=[bm25_retriever, vector_retriever],\n",
    "            weights=[0.5, 0.5]\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid retriever type: {retriever_type}\")\n",
    "\n",
    "\n",
    "# --- 4. Hm To Universal Test Set (S dng LLM Judge) ---\n",
    "async def generate_synthetic_test_set_from_db(llm, db: Chroma, num_samples: int = 5) -> List[Dict]:\n",
    "    \n",
    "    raw_data = db.get(include=[\"documents\", \"metadatas\"])\n",
    "    all_chunks_data = [\n",
    "        {\"page_content\": doc, \"metadata\": meta}\n",
    "        for doc, meta in zip(raw_data[\"documents\"], raw_data[\"metadatas\"])\n",
    "    ]\n",
    "    \n",
    "    valid_chunks = [\n",
    "        chunk for chunk in all_chunks_data\n",
    "        if len(chunk[\"page_content\"]) > 200 and \"subscribe\" not in chunk[\"page_content\"].lower()\n",
    "    ]\n",
    "    \n",
    "    if len(valid_chunks) < num_samples:\n",
    "        num_samples = len(valid_chunks)\n",
    "        if num_samples == 0: return []\n",
    "\n",
    "    sampled_chunks = random.sample(valid_chunks, num_samples)\n",
    "\n",
    "    generation_prompt_template = ChatPromptTemplate.from_template(\n",
    "        \"\"\"Bn l chuyn gia to d liu. Da vo NG CNH (context) sau, hy to ra 1 cp (cu hi, cu tr li) m NG CNH ny tr li trc tip.\n",
    "        - Cu tr li (ground_truth) phi c rt ra TRC TIP t NG CNH.\n",
    "        - Tr li bng ting Vit.\n",
    "        - Ch tr v 1 JSON object vi 2 key: \"question\" v \"ground_truth\".\n",
    "\n",
    "        NG CNH:\n",
    "        {context}\n",
    "\n",
    "        JSON:\n",
    "        \"\"\"\n",
    "    )\n",
    "    generation_chain = generation_prompt_template | llm\n",
    "    \n",
    "    test_set = []\n",
    "    print(f\"  ang dng LLM Judge  to {num_samples} mu test...\")\n",
    "    for chunk_data in sampled_chunks:\n",
    "        context = chunk_data[\"page_content\"]\n",
    "        try:\n",
    "            response = await generation_chain.ainvoke({\"context\": context})\n",
    "            json_str = response.content.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "            data = json.loads(json_str)\n",
    "\n",
    "            test_set.append({\n",
    "                \"question\": data[\"question\"],\n",
    "                \"ground_truth\": data[\"ground_truth\"],\n",
    "                \"ground_truth_context\": [context]\n",
    "            })\n",
    "        except Exception:\n",
    "            continue \n",
    "\n",
    "    return test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e784557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Hm Chy nh gi 1 Cu hnh ---\n",
    "async def run_ragas_for_config(\n",
    "    config_name: str, \n",
    "    db: Chroma, \n",
    "    retriever_type: str, \n",
    "    llm_generator,\n",
    "    llm_judge,\n",
    "    embedding,\n",
    "    current_count: int, \n",
    "    total_configs: int, \n",
    "    universal_test_set: List[Dict]\n",
    ") -> Dict:\n",
    "    \n",
    "    print(f\"\\n--- BT U NH GI CONFIG {current_count}/{total_configs}: {config_name} ---\")\n",
    "\n",
    "    # 1. To Retriever & Ly Test Set\n",
    "    retriever = get_retriever_for_config(db, retriever_type)\n",
    "    test_set = universal_test_set\n",
    "    \n",
    "    if not test_set:\n",
    "        print(f\"LI: {config_name} khng th to test set.\")\n",
    "        return {\"config\": config_name, \"error\": \"Test set creation failed\"}\n",
    "\n",
    "    # 2. nh ngha cc thnh phn RAG\n",
    "    parser = JsonOutputParser(pydantic_object=VideoAnswer)\n",
    "    \n",
    "    generation_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Da vo transcript sau, tr li cu hi ca ngi dng bng ting Vit.Phn tm tt ni dung th nn tm tt trong 3 cu, \n",
    "da vo cc on transcript c cung cp v ch ra on video cha thng tin  v cc on video lin quan khc (nu c) (nhng vn chung 1 text tm tt) (video url, thi im bt u v kt thc).\n",
    "ng thi lm mt li ni dung tm tt \n",
    "Khi trch dn thng tin, **lun s dng ng [Video URL] v [Start] t doc cha ni dung **.\n",
    "Nu khng bit cu tr li th c tr li l ti khng bit v  tin cy l zero\n",
    "Nu cu hi khng lin quan n ni dung video th tr li ti ch c hun luyn tr li cc cu hi lin quan n ni dung video v  tin cy l zero\n",
    "Khng ba ra thng tin khng c cn c, khng tr li sai format\n",
    "nh dng u ra phi tun theo JSON schema sau:\n",
    "{format_instructions}\n",
    "Transcript:\n",
    "{context}\n",
    "\n",
    "Cu hi: {question}\n",
    "\\nAnswer:                                          \n",
    "\"\"\")\n",
    "\n",
    "    # 2a. Retriever + Rerank Chain\n",
    "    retrieval_and_rerank_chain = (\n",
    "        RunnablePassthrough.assign(\n",
    "            docs=RunnableLambda(lambda x: retriever.get_relevant_documents(x[\"question\"]))\n",
    "        )\n",
    "        | RunnableLambda(lambda x: crossencoder_rerank(x[\"docs\"], x[\"question\"], top_k=10))\n",
    "    )\n",
    "\n",
    "    # 2b. RAG Chain Hon chnh\n",
    "    rag_chain = (\n",
    "        RunnablePassthrough.assign(retrieved_docs=retrieval_and_rerank_chain)\n",
    "        | RunnablePassthrough.assign(\n",
    "            context=lambda x: format_doc(x[\"retrieved_docs\"]),\n",
    "            question=RunnablePassthrough()\n",
    "        )\n",
    "        | generation_prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "        | llm_generator\n",
    "    )\n",
    "\n",
    "    # 3. Chy RAG Chain trn Universal Test Set\n",
    "    evaluation_data = []\n",
    "    \n",
    "    for i, item in enumerate(test_set):\n",
    "        question = item['question']\n",
    "        print(f\"  [{config_name}] ang x l mu {i+1}/{len(test_set)}...\") \n",
    "        \n",
    "        # A. Chy ton b chui RAG  ly cu tr li\n",
    "        response_msg = await rag_chain.ainvoke({\"question\": question})\n",
    "        \n",
    "        # B. Ly retrieved contexts (Chy li retrieval_and_rerank_chain)\n",
    "        retrieved_docs_reranked = await retrieval_and_rerank_chain.ainvoke({\"question\": question})\n",
    "        contexts_list = [d.page_content for d in retrieved_docs_reranked]\n",
    "\n",
    "        # C. Trch xut answer text\n",
    "        try:\n",
    "            json_str = response_msg.content.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "            answer_json = json.loads(json_str)\n",
    "            answer_text = answer_json.get(\"text\", \"\")\n",
    "        except Exception:\n",
    "            answer_text = response_msg.content \n",
    "\n",
    "        evaluation_data.append({\n",
    "            \"question\": question,\n",
    "            \"answer\": answer_text,\n",
    "            \"contexts\": contexts_list,\n",
    "            \"ground_truth\": item[\"ground_truth\"],\n",
    "            \"ground_truth_context\": item[\"ground_truth_context\"]\n",
    "        })\n",
    "    \n",
    "    # 4. nh gi Ragas\n",
    "    dataset = Dataset.from_list(evaluation_data)\n",
    "    metrics = [faithfulness, answer_relevancy, context_precision, context_recall]\n",
    "    \n",
    "    print(f\"  [{config_name}] ang chy Ragas metrics...\")\n",
    "    \n",
    "    results = evaluate(\n",
    "        dataset=dataset,\n",
    "        metrics=metrics,\n",
    "        llm=llm_judge,\n",
    "        embeddings=embedding \n",
    "    )\n",
    "    \n",
    "    final_metrics = results.metrics\n",
    "    final_metrics[\"config\"] = config_name\n",
    "    print(f\"---  HON TT CONFIG {current_count}/{total_configs} ---\")\n",
    "    return final_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3eb24281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "--- BC 1: TO UNIVERSAL TEST SET ---\n",
      "  ang dng LLM Judge  to 5 mu test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DEBUG: Cu trc Universal Test Set (5 MU) ---\n",
      "\n",
      "Mu 1:\n",
      "  QUESTION: M hnh D (Discriminator) xem xt nhng loi d liu no?\n",
      "  GROUND TRUTH: M hnh D, Discriminator s xem xt c d liu tht v d liu gi c to ra.\n",
      "  CONTEXT (Source): v d liu fake. V m hnh G ny c t cc ci vector nhiu G1, G2, GN to ra cc ci im d liu gi ny. Sau  th ci m hnh phn bit, tc l m hnh D, Discriminator s xem xt c d liu t...\n",
      "\n",
      "Mu 2:\n",
      "  QUESTION: Vic thm log vo cng thc c tc dng g?\n",
      "  GROUND TRUTH: Vic thm log vo n s gip chng ta n gin ha ci cng thc ny. V log ca tch s a v ci hm tng.\n",
      "  CONTEXT (Source): ta s thm ci log vo. Vy th ci vic thm log vo n s gip chng ta n gin ha ci cng thc ny. V log ca tch s a v ci hm tng. Khi chng ta bin i n s d dng hn. V n s tn...\n",
      "\n",
      "Mu 3:\n",
      "  QUESTION: Khi c ta  ca i tng trong nh, v d nh ngi, v mun t cu hi hi thoi, dng cu hi u tin c th l g?\n",
      "  GROUND TRUTH: V d nh l what type of vehicle is featured in the image\n",
      "  CONTEXT (Source): c ta  ca i tng nh l ngi ca nhng ngi trong tm hnh backpack v.v. th n s l c ta  lm d liu u vo v c 3 dng cu hi c yu cu ci dng cu hi u tin  l dng cu ...\n",
      "\n",
      "Mu 4:\n",
      "  QUESTION: Trong qu trnh x l, s khc bit gia vic kt hp c trng trong clip v phng php c m t trong ng cnh ny l g?\n",
      "  GROUND TRUTH: vi clip th chng ta ch kt hp n  ci bc cui cng thi Cn  y chng ta s thc hin  bc trung gian\n",
      "  CONTEXT (Source): trung gian, trong khi  vi clip th chng ta ch kt hp n  ci bc cui cng thi Cn  y chng ta s thc hin  bc trung gian Th ti sao li c nhng ci vic nh vy?  l khi chng ta ...\n",
      "\n",
      "Mu 5:\n",
      "  QUESTION: Trong ng cnh ny, mu cam tng ng vi s no?\n",
      "  GROUND TRUTH: mu cam tng ng vi s 1\n",
      "  CONTEXT (Source): mu cam tng ng vi s 1 V n i cng kh l mt Ri, tip theo th chng ta s tm cch trc quan ha mt chui cc con s m c ly t 2 ci vector T 1 cho n 0 Th chng ta thy l n  c...\n",
      "\n",
      "================================================================================\n",
      "Bt u nh gi tng cng 12 cu hnh trn cng b Test Set...\n",
      "================================================================================\n",
      "\n",
      "--- BT U NH GI CONFIG 1/12: semantic_semantic_qwen ---\n",
      "  [semantic_semantic_qwen] ang x l mu 1/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_3340\\1181090127.py:47: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs=RunnableLambda(lambda x: retriever.get_relevant_documents(x[\"question\"]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " xy ra li trong qu trnh thc thi: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`\n",
      "Vui lng kim tra li Quota API v cc li khi to.\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Hm Lp Chnh run_all_configs_and_compare ---\n",
    "async def run_all_configs_and_compare(db_semantic, db_recursive, llm_qwen, llm_gemini, embedding, num_test_samples=5):\n",
    "    \n",
    "    if not db_semantic or not db_recursive:\n",
    "        print(\"LI: Mt hoc c hai DB cha c ti. Vui lng kim tra li ng dn.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    llm_judge = llm_gemini \n",
    "\n",
    "    # --- BC 1: TO UNIVERSAL TEST SET (CH 1 LN) ---\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"--- BC 1: TO UNIVERSAL TEST SET ---\")\n",
    "    universal_test_set = await generate_synthetic_test_set_from_db(llm_judge, db_recursive, num_samples=num_test_samples)\n",
    "    \n",
    "    if not universal_test_set:\n",
    "        print(\"LI: Khng th to Universal Test Set. Dng nh gi.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # DEBUG: Hin th ton b Test Set\n",
    "    print(f\"\\n--- DEBUG: Cu trc Universal Test Set ({len(universal_test_set)} MU) ---\")\n",
    "    for idx, sample in enumerate(universal_test_set):\n",
    "        print(f\"\\nMu {idx+1}:\")\n",
    "        print(f\"  QUESTION: {sample['question']}\")\n",
    "        print(f\"  GROUND TRUTH: {sample['ground_truth']}\")\n",
    "        print(f\"  CONTEXT (Source): {sample['ground_truth_context'][0][:200]}...\")\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    # --- BC 2: CHY VNG LP NH GI ---\n",
    "    chunking_map = {\"semantic\": db_semantic, \"recursive\": db_recursive}\n",
    "    retrieval_types = [\"semantic\", \"bm25\", \"hybrid\"]\n",
    "    llm_map = {\"qwen\": llm_qwen, \"gemini\": llm_gemini}\n",
    "    \n",
    "    all_results = []\n",
    "    total_configs = len(chunking_map) * len(retrieval_types) * len(llm_map)\n",
    "    current_count = 0 \n",
    "    \n",
    "    print(f\"Bt u nh gi tng cng {total_configs} cu hnh trn cng b Test Set...\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    for chunk_name, db in chunking_map.items():\n",
    "        for retrieval_name in retrieval_types:\n",
    "            for llm_name, llm_generator in llm_map.items():\n",
    "                current_count += 1 \n",
    "                config_name = f\"{chunk_name}_{retrieval_name}_{llm_name}\"\n",
    "                \n",
    "                result = await run_ragas_for_config(\n",
    "                    config_name=config_name,\n",
    "                    db=db,\n",
    "                    retriever_type=retrieval_name,\n",
    "                    llm_generator=llm_generator,\n",
    "                    llm_judge=llm_judge,\n",
    "                    embedding=embedding,\n",
    "                    current_count=current_count, \n",
    "                    total_configs=total_configs,\n",
    "                    universal_test_set=universal_test_set # TRUYN VO TEST SET CHUNG\n",
    "                )\n",
    "                all_results.append(result)\n",
    "                \n",
    "    # In bng tng hp\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"--- BNG TNG KT KT QU RAGAS ---\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    df_final = pd.DataFrame(all_results)\n",
    "    df_final = df_final[['config', 'faithfulness', 'answer_relevancy', 'context_precision', 'context_recall']].sort_values(by='faithfulness', ascending=False)\n",
    "    \n",
    "    print(df_final.to_markdown(index=False))\n",
    "    return df_final\n",
    "\n",
    "\n",
    "# --- KHI THC THI CUI CNG (Cn chy  cui Notebook) ---\n",
    "\n",
    "if 'llm_qwen' in globals() and 'llm_gemini' in globals() and 'vector_db_recursive' in globals() and 'vector_db_semantic' in globals() and 'embedding' in globals():\n",
    "    try:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        final_results_df = loop.run_until_complete(\n",
    "            run_all_configs_and_compare(vector_db_semantic, vector_db_recursive, llm_qwen, llm_gemini, embedding)\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"\\n xy ra li trong qu trnh thc thi: {e}\")\n",
    "        print(\"Vui lng kim tra li Quota API v cc li khi to.\")\n",
    "else:\n",
    "    print(\"LI: Vui lng chy cc cell khi to (LLM, DB, Embedding) trc khi chy cell ny.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4738a701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
